{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics workbook \n",
    "## Chapter 1\n",
    "### Statistic is the science of data analysis\n",
    " - •\tIt is a scientific approach based on calculations.\n",
    " - •\tUses mathematical methods to characterize data.\n",
    " - •\tPredicts the outcome of various processes before they happen. \n",
    " - •\tFinds how various factors influence data.\n",
    " - •\tFinds how different factors behind the data depend on each other.\n",
    " - •\tIn many situations data is given by natural processes and thus observation plays a key role. \n",
    " - •\tIn general we need statistics for data of certain complexity. Simple data may not require a statistical description. \n",
    "\n",
    "### Sampling and descriptive statistics\n",
    "**Example:** what is the prevalence of diabetes in the Icelandic population? (prevalence = the percentage of people affected by the disease).\n",
    "In order to evaluate the proportion we consider a **sample** of the Icelandic population. \n",
    "Prevalence (%) = (number of individuals with diabetes in the sample / number of individuals in the sample) * 100\n",
    "\n",
    "**Sample = subset of the total population**\n",
    "\n",
    "A good sample should represent well the entire population, otherwise the sample is **biased**.\n",
    "\n",
    "The students of RU are not a good sample in this case because they are young and only very few have the disease.\n",
    "\n",
    "A small sample is not good because of the relatively large random factors.  \n",
    "\n",
    "A **population** is the entire collection of objects or outcomes about which information is sought. \n",
    "\n",
    "A **sample** is a subset of a population, containing the objects or outcomes that are actually observed.\n",
    "\n",
    "A **simple random sample** of size n is a sample chosen by a method in which each collection of n population items is equally likely to make up the sample, just as in lottery. (?)\n",
    "\n",
    "### Sample variation effect \n",
    "**Example 1.3**\n",
    "A quality inspector draws a simple random sample of 40 bolts from a large shipment and measures the length of each. He finds that 34 of them, or 85%, meet a length specification. He concludes that exactly 85% of the bolts in the shipment meet the specification. The inspector’s supervisor concludes that the proportion of good bolts is likely to be close to, but not exactly equal to, 85%. Which conclusion is appropriate? \n",
    "My answer: The inspector’s supervisor. \n",
    "\n",
    "**Example 1.4**\n",
    "Another inspector repeats the study with a different simple random sample of 40 bolts. She finds that 36 of them, or 90%, are good. The first inspector claims that she must have done something wrong, since his results showed that 85%, not 90%, of bolts are good. Is he right?\n",
    "My answer: No there is variance in such a small sample.\n",
    "Answer from book: This is sampling variation at work. Two different samples from the same population will differ from each other. However, the larger the samples the smaller the observed differences.\n",
    "\n",
    "### The case of multiple measurements\n",
    "**Example 1.5**\n",
    "A geologist weighs a rock several times on a sensitive scale. Each time, the scale gives a slightly different reading. Under what conditions can these readings be thought of as a simple random sample? What is the population? \n",
    "\n",
    "If the physical characteristics of the scale remain the same for each weighing, so that the measurements are made under identical conditions, then the readings may be considered to be a simple random sample. The population is conceptual. It consists of all the readings that the scale could in principle produce.\n",
    "\n",
    "### About bias\n",
    " - •\tThe word **bias** means an incorrect tendency of an evaluation or estimation.\n",
    " - •\tThe bias can possibly be in the data or in the method of analysis.\n",
    " \n",
    " **Examples**\n",
    " - •\tSystematic errors, due to incorrect measurements.\n",
    " - •\tThe measurments are not independant: for example the same result (or data) is reapeted without repeating the measurment. \n",
    " - •\tThe number of measurements are too small. \n",
    " - •\tSome data points have been ignored. \n",
    " - •\tAnd many other possible situations, from case to case. \n",
    "\n",
    "### Sample mean and sample varience\n",
    "Suppose x is a random variable in a data set of n variables.\n",
    "\n",
    "Data = [x1, x2, x3 . . ., xn] \n",
    "\n",
    "We want to find the mean value and we want to know the variability. \n",
    "\n",
    "Sample = [1.1, 1.3, 0.9, 1.1, 0.8], n=5 \n",
    "\n",
    "**Sample mean:**\n",
    "\n",
    "$\\hat{x} = \\frac{1}{n} \\sum \\limits _{i=1} ^{n} x_{i}$\n",
    "\n",
    "**Sample variance:**\n",
    "\n",
    "$s^{2} = \\frac{1}{n-1} \\sum \\limits _{i=1} ^{n} (x_{i} - \\hat{x})^{2}$\n",
    "\n",
    "$s^{2} = \\frac{1}{n-1} (\\sum \\limits _{i=1} ^{n} x^{2}_{i} - n\\hat{x}^{2})$\n",
    "\n",
    "n-1 because there are n-1 independant terms.\n",
    "\n",
    "**Standard deviation:**\n",
    "\n",
    "$s = \\sqrt{\\frac{1}{n-1} \\sum \\limits _{i=1} ^{n} (x_{i} - \\hat{x})^{2}}$\n",
    "\n",
    "### Summary statistics\n",
    "There are two types of data: **quantitative** or **qualitative**\n",
    "\n",
    "**Quantitative data = numbers**\n",
    "\n",
    "**Qualitative data = categories**\n",
    "\n",
    "Usually the summary statistics is applicable to quantitative data.\n",
    "Consider the numeric random variable x and data sample $[x_{1},x_{2},x_{3},. . ., x_{n}]$.\n",
    "\n",
    "**Outliers** are numbers that are much larger or much smaller than the other numbers. Look at them carefully:  Are they real data? Are they wrong numbers, are they wrong measurements?\n",
    "\n",
    "**Sample median**: Sort the numbers in ascending order.   The median is the number that divides the data in two halves.  If we have n data points, the median is $x_\\frac{n+1}{2}$ if n is an odd number, and $\\frac{(x_{\\frac{n}{2}} + x_{\\frac{n}{2} + 1})}{2}$ if n is an even number.\n",
    "\n",
    "**Quartiles:** Sort the data and find the three numbers that split the data points in four groups, each with the same number of data points. (Or four quarters.) The 2-nd quartile is identical to the median.\n",
    "\n",
    "**Percentiles:** Sort the data and find the number such that p% of the data points have lower values than it. The quartiles correspond to p=25, 50, and 75.\n",
    "\n",
    "## Chapter 2\n",
    "### Probability\n",
    "**Probability = chances = likelihood that an event occurs**\n",
    "\n",
    "Probability can be evaluated from data. It can be defined for phenomena or experiments that can be (at least potentially) repeated. \n",
    "\n",
    "**Example:**\n",
    "\n",
    "Team A plays against Team B. What are the chances that Team A wins?\n",
    "Use data: the previous matches between these teams.\n",
    "\n",
    "P(A wins) = number of previous games won by A / total number of games played against other team. **This is an estimated probability.**\n",
    "\n",
    "A possibly better **estimate** may be to use other information, like where the game will be held (at home, or away) etc. \n",
    "\n",
    "### The fundamental role of data\n",
    "\n",
    "**In practice the probability is obtained / inferred from the data observed for the particular phenomenon or experiment of interest.**\n",
    "\n",
    "**The probability of an event E to occur is:**\n",
    "P(E) = number of favorable outcomes (for event E) / number of all possible outcomes\n",
    "\n",
    "Data can be about the history of the events, or about their distribution, or about the details of a particular phenomenon or experiment. It represents what we already know. Probabilities are in general used for prediction, but also for characterization of a certain process, for understanding, etc. They are useful for processes of a certain complexity where causality may not be very simple and a certain randomness is working. Lack of data can prevent us from finding a probability of an event. \n",
    "\n",
    "**Example:**\n",
    "We have a box with identical objects, but they have two different colors A and B. What is the probability of extracting color A. \n",
    "\n",
    "**Method 1:** Do it a number of times and look at the data. \n",
    "\n",
    "P(A) = number of outcomes A / number of trials \n",
    "\n",
    "This is the estimated probability obtained from a sample. \n",
    "\n",
    "**Method 2:** Open the box and look at the proportions.\n",
    "\n",
    "P(A) = number of objects with color A / total number of objects\n",
    "\n",
    "This is the exact probability obtained from the whole population. In practice we may not have access to the whole population.\n",
    "\n",
    "### Terminology\n",
    "The set of all possible outcomes of an experiment is called **the sample space** for that experiment. A subset of the sample space is called an **event**.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "For a rolling die, the sample space is :{1,2,3,4,5,6}\n",
    "\n",
    "For a coin toss, the sample space is: {heads, tails}\n",
    "\n",
    "For weighing a box, the sample space is mass plus/minus uncertainty, but theoretically before we know any result the sample space is [0, infinity[\n",
    "\n",
    "**Events can be:** Die shows 2 after one roll, or shows 2 and the 4 after two rolls. Events can be simple or complex. \n",
    "\n",
    "### Refreshment on sets\n",
    "A set (mengi) is a collection of elements. Lets say we have set A and set B. \n",
    "Union of two sets $A \\cup B$ = all the elements from both sets put together. \n",
    "\n",
    "Intersection of two sets $A \\cap B$ = all the elements common in A and B. \n",
    "\n",
    "$A^{c} =$ **not** A\n",
    "\n",
    "$\\cup$ -> OR\n",
    "\n",
    "$\\cap$ -> AND\n",
    "\n",
    "$B \\subset A$ B is included A. Which means $A \\cup B = A$ and $A \\cap B = B$\n",
    "\n",
    "$A \\cup B = B \\cup A$\n",
    "\n",
    "$A \\cap B = B \\cap A$\n",
    "\n",
    "### Events as sets\n",
    "\n",
    "**S = the whole sample space**\n",
    "\n",
    "**E = Event**\n",
    "\n",
    "**It can be a simple event or a combination of events.**\n",
    "\n",
    "E is a subset of S: $E \\subset S$\n",
    "\n",
    "Possibly E = S or $E = \\phi$ (if event is not in sample space)\n",
    "\n",
    "### Mutually exclusive sets \n",
    "\n",
    "The events A and B are said to be mutually exclusive if they cannot occur together. That means $A \\cap B = \\phi$.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Iceland plays against France. The sample space is: {Iceland wins, France wins, draw}\n",
    "\n",
    "Events A = {Iceland wins} and B = {France wins} cannot occur together. \n",
    "A and B corresponds to set with no common element. \n",
    "\n",
    "### The addition rule\n",
    "\n",
    "What if A and B are not mutually exclusive. \n",
    "\n",
    "Then $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n",
    "\n",
    "An intuitive proof: if we assume that $P(A \\cup B) = P(A) + P(B)$ we have to notice that the intersection $P(A \\cap B)$ is included twice. To correct the result we have to subtract it once. \n",
    "\n",
    "Another version: $P(A \\cup B) = 1 - P(A^{c} \\cap B^{c})$\n",
    "\n",
    "### The difference between Probability Theory and Statistics\n",
    "\n",
    "These two sciences are related because they study random events.  But the \n",
    "approach is different.\n",
    "\n",
    "**Probability Theory**\n",
    " - The main goal is to evaluate the probability of complex events by \n",
    "considering the probability of some simple events being known.\n",
    " - Uses discrete mathematics, combinatorics, graph theory.\n",
    " - Traditionally it is a field of mathematics, with axioms, theorems, proofs.\n",
    "\n",
    "**Statistics**\n",
    " - The main goal is to evaluate the probabilities of random events using data.\n",
    " - Uses elements of probability theory, but often in an empirical way.\n",
    " - It can be considered an experimental or a natural science, with some \n",
    "mathematics in the background, but the main tool is the computer.\n",
    " - Because of the evolution of computers Statistics is now a very powerful \n",
    "research method in many fields: engineering, economy, medicine, \n",
    "sociology, business, etc.\n",
    "\n",
    "### Axioms of probability\n",
    "1. Let S be a sample space.  Then $P(S) = 1$ \n",
    "2. For any event A,  $0 \\leq P(A) \\leq 1$\n",
    "3. If A and B are mutually exclusive events, then $P(A \\cup B) = P(A) + P(B)$\n",
    "\n",
    "All the properties of probabilities can be seen as consequences of the \n",
    "axioms 1,2,3.  \n",
    "\n",
    "**For example:**\n",
    " - If $A^{c}$ is the complement of $A \\Rightarrow S = A^{c} \\cup A$; Use 1 and 3 $\\Rightarrow P(A^{c}) = 1- P(A)$\n",
    " - $S^{c} = \\phi \\Rightarrow P(\\phi) = 0$\n",
    "### Example of mutually exclusive events\n",
    "**Example 2.4**\n",
    "\n",
    "A target on a test firing range consists of a bull’s-eye \n",
    "with two concentric rings around it.  A projectile is fired at the target.  The \n",
    "probability that it hits the bull’s-eye is 0.10, the probability that it hits the inner \n",
    "ring is 0.25, and the probability that it hits the outer ring is 0.45.  \n",
    "\n",
    "What is the probability that the projectile hits the target?\n",
    "\n",
    "$0.10 + 0.25 + 0.45 = 0.80$ \n",
    "\n",
    "What is the probability that it misses the target?\n",
    "\n",
    "$1 - 0.80 = 0.20$\n",
    "\n",
    "[See rectangle on slide package 1 (Page 4)](https://reykjavik.instructure.com/courses/6357/pages/lecture-package-1-conditional-probabilities?module_item_id=262176)\n",
    "\n",
    "### Probabilities estimated from data\n",
    "**Examples 2.6-2.7 / p.56**\n",
    "\n",
    "A machine produces Aluminum rods with specified length and diameter.  \n",
    "The length can be:  to short, OK, or too long.\n",
    "\n",
    "The diameter can be: too thin, OK, or too thick. \n",
    "\n",
    "Data for a sample of 1000 rods is shown in the table.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/Ch2/table2-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/logisigurdarson/Documents/HR/2.ár/haustönn/Tölfræði/Workbook/Statistics/Workbook.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/logisigurdarson/Documents/HR/2.%C3%A1r/haust%C3%B6nn/T%C3%B6lfr%C3%A6%C3%B0i/Workbook/Statistics/Workbook.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/logisigurdarson/Documents/HR/2.%C3%A1r/haust%C3%B6nn/T%C3%B6lfr%C3%A6%C3%B0i/Workbook/Statistics/Workbook.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m./datasets/Ch2/table2-1.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/logisigurdarson/Documents/HR/2.%C3%A1r/haust%C3%B6nn/T%C3%B6lfr%C3%A6%C3%B0i/Workbook/Statistics/Workbook.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39mrename(index\u001b[39m=\u001b[39m{\u001b[39m0\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mToo Short\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mOK\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m2\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mToo Long\u001b[39m\u001b[39m'\u001b[39m})\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/Ch2/table2-1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('./datasets/Ch2/table2-1.csv', header=0)\n",
    "df.rename(index={0:'Too Short', 1:'OK', 2:'Too Long'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the probability that a rod is too short?  \n",
    "\n",
    "    $P(too short) = (10+3+5)/1000 = 0.018$\n",
    "2. What is the probability that a rod is either too short or too thick?\n",
    "    \n",
    "    $P(too thich) = (5+4+13)/1000 = 0.022$\n",
    "    \n",
    "    $P(too short AND too thick) = 5/1000 = 0.005$\n",
    "    \n",
    "    $P(too short OR too thick) = 0.018 + 0.022 - 0.005 = 0.035$\n",
    "\n",
    "### Conditional probability\n",
    "Let A and B be two different events. The probability for A to happen when B is true is called the probability of A conditioned by B, denoted $P(A|B)$.\n",
    "\n",
    "$P(A|B) =$ number of outcomes of A when B is true / number of outcomes of B\n",
    "\n",
    "Multiply and divide the total number of elements in the sample space $\\Rightarrow$\n",
    "\n",
    "$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$ or $P(A \\cap B) = P(A|B) * P(B)$\n",
    "\n",
    "If we exchange A and B, because $P(A \\cap B) = P(B \\cap A) \\Rightarrow$\n",
    "\n",
    "**Bayes' rule:**\n",
    "\n",
    "$P(A|B)P(B) = P(B|A)P(A)$\n",
    "\n",
    "Bayes' rule is very useful in practical situations when data corresponds to the condition B true, but the interest is rather in the condition A true. \n",
    "\n",
    "In practise the probabilities are almost always conditioned by the available information, which is the data or knowledge about the specific process. \n",
    "\n",
    "The sample space in this case is not the total sample space, it is only a subset. \n",
    "\n",
    "### Independent events\n",
    "Two events are **independant** if the probability of each event remains the same whether or not the other occurs. \n",
    "\n",
    "$P(A|B) = P(A), P(B|A) = P(B)$\n",
    "\n",
    "For independent events we have the multiplication rule:\n",
    "\n",
    "$P(A \\cap B) = P(A)P(B)$\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "1. Throw a die two times. What is the probability to have face 1 up both times? Does the second throw depend on the first throw? **No**.\n",
    "\n",
    "    $P(first\\,1 \\cap second\\,1) = P(first\\,1) P(second\\,1) = (\\frac{1}{6})^2$\n",
    "\n",
    "2. (Example 2.20 (Page 72)) Look at the data for the Aluminum rods. Show that $P(too \\, long \\mid too \\, thin) = P(too \\, long) = 0.04$\n",
    "\n",
    "    $$\n",
    "    P(too\\,long) = \\frac{(2 + 25 + 13)}{1000} = 0.04 \\\\ \\\\\n",
    "\n",
    "    P(too\\,thin) = \\frac{(10 + 38 + 2)}{1000} = 0.05 \\\\ \\\\\n",
    "    \n",
    "    P(too\\,long \\cap too\\,thin) = \\frac{2}{1000} = 0.002 \\\\ \\\\\n",
    "    \n",
    "    P(too\\,long \\mid too\\,thin) = \\frac{0.002}{0.05} = \\frac{2}{50} = 0.04\n",
    "    $$\n",
    "\n",
    "    Apparently too long and too thin are independent events, while we know that too short and too thick are not independent. In practise this result may be real for the whole population of rods, but it may also be limited to the sample of 1000 rods used. To clarify one has to increase the sample size, or perform more advanced statistical tests. \n",
    "\n",
    "### The muliplication rule for more events\n",
    "If A, B, C, D, ... are independent events then $P(A \\cap B \\cap C \\cap D \\cap ...) = P(A)P(B)P(C)P(D)...$\n",
    "\n",
    "**Example 2.23:**\n",
    "\n",
    "Of the microprocessors manufactured by a certain process, 20% are defective. Five microprocessors are chosen at random. Assum the function independently. What is the probability the all work?\n",
    "\n",
    "$$\n",
    "P(one\\, works) = 1 - 0.2 = 0.8 \\\\\n",
    "P(all\\,five\\,work) = (1 - 0.2)^5\n",
    "$$\n",
    "### Law of total probability\n",
    "Imagine an event B which can be seen as a combination (partition) of some other events $A_1, A_2, A_3,...,$ which are mutually exclusive. but they cover all possible occurrences of B. \n",
    "\n",
    "If so, $P(B) = \\sum_i P(B \\mid A_i)P(A_i)$\n",
    "\n",
    "Partition example: $S = A_1 \\cup A_2 \\cup A_3$ and $A_1 \\cap A_2 \\cap A_3 = \\phi$\n",
    "\n",
    "$B = (B \\cap A_1) \\cup (B \\cap A_2) \\cup (B \\cap A_3)$\n",
    "\n",
    "$P(B) = (B \\cap A_1) + (B \\cap A_2) + (B \\cap A_3)$\n",
    "\n",
    "$P(B) = P(B \\mid A_1)P(A_1) + P(B \\mid A_2)P(A_2) + P(B \\mid A_3)P(A_3)$ \n",
    "\n",
    "\n",
    "**Example:** Pic a random kennitala ID of a student registered to the course. The probability that the student is in the problem solving group H1 is:\n",
    "\n",
    "$P(H1) = P(H1 \\mid girl)P(girl) + P(H1 \\mid boy)P(boy) = \\sum_{field\\,of\\,study} P(H1 \\mid field\\,of\\,study)P(field\\,of\\,study)$\n",
    "\n",
    "Here we assume each student is registered in only one field of study. \n",
    "\n",
    "Mutually exclusive $\\Rightarrow$ not independent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2.26 (page 80)**\n",
    "- The proportion of people in a given community who have a certain disease is 0.005. \n",
    "A test is available to diagnose the disease.\n",
    "- If a person has the disease, the probability that the test will produce a positive \n",
    "signal is 0.99. If a person does not have the disease, the probability that the test will \n",
    "produce a positive signal is 0.01.\n",
    "- If a person tests positive, what is the probability that the person actually has the \n",
    "disease?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "A person has the disease D with probability: $P(D) = 0.005$  \n",
    "$P(nD) = 1 - P(D) = 0.995$ is the probability of not having the disease: (nD = nonD or $D^c$) \n",
    "\n",
    "A person tests positive with probability:  $P(+)$\n",
    "\n",
    "We also know that $P(+|D) = 0.99$  and $P(+|nD) = 0.01$ \n",
    "\n",
    "We want: $P(D|+)$ \n",
    "\n",
    "Use Bayes' rule:\n",
    "\n",
    "$P(D \\mid +) = P(+ \\mid D)P(D) \\Rightarrow P(D \\mid +) = \\frac{P(+ \\mid D)P(D)}{P(+)}$\n",
    "\n",
    "Use the law of tota probability:\n",
    "\n",
    "$P(+) = P(+ \\mid D)P(D) + P(+ \\mid nD)P(nD)$ where $P(nD) = 1 - P(D)$\n",
    "\n",
    "and obtain: \n",
    "\n",
    "$P(D \\mid +) = \\frac{P(+ \\mid D)P(D)}{P(+ \\mid D)P(D) + P(+ \\mid nD)[1 - P(D)]} = \\frac{0.99 \\times 0.005}{0.99 \\times 0.005 + 0.01 \\times 0.995} = 0.332$\n",
    "\n",
    "**Comment**:\n",
    "We see that only about a third of the people who test positive for the disease actually have the disease. Note that the test is fairly accurate; it correctly classifies 99% \n",
    "of both diseased and non-diseased individuals. The reason that a large proportion of those who test positive are actually disease-free is that the disease is rare—only 0.5% of \n",
    "the population has it. Because many diseases are rare, it is the case for many medical tests that most positives are false positives, even when the test is fairly accurate. For \n",
    "this reason, when a test comes out positive, a second test is usually given before a firm diagnosis is made.  See also problem 2.3.30 in the list of problems for week 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another application of Bayes' rule\n",
    "$P(A \\mid B)P(B) = P(B \\mid A)P(A)$ or $P(A \\mid B) = \\frac{P(A)P(B \\mid A)}{P(A)P(B \\mid A) + P(nA)P(B \\mid nA))} = \\frac{P(B \\mid A)P(A)}{P(B)}$\n",
    "\n",
    "*What is the probability of a smoker to develop lung cancer?*\n",
    "\n",
    "To answer the question we need data and a correct probability setup. \n",
    "\n",
    "**Q: How frequent is smoking in Iceland?**\n",
    "\n",
    "**Google:** Smoking (S) in Iceland is banned in resturants, cafés, bars and night clubs as of June 2007. A large majority of Icelanders approve the ban. At the time the ban went into effect, almost one in four Icelandic people were smokers. $\\Rightarrow P(S) = 0.25$\n",
    "\n",
    "**Q: What fraction of lung cancer is caused by smoking?**\n",
    "\n",
    "**Google:** It has been estimated that active smoking is responsible for 80 percent of lung cancer (LC) cases. $\\Rightarrow P(S \\mid LC) = 0.80$\n",
    "\n",
    "We want to estimate the probability of LC for smokers, which is $P(LC \\mid S)$\n",
    "\n",
    "Use Bayes' rule: $P(LC \\mid S) = \\frac{P(S \\mid LC)P(LC)}{P(S)}$\n",
    "\n",
    "In general we do not know P(LC) because the disease may not have been diagnosed yet. But LC can also develop in no smokers (nS). \n",
    "\n",
    "Use Bayes' rule: $P(LC \\mid nS) = \\frac{P(nS \\mid LC)P(LC)}{P(nS)} = \\frac{[1 - P(S \\mid LC)]P(LC)}{[1 - P(S)]}$\n",
    "\n",
    "Instead of $P(LC \\mid S)$ we can calculate the relative risk:\n",
    "\n",
    "$\\frac{P(LC \\mid S)}{P(LC \\mid nS)} = \\frac{P(S \\mid LC)}{1 - P(S \\mid LC)} \\times \\frac{1 - P(S)}{P(S)} = \\frac{0.8}{0.2} \\times \\frac{0.75}{0.25} = 12$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetics and diseases \n",
    "In a genetics study, the genome (DNA) of a large collection of individuals having a particular disease D is observed (genotyped). Instead of the smoking condition from the previous example of lung cancer consider now a certain gene varient X. The data collected allows the direct estimation of: \n",
    "\n",
    "$P(X \\mid D) = \\frac{The\\,number\\,of\\,patients\\,with\\,the\\,gene\\,X\\,variant}{The\\,number\\,of\\,all\\,patients}$\n",
    "\n",
    "The typical result of such a study is the relative risk of X for the disease: \n",
    "\n",
    "$R = \\frac{P(D \\mid X)}{P(D \\mid nX)} = \\frac{P(X \\mid D)}{1 - P(X\\mid D)} \\frac{1 - P(X)}{P(X)}$\n",
    "\n",
    "P(X) is the unconditional probability (frequency) of the genetic varient X, which is estimated from a seperated set of individuals randomly selected from the population. This is called population controls. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random variables in general\n",
    "Consider the variable X, which:\n",
    "- Can be a two-level variable (also called binary): True/False, Yes/No\n",
    "- Can be a multilevel variable: a colour, a direction, etc.\n",
    "- Can be a sequence of numbers like: 1,2,3,... or 10,20,30,... or 0.3,4.1,4.8,...\n",
    "- Can be a any number in an interval, like (0,1) or (a,b)\n",
    "\n",
    "We assume the X variable takes one or another value at random, and we \n",
    "associate a probability to the event that X has a certain value.\n",
    "\n",
    "### Discrete random variables \n",
    "When flipping a coin the outcomes are one or the other face up.  This is a \n",
    "binary variable (two values): face 1 and face 2, or we could use 0 and 1 (bits). \n",
    "\n",
    "For a fair coin P(face 1) = P(face 2) = 0.5 \n",
    "\n",
    "In general, the probabilities of a binary variable are p and 1-p, where p ∊(0,1)\n",
    "For a fair die the top face 1,...,6  and P(top face = i) = 1/6 for any i = 1,...,6.\n",
    "\n",
    "In the textbook the random variable is often denoted with capital X and a \n",
    "particular outcome with small x.\n",
    "\n",
    "P(X = x) or P(x) is the probability that the outcome of X is x, and it is called the \n",
    "probability distribution function (or the probability mass function), or simply the \n",
    "distribution of X.\n",
    "\n",
    "In all cases $\\sum_i P(X = x_i) = 1$. \n",
    "\n",
    "### Cumulative distribution function\n",
    "**Example (page 93):** The number of flaws (imperfections) in a 1-inch length \n",
    "of copper wire manufactured by a certain process varies from wire to wire.  \n",
    "Overall, 48% of the wires produced have no flaws, 39% have one flaw, 12% \n",
    "have two flaws, and 1% have three flaws.  \n",
    "\n",
    "Denote by X be the number of flaws in a randomly selected piece of wire.  \n",
    "All possible values of X are 0,1,2,3\n",
    "\n",
    "The distribution function is: \n",
    "$P(X = 0) = 0.48$, $P(X = 1) = 0.39$, $P(X = 2) = 0.12$, and $P(X = 3) = 0.01$ \n",
    "\n",
    "The cumulative distribution function of X is the probability that the variable X \n",
    "is less than or equal to a given value x.\n",
    "\n",
    "$F(x) = P(X \\leq x) = \\sum_{x_i \\leq x}P(x_i)$\n",
    "\n",
    "For example: F(1) = 0.48 + 0.39\n",
    "\n",
    "### Mean and variance of a discrete random number \n",
    "Notation for mean: E(x) (E: Expected), $\\mu$ , $\\mu_x$, $<x>$. \n",
    "\n",
    "$E(x) = \\sum_i x_i P(x_i)$\n",
    "\n",
    "Variance: Var(x), V(x), $\\sigma^2$, $\\sigma^2_x$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Var(x) &= E[(x - \\mu)^2] \\\\\n",
    "&= \\sum_i (x_i - \\mu)^2P(x_i) \\\\\n",
    "&= \\sum_i (x^2_i - 2 \\mu x_i + \\mu^2)P(x_i) \\\\\n",
    "&= \\sum_i x^2_i P(x_i) - \\sum_i 2 \\mu x_i P(x_i) + \\sum_i \\mu^2 P(x_i) \\\\\n",
    "&= E(x^2) - 2 \\mu \\sum_i X P(x_i) + \\mu^2 \\sum_i P(x_i) \\\\\n",
    "&= E(x^2) - (E(x))^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$ \\sigma = \\sqrt{E[(x - \\mu)^2]}$ is the standard deviation.\n",
    "\n",
    "The variance is the mean of the square minus the square of the mean. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and variance of a data sample\n",
    "\n",
    "$x: x_1, x_2,..., x_n \\quad P(x_i) = \\frac{1}{n} \\quad E(x) = \\sum_i x_i P(x_i) = \\frac{1}{n} \\sum_i x_i = \\bar{x}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "s^2 &= \\frac{1}{n-1} \\sum_i (x_i - \\bar{x})^2 \\\\\n",
    "&= \\frac{1}{n-1} \\sum_i (x^2_i -2\\bar{x}x_i + \\bar{x}^2) \\\\\n",
    "&= \\frac{1}{n-1} (\\sum_i x^2_i - \\sum_i 2\\bar{x}x_i + \\sum_i \\bar{x}^2) \\\\\n",
    "&= \\frac{1}{n-1} (\\sum_i x^2_i - 2\\bar{x}\\sum_i x_i + n\\bar{x}^2) \\\\\n",
    "&= \\frac{1}{n-1} (\\sum_i x^2_i - n\\bar{x}^2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$ n >> 1 \\qquad s^2 = \\frac{1}{n} \\sum_i x^2_i - \\bar{x}^2 \\Rightarrow s^2 = \\bar{x^2} - \\bar{x}^2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous random variable\n",
    "A random number which can take any value in a certain interval. \n",
    "\n",
    "**Example:** The height of the individuals in the Icelandic population. \n",
    "\n",
    "The probability distribution f(x) is a continuous function of x. \n",
    "\n",
    "The continuous random variable X can never be equal to a given number. Therefore $P(X = a) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"exampleCh2.jpg\" width=\"600\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "  \n",
    "# get the image\n",
    "Image(url=\"exampleCh2.jpg\", width=600, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a continuous RV the probability distribution is also called probability density. \n",
    "\n",
    "In practice a discrete random variable with very many values can be considered continuous. The histogram will have many bins (columns) and will become a continuous function.\n",
    "\n",
    "Length: dx.\n",
    "\n",
    "$P(a - \\frac{dx}{2} \\lt x \\lt a + \\frac{dx}{2}) = dP (x \\approx a)$\n",
    "\n",
    "$dP(x) = f(x)dx \\Rightarrow$ **probability density or distribution function.** \n",
    "\n",
    "Or: $f(x) = \\frac{dP}{dx}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(a \\lt x \\lt b) &= P(a \\leq x \\leq b) \\\\\n",
    "&= \\sum_{x = a}^{x=b} dP(x) \\\\\n",
    "&= \\int_{a}^{b} dP(x) \\\\\n",
    "&= \\int_{a}^{b} f(x) dx\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$P(x_{min} \\lt x \\lt x_{max}) = 1 \\Rightarrow \\int_{x_{min}}^{x_{max}} f(x)dx = 1$ \n",
    "\n",
    "**The normalization condition.**\n",
    "\n",
    "Similar to $\\sum_i P(x_i) = 1$ for discrete random numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cumulatvie distribution function (CDF)\n",
    "\n",
    "The CDF F(a) is the probability that $x \\leq a$. \n",
    "\n",
    "$F(a) = P(x \\leq a) = \\int_{x_{min}}^a f(x) dx$\n",
    "\n",
    "F(a) is the area to the left of a. (See image above). \n",
    "\n",
    "Consequently $P(a \\leq x \\leq b) = F(b) - F(a)$ or the area between a and b. \n",
    "\n",
    "**Properties of CDF**\n",
    "- $F(x) \\gt 0$ because it is a probability. \n",
    "- F(x) always increases when x increases.\n",
    "- $F(x_{min}) = 0$\n",
    "- $F(x_{max}) = 1$ because of the normalization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different types of mean values \n",
    "When we have a limited set of data from a large population, which we call a \n",
    "sample,  $x_1, x_2, ... x_n,$ we use the sample mean:\n",
    "\n",
    "$\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$\n",
    "\n",
    "This is an estimation (or approximation) of the population mean, the best we \n",
    "can have with our data. Usually the notation $\\bar{X}$ reserved for the sample mean.\n",
    "\n",
    "Assuming X a continuous variable, the true population mean should be:\n",
    "\n",
    "$\\mu = \\mu_x = <X> = E(X) = \\int_{x_{min}}^{x_{max}} xP(x) dx$\n",
    "\n",
    "Remember, several notations are used for the population mean: $\\mu, \\mu_x, <X> ,E(x)$. \n",
    "The population mean is the true (or real, or exact) mean value of $X$, but often \n",
    "we do not know it and we have to use instead the estimation $\\bar{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variance is also a mean value\n",
    "The variance (which is the square of the standard deviation) is also a mean \n",
    "value.  The one estimated from a data sample is denoted by $s^2$. \n",
    "\n",
    "$s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2$\n",
    "\n",
    "Remember, we divide the sum by n-1 and not by n because the sum contains \n",
    "n-1 independent terms. \n",
    "\n",
    "The true, population values, often unknown, are denoted by $\\sigma^2, \\sigma_x^2, Var(X), V(X)$.\n",
    "\n",
    "$Var(X) = E[(X - \\mu_x)^2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear combination of RV \n",
    "RV $X = x_1,x_2,...,x_n \\quad P(x_i) = [1,n] \\quad E(X), Var(X)$ are known.\n",
    "\n",
    "RV $Y = y_1,y_2,...,y_m \\quad P(y_j) =b[1,m] \\quad E(Y), Var(Y)$ are known.\n",
    "\n",
    "a, b are constant numbers. Lets create a new random variable:\n",
    "\n",
    "RV $Z = aX + bY$ what is $E(Z) = ?$ and $Var(Z) = ?$\n",
    "\n",
    "This combination is called a linear combination cause we only use first powers. \n",
    "\n",
    "$ax_i + by_j = z_{ij} \\quad P(z_{ij}) = P(x_i \\cap y_j)$ (This is called joined distribution)\n",
    "\n",
    "$\\sum_j P(z_{ij}) = \\sum_j P(x_i \\cap y_j) = P(x_i)$ (law of total probability)\n",
    "\n",
    "$\\sum_i  P(z_{ij}) = \\sum_i P(x_i \\cap y_j) = P(y_j)$ (law of total probability)\n",
    "\n",
    "$\\sum_{ij}  P(z_{ij}) = 1$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(Z)&= \\sum_{ij} z_{ij} P(z_{ij}) \\\\\n",
    "&= \\sum_{ij} (ax_i + by_j)P(x_i \\cap y_j) \\\\\n",
    "&= \\sum_{ij} a \\sum_{ij} x_i P(x_i \\cap y_j) + b \\sum_{ij} y_j P(x_i \\cap y_j) \\\\\n",
    "&= a \\sum_i x_i P(x_i) + b \\sum_j y_j P(y_j) \\\\ \n",
    "&= a E(X) + b E(Y) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$ Var(Z) = E(Z^2) - [E(Z)]^2 \\quad z_{ij} = ax_i + by_j$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(Z^2) &= \\sum_{ij} z^2_{ij} \\\\\n",
    "&= \\sum_{ij} (a^2x^2_i + 2abx_iy_j+ b^2y^2_j) P(z_{ij}) \\\\\n",
    "&= a^2 \\sum_i x^2_i P(x_i) + 2ab \\sum_{ij} x_i y_j P(z_{ij}) + b^2 \\sum_j y^2_j P(y_j) \\\\\n",
    "&= a^2 E(X^2) + 2ab E(XY) + b^2 E(Y^2)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$[E(Z)]^2 = a^2 [E(X)]^2 + 2ab E(X)E(Y) + b^2 [E(Y)]^2$\n",
    "\n",
    "$Var(Z) = a^2Var(X) + b^2Var(Y) + 2ab [E(XY) - E(X)E(Y)] = Cov(X,Y)$ \n",
    "\n",
    "If X and Y are independant random variables the covariance (Cov(X,Y)) should be 0. $\\Rightarrow Cov(X,Y) = 0$\n",
    "\n",
    "$\\Rightarrow Var(Z) = a^2Var(X) + b^2Var(Y)$\n",
    "\n",
    "We discussed linear combinations (or linear functions) of two random variables, X and Y, of the form $F(X,Y) = aX + bY$ where a, b are constant numbers. \n",
    "\n",
    "Particular cases of linear functions of only on RV can be: \n",
    "\n",
    "$b = 0 \\quad F(X) = aX \\quad or\\, Y = 1 \\quad F(X) = aX + b$\n",
    "\n",
    "Another possibility:\n",
    "\n",
    "$F(X,Y) = aX + bY + c$ where c is another constant number. \n",
    "\n",
    "**In general:** if $X_1, X_2,...,X_n$ are random variables and $c_1, c_2,...,c_n$ are constant numbers, then the random variable $Z = c_1X_1 + c_2X_2 + ... + c_nX_n$ is called a linear combination of $X_1, X_2,...,X_n$. \n",
    "\n",
    "If X, Y are random variables and a, b two constant number then: \n",
    "\n",
    "$E(aX + bY) = aE(X) + bE(Y)$\n",
    "\n",
    "$Var(aX + bY) = a^2Var(X) + b^2Var(Y)$\n",
    "\n",
    "**Particular cases**\n",
    "\n",
    "1. Add a constant b to a random variable X $\\Rightarrow E(X + b) = E(X) + b$ and $Var(X + b) = Var(X)$\n",
    "\n",
    "2. Multiply X with a constant b $\\Rightarrow E(bX) = b E(X)$ and $Var(bX) = b^2Var(X)$\n",
    "\n",
    "3. Add two independant random variables X and Y.\n",
    "\n",
    "$E(X + Y) = E(X) + E(Y)$ and $Var(X + Y) = Var(X) + Var(Y)$ \n",
    "\n",
    "4. Consider the difference X-Y\n",
    "\n",
    "$E(X - Y) = E(X) - E(Y)$ and $Var(X - Y) = Var(X) + Var(Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The covariance of independant variables\n",
    "Let X and Y be two random variables. By definition $Cov(X,Y) = E[(X - \\mu_x)(Y - \\mu_y)]$ where $\\mu_x = E(X)$ and $\\mu_y = E(Y)$ \n",
    "\n",
    "$Cov(X,Y) = E(XY - XE(Y) - E(X)Y + E(X)E(Y) = E(XY) - E(Y)E(X) - E(X)E(Y) +E(X)E(Y)$\n",
    "\n",
    "$\\Rightarrow Cov(X,Y) = E(XY) - E(X)E(Y)$\n",
    "\n",
    "Suppose $X = x_i$ with probability $P(x_i) \\quad i = 1,2,...,n$ and $Y = y_j$ with probability $P(y_j) \\quad j = 1,2,...,m$ \n",
    "\n",
    "$E(XY) = \\sum_{ij} x_iy_j P(x_i \\cap y_j)$ \n",
    "\n",
    "If X and Y are independant $\\Rightarrow P(x_i \\cap y_j) = P(x_i) P(y_j)$ \n",
    "\n",
    "$\\Rightarrow E(XY) = \\sum_{ij} x_iy_j P(x_i)P(y_j) = [\\sum_i x_iP(x_i)][\\sum_j y_jP(y_j)] = E(X)E(Y)$ \n",
    "\n",
    "$\\Rightarrow Cov(X,Y) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sample mean is also a random variable\n",
    "Consider a random variable X with *true* mean $\\mu$ and *true* standard deviation $\\sigma$. We do not know $\\mu$ and $\\sigma$, but we have a limited set of values, for example from a measurement: $x_1,x_2, ... ,x_n$ (a data sample). \n",
    "\n",
    "the sample mean is $\\bar{X} = \\frac{1}{n} \\sum_{i = 1}^n x_i$\n",
    "\n",
    "Suppose we can repeat the n measurements many times. Then we obtain each time a slightly different $\\bar{X}$, because of different data and a finite n. So the sample mean is a random variable itself. \n",
    "\n",
    "Each particular value $x_i$ can be considered a replica of the random variable X with the mean $\\mu$ and the std. $\\sigma$. \n",
    "\n",
    "What are the mean and the standard deviation of $\\bar{X}$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mean and st.dev of the sample mean\n",
    "$\\bar{x} = \\frac{1}{n} \\sum_i x_i = \\frac{1}{n} x_1 + \\frac{1}{n} x_2 + ... + \\frac{1}{n} x_n$\n",
    "\n",
    "$E(ax_1 + bx_2) = aE(x_1) + bE(x_2)$\n",
    "\n",
    "$E(\\bar{x}) = \\frac{1}{n} E(x_1) + \\frac{1}{n} E(x_2) + ... + \\frac{1}{n} E(x_n)$\n",
    "\n",
    "$E(\\bar{x}) = \\mu_{\\bar{x}} = \\mu$\n",
    "\n",
    "$\\sigma_{\\bar{x}} = ?$\n",
    "\n",
    "$Var(ax_1 + bx_2) = a^2Var(x_1) + b^2Var(x_2)$\n",
    "\n",
    "$Var(\\bar{x}) = \\frac{1}{n^2} Var(x_1) + \\frac{1}{n^2} Var(x_2) + ... + \\frac{1}{n^2} Var(x_n) = \\frac{1}{n^2} \\sigma^2 n = \\frac{1}{n} \\sigma^2$ \n",
    "\n",
    "$\\Rightarrow \\sigma_{\\bar{x}} = \\frac{1}{\\sqrt{n}} \\sigma$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result for the mean value of $\\bar{x}$ is expected and does not tell us much. \n",
    "\n",
    "However the result for the std. is very important. It tells us the std. of $\\bar{x}$ is smaller than the std. of the observed data. In other words the mean value of $\\bar{x}$ is more stable than one single observed value $x_i$. \n",
    "\n",
    "**Therefore $\\bar{x}$ is a better estimate of the true (still unknown) mean value $\\mu$ that any individual value $x_i$**\n",
    "\n",
    "The std. of the sample mean is called standard error. We use the standard error to report the uncertainty of the sample mean value. Usually we do not know $\\sigma$, but use instead $\\sigma \\approx s$ (the sample std. dev.) and then $\\sigma{\\bar{x}} = \\frac{s}{\\sqrt{n}}$ where $s^2 = \\frac{1}{n-1} \\sum_i (x_i - \\bar{x})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagation of errors\n",
    "\n",
    "- Measurements are typically imperfect due to limitations of the methods or of the intruments.\n",
    "- The errors in the measurements produce errors in the calculated values that depend on the measurements $\\Rightarrow$ **propagation of errors**\n",
    "- Systematic errors create a bias. For example a mass scale that indicates 5 grams when nothing is placed on the scale. These are *real errors*.\n",
    "- *Real errors* must be avoided or minimized.\n",
    "- Imperfect measurements are not considered real errors, but **uncertainties**. \n",
    "- The uncertainties are random errors and are treated with statistics.\n",
    "- Real errors due to accidentally incorrect measurements may still occur at random. They can create **outliers** in the data that should be checked or discarded.\n",
    "\n",
    "### Uncertainty\n",
    "- The measured value = true value + bias ± uncertainty\n",
    "- The measurement method should minimize the bias and the uncertainty.\n",
    "- Sometimes a bias is known and accepted, and the final result can be corrected.\n",
    "- The true value is typically unknown.\n",
    "- Assuming zero bias, we believe that **The true value = the measured value ± uncertainty**\n",
    "- We consider, empirically, that the uncertainty is the standard deviation of the measured value, seen as a random variable\n",
    "\n",
    "### Accuracy vs. precision \n",
    "- A measurement is accurate if the bias is small \n",
    "- A measurement is precise if the uncertainty is small\n",
    "\n",
    "### The main practical situations\n",
    "\n",
    "**Case 1:** The measurement is done once. Then the uncertainty is given by limitations of the instrument.     \n",
    "\n",
    "**Example:** The lenght of a metal pipe is measured with a regular tape. The measured lenght is approx. 42.3 cm, with a reading uncertainty of ± 1mm . \n",
    "\n",
    "**Case 2:** Suppose several independent measurements can be done. The best value is their mean value and the uncertainty is the standard error. See the dedicated item in this lecture package.\n",
    "\n",
    "**Case 3:**  The variable of interest is a function of one or more measurements. Then we experience the propagation of errors. See another dedicated item in this lecture package.\n",
    "\n",
    "**Case 4:** The variable of interest is a slope or and intercept of a linear fit. This case will be discussed later in the context of liner regression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case of multiple measurements\n",
    "- Consider $x_1, ..., x_n$ ndependent measurements of a (physical) quantity Q.\n",
    "- For example Q is a friction coefficient, or the height of individuals in a population, or the thickness of some metal rods, etc.\n",
    "- All measurements are done in the same conditions, and the differences between them can be attributed to some uncontrollable random factors.\n",
    "- Thus $x_1, ..., x_n$ can be considered the outcome of a random variable X with mean value Q.\n",
    "- The best estimate of Q is the sample mean $\\bar{x}$\n",
    "- How do we estimate the uncertainty of our result? (Remember,that is the std. of Q.)\n",
    "- We have two options, depending on how we estimate the std. of the measurements $x_i$\n",
    "\n",
    "### Method 1: Evaluate the uncertainty of each measurement\n",
    "- We could evaluate the error (or uncertainty, or limitation) of each particular $x_i$ considering the resolution of the instruments and possibly other factors.\n",
    "- In some cases $x_i$ is a result of a calculation, and we need to consider the propagation of errors from the primary measurements to the calculated $x_i$ \n",
    "- Suppose we have the uncertainty of each measurement $x_i$ as  ±$\\sigma_i$\n",
    "- Now we need the uncertainty of $\\bar{x} = \\frac{x_1 + x_2 + ... + x_n}{n}$. This is a **linear combination** of n RVs with coefficients $\\frac{1}{n}$ and we learned that $\\sigma^2_{\\bar{x}} = \\frac{1}{n^2}\\sigma^2_1 + \\frac{1}{n^2}\\sigma^2_2 + ... + \\frac{1}{n^2}\\sigma^2_n$\n",
    "- So the final result is $Q = \\bar{x} \\pm \\sigma_{\\bar{x}}$ where $\\sigma_{\\bar{x}} = \\frac{1}{n} \\sqrt{\\sigma^2_1 + \\sigma^2_2 + ... + \\sigma^2_n}$\n",
    "- all measurements are performed in the same conditions, we can assume that all $\\sigma_i$ are equal (call them $\\sigma$) and if so $\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Consider the measurements a data sample\n",
    "- Instead of evaluating the uncertainty of each measurement (which may not be easy), we could consider $x_1, ..., x_n$ a data sample. \n",
    "- Then, we can use the sample std. $s = \\sqrt{\\frac{1}{n - 1} \\sum_i (x_i - \\bar{x})^2}$ as an estimated uncertainty of each measurement. \n",
    "- So the final result is $Q = \\bar{x} \\pm \\sigma_{\\bar{x}}$ where $\\sigma_{\\bar{x}} = \\frac{s}{\\sqrt{n}}$\n",
    "- This was one of the methods used in the Physics Lab.  However, we cannot use this method with very few measurements because the estimated standard deviation would be poor. A typical (empirical) recommendation is at least 6 measurements, but I prefer 10.\n",
    "- If we have only a few measurements, than we better use Method 1. \n",
    "- If we have enough measurements, the two methods should give the same result. But we should not forget that these are estimates, and not exactly equal. In practice we should report both the method and the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The uncertainty of a function of measured variables \n",
    "x and y are independant RV (random variables) and we have a function U(x,y)\n",
    "\n",
    "We know the standard deviation of x and y. \n",
    "\n",
    "$x = \\mu_x \\pm \\sigma_x \\quad y = \\mu_y \\pm \\sigma_y$\n",
    "\n",
    "Then we would say that:\n",
    "\n",
    "$U = U(\\mu_x, \\mu_y) \\pm \\sigma_u \\quad \\sigma_u = ?$\n",
    "\n",
    "To do that we need to use the results from the calculus. First of all we assume the uncertainties of the measurements are not very big, which is very common. \n",
    "\n",
    "$U(x,y) = U(\\mu_x, \\mu_y) + \\frac{\\delta U}{\\delta x} \\Big|_{x = \\mu_x \\\\ y = \\mu_y} (x - \\mu_x) + \\frac{\\delta U}{\\delta y} \\Big|_{x = \\mu_x \\\\ y = \\mu_y} (y - \\mu_y) + ... $\n",
    "\n",
    "$U = const + a(x - \\mu_x) + b(y - \\mu_y)$ (linear combination of RV)\n",
    "\n",
    "$\\sigma_u^2 = \\sigma_{const}^2 + a^2 \\sigma_{x - \\mu_x}^2 + b^2 \\sigma_{y - \\mu_y}^2 = a^2 \\sigma_{x}^2 + b^2 \\sigma_{y}^2$\n",
    "\n",
    "$\\sigma_u^2 = (\\frac{\\delta U}{\\delta x})^2 \\sigma_x^2 + (\\frac{\\delta U}{\\delta y})^2 \\sigma_y^2$\n",
    "\n",
    "$\\sigma_u = \\sqrt{(\\frac{\\delta U}{\\delta x} \\sigma_x)^2 + (\\frac{\\delta U}{\\delta y} \\sigma_y)^2}$ (formula for the propagation of errors)\n",
    "\n",
    "### Particular cases\n",
    "\n",
    "**Case 1:** U is a function of one single variable, U(x). This means:\n",
    "\n",
    "$\\sigma_u = \\sqrt{(\\frac{\\delta U}{\\delta x} \\sigma_x)^2} = \\Big| \\frac{dU}{dx} \\Big| \\sigma_x \\quad x \\pm \\sigma_x \\quad U \\pm \\sigma_U$\n",
    "\n",
    "1. a) \n",
    "\n",
    "    $U = cx \\quad c = const \\quad \\sigma_U = c \\sigma_x$\n",
    "\n",
    "    $\\frac{dU}{dx} = c$\n",
    "\n",
    "   b) \n",
    "\n",
    "    Area of a square (with sides x) $A = x^2$\n",
    "\n",
    "    $\\sigma_A = \\Big| \\frac{dA}{dx} \\Big| \\sigma_x = 2x \\sigma_x$\n",
    "\n",
    "    Relative uncertainty: $\\frac{\\sigma_A}{A} = \\frac{2x\\sigma_x}{x^2} = \\frac{2\\sigma_x}{x}$\n",
    "\n",
    "    If relative uncertainty of side $\\frac{\\sigma_x}{x} = 1\\%$ then $ \\frac{\\sigma_A}{A} = 2\\%$\n",
    "\n",
    "    c) Volume $V = x^3$ \n",
    "\n",
    "    $\\sigma_V = \\Big| \\frac{dV}{dx} \\Big| \\sigma_x = 3x^2 \\sigma_x$\n",
    "\n",
    "    Relative uncertainty: $\\frac{\\sigma_V}{V} = \\frac{3x^2\\sigma_x}{x^3} = 3\\frac{\\sigma_x}{x} \\Rightarrow \\frac{\\sigma_x}{x} = 1\\%$ then $ \\frac{\\sigma_V}{V} = 3\\%$\n",
    "\n",
    "    d) $U = constant * x^n \\quad \\sigma_U = constant * n x^{n-1} \\sigma_x$\n",
    "\n",
    "    $\\frac{\\sigma_U}{U} = \\frac{const * n x^{n-1} \\sigma_x}{const * x^n} \\Rightarrow \\frac{\\sigma_U}{U} = \\big|n \\big| \\frac{\\sigma_x}{x}$\n",
    "\n",
    "    This means if $\\big| n \\big| \\gt 1 \\Rightarrow \\frac{\\sigma_U}{u} \\gt \\frac{\\sigma_x}{x}$ and $\\big| n \\big| \\lt 1 \\Rightarrow \\frac{\\sigma_U}{u} \\lt \\frac{\\sigma_x}{x}$\n",
    "\n",
    "2. U is function of two variables, U(x,y)\n",
    "\n",
    "    a) Example 3.6 page 171\n",
    "\n",
    "    A surveyor is measuring the perimeter of a rectangular lot. He measures two adjacent sides to be 50.11 ± 0.05 m and 75.21 ± 0.08 m. These measurements are independent. Estimate the perimeter of the lot and find the uncertainty in the estimate.\n",
    "\n",
    "    $x = 50.11 \\pm 0.05$ \n",
    "\n",
    "    $y = 75.21 \\pm 0.08$ \n",
    "\n",
    "    Perimeter $P = 2x + 2y$ \n",
    "\n",
    "    $\\sigma_p^2 = 2^2 \\sigma_x^2 + 2^2 \\sigma_y^2$\n",
    "\n",
    "    $\\sigma_p^2 = (2 \\sigma_x)^2 + (2 \\sigma_y)^2$\n",
    "\n",
    "    b) Area = xy \n",
    "\n",
    "    $\\sigma_A = \\sqrt{(\\frac{\\delta A}{\\delta x} \\sigma_x)^2 + (\\frac{\\delta A}{\\delta y} \\sigma_y)^2} = \\sqrt{(y \\sigma_x)^2 + (x \\sigma_y)^2}$\n",
    "\n",
    "    $\\frac{\\sigma_A}{A} = \\frac{\\sqrt{(y \\sigma_x)^2 + (x \\sigma_y)^2}}{xy} = \\sqrt{(\\frac{\\sigma_x}{x})^2 + (\\frac{\\sigma_y}{y})^2}$\n",
    "\n",
    "    c) $U = const * x^n * y^m$\n",
    "\n",
    "    $\\frac{\\sigma_U}{u} = \\sqrt{(\\big|n\\big| \\frac{\\sigma_x}{x})^2 + (\\big|m\\big|\\frac{\\sigma_y}{y})^2}$\n",
    "    \n",
    "     $\\frac{\\sigma_U}{u} = \\sqrt{(\\big|n\\big| \\frac{\\sigma_x}{x})^2 + (\\big|m\\big|\\frac{\\sigma_y}{y})^2 + (\\big|p\\big|\\frac{\\sigma_z}{z})^2 + ...}$\n",
    "\n",
    "    $\\sigma_U = \\sqrt{(\\frac{\\delta U}{\\delta x_1} \\sigma_{x_1})^2 + (\\frac{\\delta U}{\\delta x_2} \\sigma_{x_2})^2 + ... + (\\frac{\\delta U}{\\delta x_n} \\sigma_{x_n})^2}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative error for a product of powers\n",
    "\n",
    "$U(x,y,z) = x^my^nz^k$ \n",
    "\n",
    "$\\frac{\\delta U}{\\delta x} = mx^{m-1}y^nz^k$\n",
    "\n",
    "$\\frac{\\delta U}{\\delta y} = x^mny^{n-1}z^k$\n",
    "\n",
    "$\\frac{\\delta U}{\\delta z} = x^my^nkz^{k-1}$\n",
    "\n",
    "$\\sigma_U = \\sqrt{(mx^{m-1}y^nz^k \\sigma_x)^2 + (x^mny^{n-1}z^k \\sigma_y)^2 + (x^my^nkz^{k-1} \\sigma_z)^2}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\sigma_U}{U} &= \\frac{1}{x^my^nz^k} \\sqrt{(mx^{m-1}y^nz^k \\sigma_x)^2 + (x^mny^{n-1}z^k \\sigma_y)^2 + (x^my^nkz^{k-1} \\sigma_z)^2} \\\\\n",
    "&=  \\sqrt{(\\frac{mx^{m-1}y^nz^k}{x^my^nz^k} \\sigma_x)^2 + (\\frac{x^mny^{n-1}z^k}{x^my^nz^k} \\sigma_y)^2 + (\\frac{x^my^nkz^{k-1}}{x^my^nz^k} \\sigma_z)^2} \\\\\n",
    "&= \\sqrt{(m \\frac{\\sigma_x}{x}) + (n \\frac{\\sigma_y}{y}) + (p \\frac{\\sigma_k}{k}) }\n",
    "\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The uniform distribution \n",
    "$a \\leq x \\leq b$ \n",
    "\n",
    "$f(x) = const$ \n",
    "\n",
    "$t = 0.3$ \n",
    "\n",
    "The probability of x equaling t is zero. What we are interested in is what is the probability of x being on an interval near t. \n",
    "\n",
    "$dP(0.3 - \\frac{dx}{2} \\leq x \\leq 0.3 + \\frac{dx}{2}) = f(0.3)dx$ \n",
    "\n",
    "$f(x) = \\frac{dP}{dx}$\n",
    "\n",
    "$\\int_{a}^{b} dP = 1 = \\int_{a}^{b} f(x)dx = const \\int_{a}^{b} dx = const (b - a) \\\\ \\Rightarrow f(x) = \\frac{1}{b-a}$\n",
    "\n",
    "$\\mu = E(x) = \\int_{a}^{b} x dP = \\int_{a}^{b} xf(x)dx = \\frac{1}{b - a} \\int_{a}^{b} x dx = \\frac{1}{b - a}\\, \\frac{x^2}{2} \\Big|_a^b = \\frac{b^2 - a^2}{2(a - b)} = \\frac{(b - a)(b - a)}{2(b - a)} \\Rightarrow \\mu = \\frac{b - a}{2}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma^2 &= Var(x)\\\\\n",
    "&= \\mu_{x^2} - (\\mu_x)^2 \\\\\n",
    "&= \\int_{a}^{b} x^2 f(x)dx \\\\\n",
    "&= \\frac{1}{b - a} \\int_{a}^{b} x^2 dx \\\\\n",
    "&= \\frac{1}{b - a}\\, \\frac{x^3}{3} \\Big|_{a}^{b}\\\\\n",
    "&= \\frac{1}{b - a} \\times \\frac{b^3 - a^3}{3} \\\\\n",
    "&= \\frac{(b - a)(b^2 + ab + a^2)}{3(b - a)} \\\\\n",
    "&= \\frac{b^2 + ab + a^2}{3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\sigma^2 = \\frac{b^2 + ab + a^2}{3} - \\frac{b^2 + 2ab + a^2}{4} = \\frac{b^2 - 2ab + a^2}{12} = \\frac{(b - a)^2}{12}$\n",
    "\n",
    "$\\sigma = \\frac{b - a}{2\\sqrt{3}}$\n",
    "\n",
    "$a = 0 \\,\\, b= 1 \\quad 0 \\leq x \\leq 1 \\quad f(x) = 1 \\\\\n",
    "\\mu = 0.5 \\quad \\sigma = \\frac{1}{2\\sqrt{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to combinatorics\n",
    "We have n elements/objects\n",
    "\n",
    "Make groups of k $\\quad 0 \\leq k \\leq n$\n",
    "\n",
    "$x_1, x_2, x_3, ..., x_n$\n",
    "\n",
    "$k = 2$ pairs fix one element $\\Rightarrow n - 1$\n",
    "\n",
    "repeat n times $\\Rightarrow n(n - 1) \\Big| \\Rightarrow \\frac{n(n - 1)}{2}$ \n",
    "\n",
    "$k = 3$ trios \\# pairs * (n - 2)$\\Rightarrow \\frac{n(n - 1)(n - 2)}{3}$\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "n \\\\ k\n",
    "\\end{pmatrix} = \\frac{n(n - 1)(n - 2) ... (n - k + 1)}{1 * 2 * 3 ... * k} = \\frac{n!}{k!(n - k)!}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "n \\\\ 0\n",
    "\\end{pmatrix} = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "n \\\\ n\n",
    "\\end{pmatrix} = 1\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "n \\\\ k\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "n \\\\ n\n",
    "\\end{pmatrix} \n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "6 \\\\ 2\n",
    "\\end{pmatrix} = \\frac{6 * 5}{1 * 2} = 15 \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "6 \\\\ 4\n",
    "\\end{pmatrix} = \\frac{6 * 5 * 4 * 3}{1 * 2 * 3 * 4} = 15\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Formula\n",
    "$(a + b)^n = \\sum_{k = 0}^n \\begin{pmatrix} n \\\\ k \\end{pmatrix} a^k b^{n - k}$\n",
    "\n",
    "$(a + b)^2 = a^2 + 2ab + b^2$\n",
    "\n",
    "$(a + b)^3 = a^3 + 3a^2b + 3ab^2 + b^3$\n",
    "\n",
    "$(a + b)^4 = a^4 + 4a^3b + 6a^2b^2 + 4ab^3 + b^4$\n",
    "\n",
    "$a = b = 1 \\qquad \\sum_{k = 0}^n \\begin{pmatrix} n \\\\ k \\end{pmatrix} = 2^n$ \n",
    "\n",
    "$a = -1 \\quad b = 1 \\qquad \\sum_{k = 0}^n (-1)^k \\begin{pmatrix} n \\\\ k \\end{pmatrix} = 0$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The unreturned ball problem \n",
    "n objects, b are black, w are white\n",
    "\n",
    "$b + w = n$\n",
    "\n",
    "We pick a ball from the box and we do not return it. \n",
    "\n",
    "$P(b_1 \\cap b_2) = ?$\n",
    "\n",
    "**Solution 1 (use conditional probabilities)**\n",
    "\n",
    "$P(b_1) = \\frac{b}{n}$\n",
    "\n",
    "$P(b_2 \\mid b_1) = {b - 1}{n - 1}$\n",
    "\n",
    "$P(b_1 \\cap b_2) = P(b_2 \\mid b_1) \\times P(b_1) = \\frac{b(b - 1)}{n(n - 1)}$\n",
    "\n",
    "**Solution 2 (count pairs)**\n",
    "\n",
    "$P(b_1 \\cap b_2) = \\frac{\\# black\\,pairs}{\\# pairs} = \\frac{\\begin{pmatrix} b \\\\ 2 \\end{pmatrix}}{\\begin{pmatrix} n \\\\ 2 \\end{pmatrix}} = \\frac{\\frac{b(b - 1)}{2}}{\\frac{n(n - 1)}{2}} \\Rightarrow \\frac{b(b - 1)}{n(n - 1)}$\n",
    "\n",
    "$P(b_1 \\cap w_2) = \\frac{b}{n} \\times \\frac{w}{n - 1} + \\frac{w}{n} \\times \\frac{b}{n - 1} = \\frac{2wb}{n(n - 1)}$\n",
    "\n",
    "Pairs: \n",
    "\n",
    "$P(b_1 \\cap w_2) = \\frac{bw}{\\frac{n(n - 1)}{2}} = \\frac{2wb}{n(n - 1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distribution\n",
    "Consider an experiment which can result in one of two outcomes to be called “success” or “failure.”  \n",
    "\n",
    "The probability of a success is $p$ and thus the probability of a failure is then $1 – p$.  \n",
    "\n",
    "This is called a Bernoulli trial with success probability $p$. It can also be called a two-level or a binary \n",
    "process.\n",
    "\n",
    "Let $x$ be the number of successes in a Bernoulli trial.  We have $x = 0$ or $x = 1$\n",
    "\n",
    "So we can see $x$ as a binary random variable with $P(0) = 1 - p$ and $P(1) = p$\n",
    "\n",
    "Mean value: $E(x) = \\mu = p$\n",
    "Variance: $Var(x) = \\sigma^2 = p(1 - p)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial distribution\n",
    "Consider n Bernoulli trials and assume that \n",
    "- The trials are independant\n",
    "- Each trial has the same success probability p\n",
    "- X is the number of successes in n trials\n",
    "\n",
    "The possible values of X are:$0,1,2,...,n$. The *probability distribution* of X is called the binomial distribution with parameters n and p denoted as Bin(n,p).\n",
    "\n",
    "We specify that X has a binomial distribution with the notation X ~ Bin(n,p)\n",
    "\n",
    "The probability that X has a specific value $k = 0,1,2,...,n$ is:\n",
    "\n",
    "$P(X = k) = \\begin{pmatrix} n \\\\ k \\end{pmatrix} p^k (1 - p)^{n - k}$\n",
    "\n",
    "These are independant events so $P(A \\cap B) = P(A)P(B)$\n",
    "\n",
    "$0 \\leq k \\leq n$\n",
    "\n",
    "$P(X = 0) = (1 - p)^n$\n",
    "\n",
    "$P(X = 1) = p(1 - p)^{n - 1} n$\n",
    "\n",
    "$P(X = 2) = p^2 (1 - p)^{n - 2} \\begin{pmatrix} n \\\\ 2 \\end{pmatrix} \\quad \\quad \\begin{pmatrix} n \\\\ 2 \\end{pmatrix} = \\frac{n(n - 1)}{2}$\n",
    "\n",
    "$P(X = 3) = p^3 (1 - p)^{n - 3} \\begin{pmatrix} n \\\\ 3 \\end{pmatrix}$\n",
    "\n",
    "$\\sum_{k = 0}^n \\begin{pmatrix} n \\\\ k \\end{pmatrix} p^k (1 - p)^{n - k} = [p + (1 - p)]^n = 1^n = 1$\n",
    "\n",
    "### Mean and variance of the binomial distribution\n",
    "X ~ Bin(n,p)\n",
    "\n",
    "$\\mu_x = \\sum_{k = 0}^n k P(k) =\\sum_{k = 0}^n \\begin{pmatrix} n \\\\ k \\end{pmatrix} p^k (1 - p)^{n - k}$\n",
    "\n",
    "$s = 0,1$ number of successes per trial \n",
    "\n",
    "$s = 1$ with p\n",
    "\n",
    "$s = 0$ with 1 - p\n",
    "\n",
    "$\\mu = 1 * p + 0 * (1 - p) = p$\n",
    "\n",
    "$\\sigma^2 = 1^2 p + 0^2 (1 - p) - p^2 = p - p^2 = p(1 - p)$\n",
    "\n",
    "n-trials $\\Rightarrow X = s_1 + s_2 + ... + s_n$\n",
    "\n",
    "$\\mu_x = \\mu + \\mu + ... + \\mu = np$\n",
    "\n",
    "$\\sigma^2_x = \\sigma^2 + \\sigma^2 + ... + \\sigma^2 = np(1 - p)$\n",
    "\n",
    "$\\sigma_x = \\sqrt{np(1 - p)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a box with a large number of coloured balls and we want to find \n",
    "experimentally the probability that a ball is black.  We pick one ball at a time and we put \n",
    "it back, in total n times.  The number of times the ball was black is a random variable of \n",
    "binomial type X ~ Bin(n, p).  In this example the success at one attempt is getting a \n",
    "black ball, and that occurs with probability p.\n",
    "\n",
    "Although we do not know p, we can estimate (approximate) it as $\\hat{p} = \\frac{X}{n}$ where X is the *observed value* of the binomial variable. What is the uncertainty of this estimated value?\n",
    "\n",
    "Remember the properties of linear combinations of RV’s : \n",
    "\n",
    "$\\hat{p} = \\frac{X}{n} \\Rightarrow Var(\\hat{p}) = \\frac{1}{n^2} Var(X)$ or $\\sigma_{\\hat{p}} = \\frac{1}{n} \\sigma_X$\n",
    "\n",
    "We know that  X ~ Bin(n, p) has std: \n",
    "\n",
    "$\\sigma_X = \\sqrt{np(1 - p)}$ where p is the unknown exact \n",
    "value. Using now $p \\approx \\hat{p}$ we obtain $\\sigma_{\\hat{p}} = \\frac{1}{n} \\sigma_X \\approx \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$\n",
    "\n",
    "So we can say that p = estimated value $\\pm$ uncertainty $= \\hat{p} \\pm \\sigma_{\\hat{p}}$\n",
    "\n",
    "Instead of calling $\\hat{p}$ estimated probability we can call it an estimated proportion, \n",
    "depending on the interpretation of this number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distribution\n",
    "- Consider a random variable X with binomial distribution Bin(n,p) \n",
    "- Consider n very large and p very small, but such that λ=np is not too large\n",
    "(Let’s say λ < 100)\n",
    "\n",
    "In these conditions the binomial distribution becomes (see next notes in this lecture \n",
    "package)\n",
    "\n",
    "$P(k) = \\frac{\\lambda^k}{k!} e^{–\\lambda} \\quad where\\, k = 0,1,2,...,n$\n",
    "\n",
    "and it is called the Poisson distribution.  It depends on one parameter (λ), whereas the \n",
    "Binomial distribution depends on two parameters (n, p).\n",
    "\n",
    "The mean (E(k) or $\\mu$) and the variance (or $\\sigma^2$) of the Poisson distribution are:\n",
    "\n",
    "$E(k) = \\lambda$ and $Var(k) = \\lambda \\Rightarrow (std.)\\, \\sigma = \\sqrt{\\lambda}$\n",
    "\n",
    "**The interpretation of the λ parameter is the mean (or average) number of successes \n",
    "in a very large binomial process.**\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "Because a Poisson random variable is a discrete number $k=0,1,2 ...,n$ the \n",
    "(mass) distribution (function) can be represented with a histogram.  Here we \n",
    "see P(k)  for λ= 1.  Or P(k, λ= 1).\n",
    "\n",
    "Inspect the histogram visually and observe the mean value:\n",
    "\n",
    "$E(k) = \\sum_k kP(k) = \\lambda = 1$ \n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "Here we see P(k)  for λ= 10.  Or P(k, λ= 10).  \n",
    "\n",
    "Inspect the histogram visually and observe the mean value:\n",
    "\n",
    "$E(k) = \\sum_k kP(k) = \\lambda = 10$\n",
    "\n",
    "Observe also that the distribution is now wider than before.\n",
    "Because the std. is now $\\sqrt{10} = 3.2$ instead of 1 like before.\n",
    "\n",
    "Always remember the definition of the **cumulative distribution function (CDF):**\n",
    "\n",
    "$F(X) = \\sum_{k \\leq X} = \\sum_{k \\leq X} \\frac{\\lambda^k}{k!} e^{–\\lambda}$\n",
    "\n",
    "### Comparing Binomial and Poisson distributions\n",
    "Poisson is a Binomial distribution with a large number of trials n and a small probability \n",
    "of success in one single trial p.  See the tables below.  For Poisson λ = np. When n \n",
    "increases or p decreases or the numbers are closer and closer. (See slides Week 5)\n",
    "\n",
    "If we know n and p, yes. However, when n is large the computer will do \n",
    "approximations of the binomial  coefficients, such that in practice it will give you \n",
    "Poisson. But, usually, in a Poisson process n and p are not known.  See next the example \n",
    "with radiation.  The radiation in the surrounding environment can be described \n",
    "with Poisson distribution.   But there is no information on how much radiation is in \n",
    "total (that would be n) and what is the probability of one radiation event (that \n",
    "would be p).  All we can do is to measure the mean value (λ) and use only this \n",
    "number, so we can only use Poisson.  And forget about n, p, and Binomial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More math on the Poisson distribution\n",
    "**-derivation** \n",
    "\n",
    "Start with the binomial distribution $P(k) = \\begin{pmatrix} n \\\\ k \\end{pmatrix}p^k(1-p)^{n - k} \\quad 0 \\leq k \\leq n$\n",
    "\n",
    "Consider n large and p small, and denote $\\lambda = np$ \n",
    "$$\n",
    "\\begin{align}\n",
    "P(k) &= \\frac{n!}{k!(n - k)!}(\\frac{\\lambda}{n})^k (1 - \\frac{\\lambda}{n})^{n - k} \\\\\n",
    "&= \\frac{n!}{(n - k)!n^k} \\frac{\\lambda^k}{k!}(1 - \\frac{\\lambda}{n})^{n - k}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\frac{n!}{(n - k)!k!} = \\frac{1 * 2 * 3 ... n}{1 * 2 * 3 ... n - k} \\frac{1}{n^k} = \\frac{(n - k + 1)(n - k + 2)...n}{n^k} \\rightarrow 1$ when $n \\rightarrow \\infty$\n",
    "\n",
    "$(1 - \\frac{\\lambda}{n})^{n - k} = [(1 - \\frac{\\lambda}{n})^{\\frac{n}{\\lambda}}]^\\lambda (1 - \\frac{\\lambda}{n})^{-k} = (\\frac{1}{e})^\\lambda 1^{-k} \\rightarrow e^{-\\lambda}$ when $n \\rightarrow \\infty$\n",
    "\n",
    "$\\Rightarrow$ for n large $P(k) = \\frac{\\lambda^k}{k!} e^{–\\lambda}$ where $k = 0,1,2,...,n$\n",
    "\n",
    "**-normalization:**\n",
    "\n",
    "$\\sum_{k = 0}^\\infty P(k) = e^{-\\lambda} \\sum_{k = 0}^\\infty \\frac{\\lambda^k}{k}$ (Taylor series of $e^\\lambda) = e^{-\\lambda} e^\\lambda = 1$\n",
    "\n",
    "**-mean value:**\n",
    "$\\mu = \\sum_{k = 0}^\\infty kP(k) = e^{-\\lambda} \\sum_{k = 0} k \\frac{\\lambda^k}{k!} = e^{-\\lambda}S_1$ where \n",
    "\n",
    "$S_1 = \\sum_{k = 0}^\\infty k \\frac{\\lambda^k}{k!} = \\sum_{k = 1} \\frac{\\lambda^k}{(k - 1)!} = \\sum_{k = 0}^\\lambda \\frac{\\lambda^{k + 1}}{k!} = \\lambda \\sum_{k = 0}^\\infty \\frac{\\lambda^k}{k!} = e^\\lambda$\n",
    "\n",
    "$\\Rightarrow \\mu = \\lambda$\n",
    "\n",
    "**-variance**\n",
    "$\\sigma^2 = \\sum_{k = 0}^\\infty k^2 P(k) - \\mu^2 = e^{-\\lambda} \\sum_{k = 0} k^2 \\frac{\\lambda^k}{k!} - \\mu^2$\n",
    "\n",
    "$S_2 = \\sum_{k = 1} k^2 \\frac{\\lambda^k}{k!} = \\sum_{k = 1} k \\frac{\\lambda^k}{(k - 1)!} = \\sum_{k = 0} (k + 1) \\frac{\\lambda^{k + 1}}{k!} = \\lambda(\\sum_{k = 0} k \\frac{\\lambda^k}{k!} + \\sum_{k = 0} \\frac{\\lambda^k}{k!}) = \\lambda (\\lambda e^\\lambda + e^\\lambda)$\n",
    "\n",
    "$\\Rightarrow \\sigma^2 = e^{-\\lambda}\\lambda (\\lambda e^\\lambda + e^\\lambda) - \\lambda^2 = \\lambda^2 + \\lambda - \\lambda^2$\n",
    "\n",
    "$\\Rightarrow \\sigma^2 = \\lambda$ or $\\sigma = \\sqrt{\\lambda}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radiation (Poisson conclusion)\n",
    "- The radiation events can be well described by the Poission distribution\n",
    "- To do that we need the mean number of radiation events (or particles) in a fixed time interval T\n",
    "- The mean number $\\lambda$ can be measured with a radiation detector or can be calculated\n",
    "- Once we know $\\lambda$ the probability of k radiation events in the Time T is:\n",
    "\n",
    "Probability of (k events in time T) = Poisson(k,$\\lambda$) = $\\frac{\\lambda^k}{k!} e^{-\\lambda}$  $k = 0,1,2,...,\\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the normal distribution\n",
    "- The **normal distribution** (also called the Gaussian distribution) is by far the \n",
    "most commonly used distribution in statistics.  \n",
    "- It provides a good model for many, although not all, continuous populations.\n",
    "- It is a continuous (and not discrete) distribution and the random variable x \n",
    "may have any value from $]-\\infty, \\infty[$\n",
    "- Graphically it is a bell-shaped curve \n",
    "(sometimes called Gauss’ bell).\n",
    "\n",
    "### The basic idea of the normal distribution\n",
    "The normal distribution is the distribution of sample means, seen as random \n",
    "variables.\n",
    "\n",
    "*The key idea:*  Consider a sample of numbers $x_1,x_2, ...,x_n$ for example with \n",
    "uniform distribution between 0 and 1. Calculate their sample mean $\\bar{x}$. Repeat \n",
    "this process many times. The distribution of all the sample means has a peak \n",
    "around the theoretically expected mean value $\\mu = 0.5$. \n",
    "\n",
    "The numbers $x_1,x_2, ...,x_n$ do not need to have a uniform distribution, they can \n",
    "also have a binomial or Poisson, or anything.  What is important is that they all \n",
    "come from the same distribution. And if so, their sample means have a normal \n",
    "distribution.\n",
    "\n",
    "**The fact that the sample means have a normal distribution is the famous \n",
    "Central Limit Theorem (CLT).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The normal distribution N($\\mu,\\sigma^2$)\n",
    "The probability density function is:\n",
    "\n",
    "$f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{- \\frac{(x - \\mu)^2}{2\\sigma^2}},\\, \\quad x \\in (-\\infty, \\infty)$\n",
    "\n",
    "- By definition it depends on TWO parameters denoted as $\\mu$ and $\\sigma$\n",
    "- When a random variable X obeys the normal distribution we write: X ~N($\\mu, \\sigma^2$)\n",
    "- Observe that in the notation N($\\mu, \\sigma^2$) we have $\\sigma^2$ and not $\\sigma$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean value and variance of the normal distribution\n",
    "A fundamental result from Math 2: \n",
    "\n",
    "$\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}$\n",
    "\n",
    "Using this result one can show the following results (textbook pages 251-252):\n",
    "\n",
    "1. The normalization condition is true:\n",
    "\n",
    "    $\\frac{1}{\\sigma \\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty}e^{- \\frac{(x - \\mu)^2}{2\\sigma^2}} dx = 1$\n",
    "\n",
    "2. The mean value $E(x) = \\mu_x = \\mu$\n",
    "3. The variance $Var(x) = \\sigma_x^2 = \\sigma^2$ or the standard deviation $\\sigma_x = \\sigma$\n",
    "\n",
    "**So now we have the interpretation of the two parameters of the distribution \n",
    "function: μ is the mean value and σ is the std.  That is what the notation \n",
    "anticipated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The standard normal distribution\n",
    "The normal distribution with $\\mu = 0$ and $\\sigma = 1$, or N(0,1), is called the \n",
    "*standard normal distribution*, the density function being:\n",
    "\n",
    "$$ f(x) = \\frac{1}{2\\pi}e^{- \\frac{x^2}{2}}$$\n",
    "\n",
    "We will often use the so-called z-score which is $z = \\frac{x - \\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between binomial and Poisson distributions \n",
    "Consider  an  integer  random  variable  k  with  binomial  distribution k  ~  Bin(n,p). k  is  the \n",
    "numbers of “successes” out of n trials, and p is the probability of “success” in one trial.  The \n",
    "mean value of the Binomial is np and the std. is $\\sqrt{np(1 - p)}$\n",
    "\n",
    "If $n$ is large and $p$ is small we use instead Poisson with parameter $\\lambda = np$.  How large and how \n",
    "small, that depends on the situation. In principle we could use Poisson as an approximation of \n",
    "the Binomial, for example for $n = 100$ and $p = 0.1$ or so.  Obviously, when $n$ is even larger and $p$ \n",
    "is even smaller, the approximation is better and better. But remember also that in the Binomial \n",
    "distribution $k$ runs between $0$ and $n$, whereas in the Poisson it is between 0 and $\\infty$\n",
    "\n",
    "The Poisson distribution should be used when either $n$ or $p$ are unknown.  Like in the radiation \n",
    "example.  When what we know,  or what we can measure, is only the mean value $\\lambda$.  If so, we \n",
    "have k ~ Poisson($\\lambda$).      \n",
    " \n",
    "Remember also, the variance of Poisson is $\\lambda$ or the std. is $\\sqrt{\\lambda}$ A simple way to understand this \n",
    "result is to look at the std. for the Binomial and consider a very small $p$, much smaller than 1.  \n",
    "Then $1 – p \\approx 1$ and the std. of the Binomial becomes that of Poisson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The normal approximation of the binomial distribution \n",
    "Suppose now only n is large in the Binomial distribution, but p is not necessarily small.  Then \n",
    "the number of successes k ~ Bin(n,p) can have very many values. If so it is like a histogram \n",
    "with very many bins, and we could compare the Binomial with a normal distribution with mean \n",
    "np and std. $\\sqrt{np(1 - p)}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The lognormal distribution\n",
    "A random variable $x \\gt 0$ has a lognormal distribution x ~ LN, when its natural logarithm has a normal distribution: ln(x) ~$N(\\mu, \\sigma^2)$\n",
    "\n",
    "Or, the other way: if $y = ln(x)$ and y ~ $N(\\mu, \\sigma^2)$ then $x = e^y ~LN(\\mu, \\sigma^2$\n",
    "\n",
    "Another notation x ~ Lognormal($\\mu\\,,\\sigma^2$)\n",
    "\n",
    "**ATTENTION:** $\\mu$, $\\sigma^2$ are mean value and variance of the **normal** distribution associated to the lognormal, but they are also used as parameters for the lognormal. So be careful, they are **not** the mean value and variance of the lognormal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lognormal probability density function (PDF)\n",
    "if x ~ LN($\\mu$, $\\sigma^2$) then the PDF f(x) is:\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sigma x \\sqrt{2\\pi}} exp[-\\frac{(ln(x) - \\mu)^2}{2\\sigma^2}], \\quad x \\gt 0$$\n",
    "\n",
    "Using this f(x) one obtains the mean and the variance:\n",
    "\n",
    "Mean value $E(x) =e^{\\mu + \\frac{\\sigma^2}{2}}$\n",
    "\n",
    "Variance $Var(x) = e^{2\\mu + 2\\sigma^2} - [E(x)]^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness of a distribution\n",
    "Relationship of mean and median\n",
    "\n",
    "If the distribution is symmetric the distribution has zero skewness and mean = median. \n",
    "If not, often the mean value is skewed to the left/right of a typical centre of the data. \n",
    "\n",
    "It is tempting to believe that the mean is smaller/larger than the median for a left/right \n",
    "skewed distribution.  But this is not necessarily true, for example in multimodal \n",
    "distributions, or in many discrete distributions, both inequalities are possible for the \n",
    "same kind of skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The exponential distribution\n",
    "The probability density of the Exp distribution describes a continuous and positive random \n",
    "variable $x \\gt 0$ using a parameter $λ \\gt 0$. \n",
    "\n",
    "$f(x) = \\lambda e^{-\\lambda x}$ and we write x ~ Exp($\\lambda$)\n",
    "\n",
    "Check the normalization condition: $\\int_{0}^{\\infty} f(x) dx = 1$ (Meaning the sum of all probabilities = 1)\n",
    "The basic result needed is $\\int_{0}^{\\infty} e^{-\\lambda x} dx = \\frac{1}{\\lambda}$. Take the derivative of this result with respect to $\\lambda$ to obtain the mean value $\\mu = \\int_{0}^{\\infty} xf(x)dx$. Take one more deritative with respect $\\lambda$ to find the mean value of $x^2$ which is needed in the variance $\\sigma^2$  Performing these calculations one obtains the mean value equal to the standard deviation: \n",
    "\n",
    "$$\\mu = \\sigma = \\frac{1}{\\lambda}$$\n",
    "\n",
    "It is easy to calculate the cumulative function $F(x) = \\int_{0}^{\\infty} f(x^{'}) dx^{'} = 1 - e^{-\\lambda x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The connection with the Poisson distribution\n",
    "The exponential distribution is a model for the waiting time between “rare” events which \n",
    "follow a Poisson distribution.  Remember that k ~ Poisson(λ) means that the probability of k \n",
    "events is:\n",
    "\n",
    "$$P(k) = \\frac{\\lambda^k}{k!}e^{-\\lambda}$$\n",
    "\n",
    "We know that $\\lambda$ is the expected or mean number of events.  We usually count such events in a \n",
    "certain time interval. Remember the radiation example, when we used intervals of 5 seconds. Then, if  $\\lambda$ is the expected number of events per time unit, in a time t we have $\\lambda t$ events. And then, in this time t, we have k events with probability   \n",
    "\n",
    "$$P(k) = \\frac{(\\lambda t)^k}{k!}e^{-\\lambda t}$$\n",
    "\n",
    "Now, the probability of having no event in time t corresponds to k=0, and that probability is:\n",
    "\n",
    "$$P(0) = \\frac{(\\lambda t)^0}{0!}e^{-\\lambda t} = e^{-\\lambda t}$$\n",
    "\n",
    " \n",
    "We can interpret this result as the probability that the time needed until we observe $k = 1$ \n",
    "event is t.  Which is the waiting time until that moment. This result looks similar to the Exp \n",
    "distribution, only that we need to normalize it, according to the sum of all probabilities being \n",
    "1 . To do that multiply with a constant and fix that constant such that the integral over all \n",
    "times, from 0 to infinity, is 1. And we obtain that constant equal to $\\lambda$, and thus the Exp \n",
    "distribution $f(x) = \\lambda e - \\lambda x$.  In conclusion, the waiting time t between Poisson events with \n",
    "rate $\\lambda$ follows an exponential distribution with parameter $\\lambda$,  t ~ Exp($\\lambda$).  See Problem 4.7.11 in the textbook, page 271. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The case of distances between random locations on a surface \n",
    "Instead of counting events per time, we can also count events per distance, like the number of \n",
    "holes in the asphalt per kilometre, and so we can replace the time with distance.  Assuming \n",
    "the mean number of holes per kilometre is $\\lambda$ (or per another length unit, depending on the \n",
    "specific case), then the distance d between consecutive holes, or another kind of random \n",
    "locations, follows an exponential distribution,  d ~ Exp($\\lambda$).  See Problem 4.2 at page 318 of \n",
    "the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimates\n",
    "*Estimates*,  or *estimated* values, are approximations of statistical parameters \n",
    "using the observed (or existing) data. The formula used for obtaining an \n",
    "estimated value is called *estimator*. \n",
    "\n",
    "They can be more or less accurate, depending on the available data, and on \n",
    "the estimation method used.\n",
    "\n",
    "**Examples:**\n",
    "- The sample mean $\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n x_i$ \n",
    "- The sample variance  $s^2 = \\frac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar{x})^2$\n",
    "- The probability of a binary event using the Binomial distribution\n",
    "- The correlation coefficient obtained from data, Chapter 7\n",
    "- The regression coefficients (or the parameters of the best line), Chapter 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to compare the estimate with the true (or exact) value\n",
    "- Consider $\\theta$ the true (or the exact, or the real), but unknown value of a parameter\n",
    "- We denote by $\\bar{\\theta}$ an estimated value, obtained with a certain estimator, using the available data.\n",
    "- $\\bar{\\theta}$ is seen as a random variable (like the sample mean or sample variance), with mean value $E(\\bar{\\theta})$ or $\\mu_{\\bar{\\theta}}$ and variance $Var(\\bar{\\theta})$ or $\\sigma_{\\bar{\\theta}}$\n",
    "- The standard deviation of an estimator is usually called *standard error*\n",
    "- $\\mu_{\\bar{\\theta}} − \\theta = E(\\bar{\\theta}) − \\theta$ is called bias. Ideally, we would like the mean value of $\\bar{\\theta}$ to be equal to the exact value $\\theta$, but if not we say that the estimator is *biased*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is an estimator?\n",
    "- The goodness of an estimator is evaluated by the mean squared error:\n",
    "\n",
    "$$MSE_{\\bar{\\theta}} = (\\mu_{\\bar{\\theta}} - \\theta)^2 + \\sigma_{\\bar{\\theta}}^2 = \\mu_{(\\bar{\\theta} - \\theta)^2}$$\n",
    "- Or, with the alternative E and Var notations:\n",
    "\n",
    "$$MSE(\\bar{\\theta}) = [E(\\bar{\\theta}) - \\theta]^2 + Var(\\bar{\\theta}) = E[(\\bar{\\theta} - \\theta)^2]$$\n",
    "- To show that these two expressions are equivalent expand the powers in the left  form and obtain the right form\n",
    "- The MSE looks like the variance of the estimate (or estimator) $\\bar{\\theta}$ relatively to the exact (or true) value $\\theta$\n",
    "- In principle, the smaller the MSE the better the estimate is, but not always see the example of the sample standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4.67:  The estimated probability from the Binomial distribution \n",
    "- Consider a binary variable = 1 (success) or = 0 (failure). The number of successes x in n trials have Binomial distribution: x~Bin(n,p)\n",
    "- We do one experiment and we observe x successes. Then we estimate the probability of one success as $\\bar{p} = \\frac{x}{n}$\n",
    "- Is $\\bar{p} = \\frac{x}{n}$ a biased estimator? In other words is $E(\\bar{p}) = p$?\n",
    "$$E(\\bar{p}) = E(\\frac{x}{n}) = \\frac{1}{n}E(x) = \\frac{1}{n}np = p \\Rightarrow \\bar{p} \\quad is\\,unbiased$$\n",
    "- Remember: $Var(x) = np(1 − p) \\Rightarrow Var(\\bar{p}) = \\frac{p(1 - p)}{n}$ \n",
    "- We see that $MSE(\\bar{p}) = [E(\\bar{p}) - p]^2 + Var(\\bar{p}) = \\frac{p(1 - p)}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The example of the sample variance $s^2$\n",
    "Consider a limited set of values (a sample) of a random variable x with $\\mu$\n",
    "and $\\sigma$ the true (or exact) mean and std.\n",
    "\n",
    "Using the properties of linear combinations of random variable we can easily show that the sample mean $\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n x_i$ is an unbiased estimator for $\\mu$\n",
    "\n",
    "Let’s concentrate on the sample variance $s^2 = \\frac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar{x})^2$\n",
    "\n",
    "Why we use $\\frac{1}{n - 1}$ and not $\\frac{1}{n}$? Let's use the notation $\\bar{\\sigma}^2 = \\frac{1}{n} \\sum_{i = 1}^n (x_i - \\bar{x})^2$.\n",
    "\n",
    "We can see both $s^2$ and $\\bar{\\sigma}^2$ as estimators for the true variance $\\sigma^2$. \n",
    "\n",
    "But we can show that $\\bar{\\sigma}^2$ is *biased*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E[\\sum_{i = 1}^n (x_i - \\bar{x})^2] &= E[\\sum_{i = 1}^n (x_i - \\mu + \\mu - \\bar{x})^2] \\\\\n",
    "&= E[\\sum_{i = 1}^n (x_i - \\mu)^2 + 2(x_i - \\mu)(\\mu + \\bar{x}) + (\\mu - \\bar{x})^2] \\\\\n",
    "&= E[\\sum_{i = 1}^n (x_i - \\mu)^2] + 2E[n(\\bar{x} - \\mu)(\\mu - \\bar{x})] + E[n(\\mu - \\bar{x})^2] \\\\\n",
    "&= \\sum_{i = 1}^n E[(x_i - \\mu)^2] - nE[(\\mu - \\bar{x})^2] \\\\ \n",
    "&= n \\sigma^2 - \\sigma^2 \\\\\n",
    "&= (n - 1)\\sigma^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We see now that if we use $s^2 = \\frac{1}{n} \\sum_{i = 1}^n (x_i - \\bar{x})^2$ we obtain $E(s^2) = \\frac{1}{n} E[\\sum_{i = 1}^n (x_i - \\bar{x})^2] = \\frac{n - 1}{n} \\sigma^2 \\neq \\sigma^2$, meaning that this estimator of the sample variance is biased.\n",
    "\n",
    "Instead, the unbiased estimator is $s^2 = \\frac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar{x})^2$ since in this case $E(s^2) = \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bessel correction \n",
    "Using $\\frac{1}{n - 1}$ instead of $\\frac{1}{n }$ in the estimator of the sample variance $s^2$ is called \n",
    "Bessel correction. \n",
    "\n",
    "We see now that Bessel correction is used to make $s^2$ an *unbiased* estimator of the true (but often unknown) variance of the random variable x.\n",
    "\n",
    "Bessel correction also has to do with the number of *independent* terms in the sum: because we subtract the sample mean we have $n - 1$ independent terms and not n.  Check with $n = 2$, you get two equal terms, which are not independent. So if we see $s^2$ as an average of independent squared deviations, we should divide by $n-1$.\n",
    "\n",
    "But of course, in practice, if n is large enough there is no big difference \n",
    "between $\\frac{1}{n - 1}$ and $\\frac{1}{n}$ \n",
    "\n",
    "Considering now x ~ N($\\mu,\\sigma^2$) , after a pretty long, but straight forward \n",
    "calculation, we can obtain the variance and the mean squared error for $s^2$\n",
    "\n",
    "$$MSE(s^2) = Var(s^2) = \\frac{2\\sigma^4}{n - 1}$$\n",
    "\n",
    "because the bias is 0. We can also calculate the corresponding result for $\\bar{\\sigma}^2$\n",
    "\n",
    "$$MSE(\\bar{\\sigma}^2) = \\frac{(2n - 1)\\sigma^4}{n^2}$$\n",
    "\n",
    "Interestingly, although $\\bar{\\sigma}^2$ is biased, MSE($\\bar{\\sigma}^2$) $\\lt$ MSE($s^2$) Does this mean we \n",
    "should use $\\bar{\\sigma}^2$ instead of $s^2$ as an estimator for the true variance?  Not in this \n",
    "case, the unbiased estimator $s^2$ is still preferred. Observe also that we used x ~ N($\\mu,\\sigma^2$), whereas in general we do not know the distribution of the data.  \n",
    "\n",
    "But in other cases the fact that a bias may reduce the MSE of an estimator is \n",
    "important, for example in machine learning.\n",
    "\n",
    "We will show soon that $\\bar{\\sigma}^2$ is in fact the maximum likelihood estimator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation methods \n",
    "- There are various methods to estimate parameters, more or less intuitive.\n",
    "- One of the most powerful and important is the method of maximum likelihood\n",
    "- The likelihood theory is a more advanced and deeper way to connect probabilities with observed data, using Bayes rule, and it is often named Bayesian statistics\n",
    "- The alternative, considered more rigid, is called the frequentist approach, when the probabilities are seen as proportions, rather than estimates.\n",
    "- This classification is more about the interpretation of the concept of probability, and often goes into a philosophical direction.\n",
    "- Practical data analyses combines ideas from both directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The likelihood function\n",
    "- Consider $\\theta$ a parameter to be obtained from data\n",
    "- Both data and the estimated parameter have a random character, so we can treat them as events\n",
    "- According to Bayes rule:\n",
    "$$P(\\theta | data) = \\frac{P(data | \\theta) P(\\theta)}{P(data)}$$\n",
    "- In Bayesian statistics $P(\\theta)$ is called the prior probability and $P(\\theta | data)$ is called posterior probability\n",
    "- The interpretation of the likelihood function is the probability of the observed data given the parameter $\\theta$. Or as a function of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximum likelihood method of estimation\n",
    "- The basic assumption is that the observed data corresponds to a maximum probability as a function of the parameter $\\theta$\n",
    "- That means we have to maximize the likelihood function $L(\\theta) = P(data | \\theta)$\n",
    "$$\\frac{d}{d\\theta}L(\\theta) = 0$$\n",
    "- The solution of this equation is an estimated value of  our the parameter, denoted as $\\bar{\\theta}$ and called the maximum likelihood estimator or MLE.\n",
    "- In practice it is often more convenient to use the log-likelihood function, \n",
    "which is $ln(L(\\theta))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate a probability using the ML method\n",
    "sucess = 1      failure = 0     p = ? for success\n",
    "\n",
    "n trials        k ~ Bin(n,p)    282-283 textbook\n",
    "\n",
    "$k_1$ successes in 1 experiment     $k_1 = data$\n",
    "\n",
    "$P(k_1) = \\begin{pmatrix} n \\\\ k_1 \\end{pmatrix} p^{k_1}(1 - p)^{n - k_1} = P(data | p) = L(p)$\n",
    "\n",
    "$max\\,L(p) \\quad \\frac{dL}{dP} = 0 \\Rightarrow p = \\hat{p}$\n",
    "\n",
    "Use $ln(L) instead of L: $\\frac{d}{dP} ln(L) = 0$\n",
    "\n",
    "$ln(L) = ln\\begin{pmatrix} n \\\\ k_1 \\end{pmatrix} + ln(p^{k_1}) + ln((1 - p)^{n - k_1}) = ln\\begin{pmatrix} n \\\\ k_1 \\end{pmatrix} k_1 ln(p) + (n - k_1) ln(1 - p)$\n",
    "\n",
    "$\\frac{d}{dP}ln(L) = \\frac{k_1}{p} - (n - k_1) \\frac{1}{1 - p} = 0 \\quad \\frac{k_1}{p} = \\frac{n - k_1}{1 - p} = k_1(1 - p) = p(n - k_1) \\Rightarrow \\hat{p} = \\frac{k_1}{n}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two experiments: $k_1\\,,k_2$ successes = data \n",
    "\n",
    "$P(data | p) = P(k_1 \\cap k_2 | p) = P(k_1)P(k_2) = L(p)$\n",
    "\n",
    "$L(p) = \\begin{pmatrix} n \\\\ k_1 \\end{pmatrix} p^{k_1}(1 - p)^{n - k_1} \\begin{pmatrix} n \\\\ k_2 \\end{pmatrix} p^{k_2}(1 - p)^{n - k_2}$\n",
    "\n",
    "$\\frac{dL}{dP} = 0 \\Longleftrightarrow \\frac{d ln(L)}{dP} = 0$\n",
    "\n",
    "$ln(L) = ln\\begin{pmatrix} n \\\\ k_1 \\end{pmatrix} k_1 ln(p) + (n - k_1) ln(1 - p) + ln\\begin{pmatrix} n \\\\ k_2 \\end{pmatrix} k_2 ln(p) + (n - k_2) ln(1 - p)$\n",
    "\n",
    "$\\frac{d}{dP}ln(L) = \\frac{k_1}{p} - (n - k_1) \\frac{1}{1 - p} + \\frac{k_2}{p} - (n - k_2) \\frac{1}{1 - p} = \\frac{k_1 + k_2}{p} = \\frac{n - k_1 + n - k_2}{1 - p} = (k_1 + k_2)(1 - p) = p(2n - k_1 - k_2$\n",
    "\n",
    "$\\Rightarrow \\hat{p} = \\frac{k_1 + k_2}{2n} = \\frac{\\bar{k}}{n}$ MLE of p\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap. on the uncertainty of a population mean\n",
    "- Consider $x_1,x_2,...,x_n$ *independent* random variables with the same distribution that we do not necessarily know.\n",
    "- All $x_i$ variables have the same mean value $\\mu$ and variance $\\sigma^2$, **but unknown**\n",
    "- The sample mean $\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n(x_i - \\bar{x})^2$ is our best estimate for $\\sigma^2$\n",
    "- Central limit theorem: If n is sufficiently large then $\\bar{x}$ ~N($\\mu, \\frac{\\sigma^2}{n}$)\n",
    "- Then we conclude $\\mu = \\bar{x} \\pm \\sigma_{\\bar{x}}$ where $\\sigma_{\\bar{x}} \\approx \\frac{s}{\\sqrt{n}}$ is the *estimated* std. of $\\bar{x}$ which is also call *uncertainty*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From uncertainty to intervals\n",
    "- We want to transform the evaluation of the uncertainty as $\\mu = \\bar{x} \\pm Z_{score} \\sigma_{\\bar{x}}$ into an interval that captures $\\mu$:\n",
    "\n",
    "$$\\mu \\in [\\bar{x} - \\sigma_{\\bar{x}}, \\bar{x} + \\sigma_{\\bar{x}}]$$\n",
    "\n",
    "- In this case we can say that the true or exact, but unknown number $\\mu$, is in the mentioned interval with a probability p. How much is p?\n",
    "- The confidence interval is an interval between two estimated numbers which includes the true value of a parameter with a certain probability.\n",
    "- Alternatively, we can also consider:\n",
    "\n",
    "$$\\bar{x} \\in [\\mu - \\sigma_{\\bar{x}}, \\mu + \\sigma_{\\bar{x}}]$$\n",
    "\n",
    "- In this case we can say that our estimate is $\\pm$ one std. away from the true (or \n",
    "exact) mean value with probability p. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 68% Confidence intervals (CI)\n",
    "- The interval of $\\pm$ one std. around the mean value of a normal distribution \n",
    "corresponds to 68% probability (or area). We will call this interval the 68% CI\n",
    "- **Exercise:** Obtain this number yourselves.  Chose any numbers you want for \n",
    "$\\mu$ and $\\sigma$ and show that  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other confidence intervals\n",
    "- In general the 68% CI associated with $\\pm$ one std. is mostly used by engineers\n",
    "- Statisticians prefer a higher probability, most often 95% , sometimes 99%\n",
    "- How do we find these intervals in terms of the standard deviation σ of the normal distribution ?  By using the percentile function, qnorm or NORM.INV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the 95%CI\n",
    "We can always convert the random variable x into a z-score $z = \\frac{x - \\mu}{\\sigma}$ and we know that z~N(0,1)\n",
    "\n",
    "We want the 95%CI. That means the left and right tails outside this interval correspond to $\\frac{1 - 0.95}{2}$ each one.\n",
    "\n",
    "R: qnorm(0.05/2,0,1) = -1.96   Exercise: qnorm(1-0.05/2,0,1) = ? \n",
    "\n",
    "$(100 - \\alpha)\\%CI = [\\bar{x} - Z_{\\frac{\\alpha}{2}} \\sigma_{\\bar{x}}, bar{x} + Z_{\\frac{\\alpha}{2}} \\sigma_{\\bar{x}}]$\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "$z \\in [-1.96, 1.96]$ with 95% probability\n",
    "\n",
    "Or $x \\in [\\mu - 1.96\\sigma, \\mu + 1.96\\sigma]$ with 95% probability\n",
    "\n",
    "Or $\\mu \\in [x - 1.96\\sigma_{x}, x + 1.96\\sigma_{x}]$\n",
    "\n",
    "Or use $\\bar{x}$ instead of x if it represents a sample mean\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Show that the 99%CI corresponds to $\\mu \\in [x - 2.58\\sigma_{x}, x + 2.58\\sigma_{x}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general (see also textbook p. 326-327)\n",
    "$100(1 - \\alpha)%$ CI corresponds to the interval $x \\pm z_{\\frac{\\alpha}{2} \\sigma_{\\bar{x}}}$ Here $\\alpha$ represents the probability that $\\mu$ is outside the CI\n",
    "- $\\alpha = 0.32 \\Rightarrow z_{\\frac{\\alpha}{2}} = 1 \\quad$  68% CI\n",
    "- $\\alpha = 0.10 \\Rightarrow z_{\\frac{\\alpha}{2}} = 1.645 \\quad$ 90% CI\n",
    "- $\\alpha = 0.05 \\Rightarrow z_{\\frac{\\alpha}{2}} = 1.96 \\quad$  95% CI (the most common)\n",
    "- $\\alpha = 0.01 \\Rightarrow z_{\\frac{\\alpha}{2}} = 2.58 \\quad$  99% CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible scenarios\n",
    "Consider a 95% CI: There are 95% chances that the exact mean value is captured by the 95%CI\n",
    "\n",
    "There are still 5% chances that the exact mean value lies outside the 95%CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chi-square distribution\n",
    "- Let $z_1,z_2,...,z_k$ be independent random variables, all with the standard normal distribution N(0,1)\n",
    "- Consider the random variable $X = z_1^2 + z_2^2 + ... + z_k^2$\n",
    "- Then X ~ $\\chi_k^2$ called Chi-square distribution with k degrees of freedom (DOF)\n",
    "- This distribution has the probability density function\n",
    "$$f(x) = \\frac{1}{2^{\\frac{k}{2}} \\Gamma(\\frac{k}{2})} x^{\\frac{k}{2} - 1} e^{- \\frac{x}{2}},\\quad x \\lt 0$$\n",
    "- the mean value $\\mu = k$\n",
    "- the std. $\\sigma = \\sqrt{2k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Maxwell-Boltzmann distribution(s)\n",
    "- Distribution of velocities and kinetic energies of molecules in a gas\n",
    "- The distribution of velocities in the x direction in a normal distribution\n",
    "$$ f(v_x) = (\\frac{m}{2\\pi kT})^{\\frac{1}{2}} e^{-\\frac{m v_x^2}{2kT}}$$\n",
    "- $k = 1.38 \\times 10^{-23}$ J/K is Boltzmann‘s constant and T is the temperature in Kelvin\n",
    "- The kinetic energy $E = \\frac{1}{2}mv^2 = \\frac{1}{2}m(v_x^2 + v_y^2 + v_z^2)$ is a sum of 3 random \n",
    "variables and has a Chi-squared distribution with 3 degrees of freedom $\\chi^2_3$\n",
    "$$f(E) = 2 (\\frac{E}{\\pi})^{\\frac{1}{2}} (\\frac{1}{kT})^{\\frac{3}{2}} e^{-\\frac{E}{kT}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R and Excel functions\n",
    "R:  \n",
    "\n",
    "dchisq(x,k)   the distribution function\n",
    "\n",
    "pchisq(x,k)   the cumulative function \n",
    "\n",
    "qchisq(p,k)   the quantile (or percentile) function\n",
    "\n",
    "rchisq(n,k)    a random number generator of n numbers ~χk2\n",
    "\n",
    "Excel:  CHISQ.DIST(x,k,cumulative=T or F) \n",
    "\n",
    "CHISQ.INV(p,k)\n",
    "\n",
    "CHISQ.INV(RAND(),k)  the random number generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer simulation of Chi square distribution\n",
    "1. Generate random numbers ~ N(0,1) with the computer\n",
    "\n",
    "    *Method 1*: generate samples with uniform dist. and get their sample means, as \n",
    "    you did until now in R or Excel\n",
    "\n",
    "    *Method 2*: In R, use rnorm(n,0,1) and you have n numbers with N(0,1).  \n",
    "\n",
    "    *Method 3*: In R, use qnorm(runif(n,0,1),0,1) , meaning you input a random number between 0 and 1 and qnorm will convert it into a percentile. In Excel this method is the only possibility, use NORM.INV(RAND(), 0, 1)\n",
    "\n",
    "2. Now, add the squares of k random numbers ~N(0,1) to obtain one random number with Chi square distrib. with k degrees of freedom (DOF)\n",
    "\n",
    "3. In R use rchisq(n,k) to generate n random numbers with Chi sq. dist with k \n",
    "DOF.  In Excel use CHISQ.INV(RAND(),k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The distribution of the sample variance\n",
    "- We want the distribution of the sample variance $s^2 = \\frac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar{x})^2$\n",
    "- Let's assume now that all $x_i$ ~ N($\\mu, \\sigma^2$)\n",
    "- Consider the random variable $r = \\frac{(n - 1)s^2}{\\sigma^2} = \\sum_{i = 1}^n \\frac{(x_i - \\bar{x})^2}{\\sigma^2} = \\sum_{i = 1}^n z_i^2$\n",
    "- We used the \"z-score\" $z_i = \\frac{x_i - \\bar{x}}{\\sigma}$ considering $\\bar{x} \\approx \\mu \\Rightarrow z_i$ ~ $N(0,1) \\Rightarrow r$ ~ $\\chi^2_{n - 1}$: Chi square with n - 1 DOF\n",
    "- NOTE: we only have n - 1 DOF because we always subtract the mean, and thus we add together only n - 1 independant random number $z_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 95% probability interval for r\n",
    "- We learned before how to build a CI for the true population mean value $\\mu$ using the normal distribution of the sample mean $\\bar{x}$.\n",
    "- We want now a 95% CI for the true variance $\\sigma^2$, using the distribution of the sample variance $s^2$, which does not have a normal distribution\n",
    "- But we know that the number $r = \\frac{(n - 1)s^2}{\\sigma^2}$ ~ $\\chi^2_{n - 1}$\n",
    "- See **Example 5.28** in the text book\n",
    "\n",
    "To find the confidence interval of sigma we use: \n",
    "\n",
    "$5.629 \\lt \\frac{(n - 1)s^2}{\\sigma^2} \\lt 26.119$ where the lower and upper 0.025 points of $\\chi^2_{14}$ are:\n",
    "\n",
    "$\\chi^2_{14, 0.975} = 26.119$\n",
    "\n",
    "$\\chi^2_{14, 0.025} = 5.629$\n",
    "\n",
    "$\\Rightarrow \\frac{(n - 1)s^2}{26.119} \\lt \\sigma^2 \\lt \\frac{(n - 1)s^2}{5.629}$ take squareroot of both sides to get 95% CI for sigma\n",
    "\n",
    "In general for any CI of sigma: \n",
    "\n",
    "$(\\sqrt{\\frac{(n - 1)s^2}{\\chi_{n - 1, \\frac{\\alpha}{2}}^2}}, \\sqrt{\\frac{(n - 1)s^2}{\\chi_{n - 1, 1 - \\frac{\\alpha}{2}}^2}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to hypothesis testing | problem 4.7.6\n",
    "Someone claims that the waiting time in minutes, between hits at a certain website has the exponential distribution with parameter $\\lambda = 1$. Let T be the witing time until the next hit. \n",
    "\n",
    "a) If the claim is true, what is $P(T \\geq 5)$\n",
    "\n",
    "$$P(T \\geq 5) = 1 - F(5) = 1 - (1 - e^{-\\lambda * 5}) = 0.00674$$\n",
    "\n",
    "b) Based on the answer to part (a), if the claim is true, is 5 minutes an unusually long time to wait? Remember the mean waiting time is $\\frac{1}{\\lambda}$\n",
    "\n",
    "The null hypothesis $\\qquad H_0: \\lambda = 1$\n",
    "\n",
    "The alternative hypothesis $\\qquad H_1: \\lambda < 1$\n",
    "\n",
    "P-value = $P(5 \\geq X) = 0.00674$\n",
    "\n",
    "**Conclusion:** Yes, T = 5 min is unusually long, and if this is the only data point we have, most likely $H_0$ is not correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large-sample test for a population mean\n",
    "A car engine emits a mean of $\\mu = 100$ mg NOx per second. A modification of the engine may reduce emissions. A sample of $n = 50$ modified engines yield a sample mean $\\bar{x} = 92$ mg/s with sample std. dev. $s = 21$ mg/s\n",
    "\n",
    "*The problem:* Is $\\bar{x}$ really lower than $\\mu$? Or is it only a sample fluctuation effect?\n",
    "\n",
    "The *null hypothesis* or $H_0:$ the new mean emission is still 100 mg/s\n",
    "\n",
    "The *alternative hypothesis* or $H_1:$ the new mean is less than 100 mg/s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the null hypothesis is tested\n",
    "We know that $\\bar{x}$ ~ N($\\mu, \\sigma^2$) with $\\sigma_{\\mu_x} = \\frac{s}{\\sqrt{n}} = 2.970$\n",
    "\n",
    "Assuming $H_0$ true $\\mu = 100$ mg/s\n",
    "\n",
    "We use the Z-score: z ~ N(0,1) $\\quad z = \\frac{\\bar{x} - \\mu}{\\sigma_{\\bar{x}}} = -2.69$\n",
    "\n",
    "The *left sided* P-value = norm.cdf(z, 0, 1) = 0.0036\n",
    "\n",
    "The conventional signifincance level is 0.05 and our p-value is < 0.05\n",
    "\n",
    "*Conclusion*\n",
    "\n",
    "The reduction of the NOx is *significant*\n",
    "\n",
    "Therefore $H_0$ is rejected and $H_1$ should be accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the direction of the test\n",
    "Suppose now $\\bar{x} = 105$ mg/s\n",
    "\n",
    "Let's change $H_1:$ the new mean is *greater* than $\\mu = 100$ mg/s\n",
    "\n",
    "The new Z-score: $z= \\frac{\\bar{x} - \\mu}{\\sigma_{\\bar{x}}} = 1.35$\n",
    "\n",
    "The *right sided* P-value = $1 -$ norm.cdf(z, 0, 1) = 0.089 > 0.05\n",
    "\n",
    "**Conclusion**\n",
    "In this case the modified engines have an *increased emission* of NOx. However that is statistically not *significant*. Therefore $H_0$ is accepted or $H_1$ is rejected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 2-sided test (preferred)\n",
    "A scale is to be calibrated by weighing a 1000 g test weight $n = 60$ times. The scale readings have mean $\\bar{x} = 1000.6$ g and standard deviation $s = 2$ g\n",
    "\n",
    "Test $H_0: \\mu = 1000$ g versus $H_1: \\mu \\neq 1000 g$.\n",
    "\n",
    "Assuming $H_0$ is true $\\quad \\bar{x}$ ~ N($\\mu, \\sigma^2$) where $\\sigma_{\\bar{x}} = \\frac{s}{\\sqrt{n}}$\n",
    "\n",
    "Calculate the z-score: $z = \\frac{\\bar{x} - \\mu}{\\sigma_{\\bar{x}}} = 2.324$\n",
    "\n",
    "According to $H_1$ we must look at both tails of the distribution. \n",
    "\n",
    "P-value = 2 * norm.cdf(-z, 0, 1) = 2 * 0.0102 = 0.0204 < 0.05\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "The probability bias of absolute value 0.6 or larger to occur purely by chance is 0.02. Therefore the bias of the scale is significant. We reject the null and accept the alternative. The scale should be recalibrated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The connection with the confidence interval \n",
    "We can calculate the 95% CI for the *true mean* value of the measurements\n",
    "\n",
    "[$\\bar{x} - 1.96 \\sigma_{\\bar{x}}$, $\\bar{x} + 1.96 \\sigma_{\\bar{x}}$] = [1000.094, 1001.106]\n",
    "\n",
    "We can see that the real mass of 1000g is outside the 95% CI. That means there are at least 95% chances the scale is biased. Or at most 5% chances that the observed bias is only a result of randomness\n",
    "\n",
    "However, a complete hypothesis must report a p-value\n",
    "\n",
    "**Important**\n",
    "\n",
    "It is not enough only to conclude a statistical test with \"significant\" and \"not significant\". A complete result must report a p-value. The lower the p-value the more convincing the significance. A p-value larger than 0.05 may still indicate something, if we already have other information about the behavior of the data. Other researchers may prefer a lower significance threshold and they need your p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-sided vs 2-sided tests\n",
    "- If the alternative hypothesis is $H_1: \\mu > \\mu_0$ then the P-value is the area to the right of z. \n",
    "- If the alternative hypothesis is $H_1: \\mu < \\mu_0$ then the P-value is the area to the left of z. \n",
    "- If the alternative hypothesis is $H_1: \\mu \\neq \\mu_0$ then the P-value is the sum of the areas in the tails cut off by z and -z. \n",
    "- In practical statistics a 2-sided test is usually preferred\n",
    "- One reason is that most often there should be no preliminary expectation on the observed sample mean.\n",
    "- A second reason is that the p-value for a 2-sided test is larger (typically double) than for a 1-sided test and thus the significance, if that exists, is more convincing. \n",
    "- In practical statistics a 1-sided test may be accepted in a replication experiment, when the direction of the result was found in a previous study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in performing a hypothesis test\n",
    "First understand the data.  Then:\n",
    "- Define $H_0$ and $H_1$  also known as null and alternative hypotheses\n",
    "- Assume $H_0$ to be true\n",
    "- Compute a test statistic.  A test statistic is a number that is assumed to obey the distribution implied by $H_0$\n",
    "- Compute the P-value corresponding the test-statistic number\n",
    "- Conclude: reject or accept $H_0$ (or accept or reject $H_1$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on the p-value\n",
    "- The p-value is the probability that the disagreement between the two hypotheses $H_0$ and $H_1$ is even greater than observed\n",
    "- **The p-value is not the probability that $H_0$ is true !!!**\n",
    "- The P-value measures the validity of $H_0$ or $H_1$\n",
    "- If the P-value is sufficiently small, we reject $H_0$ and possibly accept H\n",
    "- The conventional threshold is $p = 0.05$ \n",
    "- If $p < 0.05$ the difference between the two hypotheses is called significant. We reject $H_0$ which looks unlikely.\n",
    "- If $p \\approx 0.05$ we have to be careful, the case is marginally (borderline) significant.  In practice we need more information, larger sample, etc.\n",
    "- If $p \\gt 0.05$ the difference between $H_0$ and  $H_1$ is not significant, it should be attributed to chances, randomness, data noise, and we have to accept $H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for population proportions\n",
    "- A supplier of semiconductor wafers claims that no more than 10% of his wafers are defective. \n",
    "- A sample of n = 400 wafers is tested, and k = 50 of them are defective. \n",
    "- Can we conclude that supplier’s claim is false?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The implementation of the 5-step scheme\n",
    "First understand the data.  The observed proportion of the defective samples is $\\hat{p} = \\frac{k}{n} = 0.125, which is  also an estimated probability that a sample is defective.  Remember the standard deviation of an estimated proportion (or \n",
    "the “uncertainty of a probability”) $\\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1 - p)}{n}}\n",
    "\n",
    "**Step 1** Define $H_0$ and $H_1$\n",
    "\n",
    "$H_0:$ the real proportion is $p = 0.1$  (as claimed by the producer) \n",
    "\n",
    "$H_1:$ the real proportion is $\\gt 0.1$ \n",
    "\n",
    "**Step 2** Assume $H_0$ to be true\n",
    "\n",
    "If $H_0$ would be true the estimated proportion $\\hat{p}$ ~ N($p,\\sigma_{\\hat{p}}^2$)\n",
    "\n",
    "**Step 3** Compute a test statistic\n",
    "\n",
    "The test statistic $z = \\frac{\\hat{p} - p}{\\sigma_{\\hat{p}}} =1.67$\n",
    "\n",
    "This number follows the distribution N(0,1) \n",
    "\n",
    "**Step 4** Compute the P-value\n",
    "\n",
    "p-value = 1 - pnorm(z,0,1) = 0.0475 (this is a one-sided or one-tailed test) Remember, the p-value is the probability that the proportion of defective wafers is even larger than the observed value 0.125, or z > 1.67 (Do not confuse the p-value with the p used for the proportion) \n",
    "\n",
    "**Step 5** Conclude \n",
    "\n",
    "The observed larger proportion is only marginally significant.  We may still trust the producer, but with some level of reservation, and we should do further testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z tests\n",
    "- When the z score ~ N(0,1) is being used, the test is called a z test.\n",
    "- Z tests that we already covered:\n",
    "    - Large sample test of a population mean\n",
    "    - Large sample test of a population proportion\n",
    "- We still need to go over a z test of the difference between the sample means of two large samples when the normal distribution is appropriate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the difference between two means, large sample case\n",
    "A sample of 544 inclusions in welds made using argon shielding averaged 0.37 $\\mu m$ in diameter, \n",
    "with a standard deviation of 0.25 $\\mu m$. A sample of 581 inclusions in welds \n",
    "made using carbon dioxide shielding averaged 0.40 $\\mu m$ in diameter, with a \n",
    "standard deviation of 0.26 $\\mu m$. Can you conclude that the mean diameters of \n",
    "inclusions differ between the two shielding gases?\n",
    "\n",
    "Sample 1: $n_x$ = 544 inclusions with mean $\\bar{x}$= 0.37 and st.dev. $s_x$= 0.25 micron\n",
    "\n",
    "Sample 2: $n_y$ = 581 inclusions with mean $\\bar{x}$= 0.40 and st.dev. $s_y$= 0.26 micron\n",
    "\n",
    "D = the difference between the two sample means = $\\bar{x} - \\bar{y}$ seen as random numbers \n",
    "\n",
    "*The null hypothesis* $H_0$: $D = 0$   \n",
    "\n",
    "*The alternative hypothesis* $H_1$: $D \\neq 0$   \n",
    "\n",
    "*The distribution* of D: As we know the sample means of large samples have normal distributions. Since the two samples are independent the difference of their means D has also a normal distribution. According to $H_0$ the mean (or \n",
    "expected) value of D is $\\mu_D = 0$. The variance of D is (linear comb. of RV’s) \n",
    "\n",
    "$$\\sigma^2_D = \\sigma_{\\bar{x}}^2 + \\sigma_{\\bar{y}}^2 = \\frac{s^2_x}{n_x} + \\frac{s^2_y}{n_y}$$\n",
    "\n",
    "So we have  D ~ N($0,\\sigma^2_D$)\n",
    "\n",
    "The z score for D: $z = \\frac{D - \\mu_D}{\\sigma_D} = \\frac{\\bar{x} - \\bar{y} - 0}{\\sqrt{\\frac{s^2_x}{n_x} + \\frac{s^2_y}{n_y}}} = -1.97$\n",
    "\n",
    "This is a 2-sided test. We are testing whether $\\bar{x} \\neq \\bar{y}$ without considering which one is larger or smaller.\n",
    "\n",
    "The 2-sided p-value = 2 * norm.cdf(-z,0,1) = 0.0488\n",
    "\n",
    "The p-value is marginal.  $H_0$ could be rejected, but the best would be to increase the sample sizes. Or at least one of them.\n",
    "\n",
    "**Exercise:** Try to increase the sample sizes one at a time and repeat the test.  \n",
    "Calculate again the p-value and conclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048838370560445085\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "print(2 * norm.cdf(-1.97, 0 ,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The t distribution \n",
    "Consider $x_1,x_2,...,x_n$ *independant* random variables with sample mean $\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n x_i$ and with sample variance $s^2 = \\frac{1}{n - 1} \\sum_{i = 1}^n (x_1 - \\bar{x})^2$\n",
    "\n",
    "- If **n is large** we know that $z = \\frac{\\bar{x} - \\mu}{\\sigma_{\\bar{x}}} = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}$ ~ N(0,1) and in practice, if we do not know the true std. $\\sigma$ we use $s \\approx \\sigma$\n",
    "- **But how large n should be? And what if n is small ?**\n",
    "- Instead of z, consider the random variable $\\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}$ \n",
    "    - It can be shown that if all $x_i$ have normal distribution, this variable does not have a normal distribution, but another one called t distribution with $n - 1$ degrees of freedom.\n",
    "- But when n is large enough, then t becomes z which has N(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The t probability density\n",
    "- The t distribution is also called Student’s distribution. \n",
    "- The probability density function (PDF) for n degrees of freedom is: \n",
    "$$f(t) = \\frac{\\Gamma (\\frac{n + 1}{2})}{\\sqrt{n\\pi} \\Gamma(\\frac{n}{2})} (1 + \\frac{t^2}{n})^{-\\frac{n + 1}{2}}$$\n",
    "\n",
    "Where the $\\Gamma(z) = \\int_0^\\infty x^{z - 1}e^{-x} dx$ is the famous special function Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"t-distribution.jpg\" width=\"400\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "  \n",
    "# get the image\n",
    "Image(url=\"t-distribution.jpg\", width=400, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing t and normal distributions\n",
    "Plots of the probability density function of the Student’s t curve for \n",
    "various degrees of freedom. The normal curve with mean 0 and variance 1 (z curve) \n",
    "is plotted for comparison (solid blue line). The t curves are more spread out than the \n",
    "normal, but the amount of extra spread decreases as the number of degrees of \n",
    "freedom increases. **For n = 30 the t distribution becomes practically N(0,1).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer functions (t-distribution)\n",
    "R functions:  \n",
    "\n",
    "dt(t,n)   density function of t with n DOF\n",
    "\n",
    "pt(t,n)   cumulative function\n",
    "\n",
    "qt(t,n)   percentile function\n",
    "\n",
    "rt (1000,n)  gives 1000 random numbers with n DOF’s\n",
    "\n",
    "Excel functions:   \n",
    "\n",
    "T.DIST(t,n,cumulative)  with n is the number of DOF’s\n",
    "\n",
    "T.INV(p,n)  the percentile function\n",
    "\n",
    "T.INV(RAND(0),n)  generates random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small-sample test for population mean \n",
    "Spacer collars for a transmission countershaft have a thickness specification of 38.98–39.02 mm. The process that manufactures the collars is supposed to be calibrated so that the mean thickness is 39.00 mm, which is in the center of the specification window. A sample of six collars is drawn and measured for thickness. The six thicknesses are 39.030, 38.997, 39.012, 39.008, 39.019, and 39.002. Assume that the population of thicknesses of the collars is approximately normal. Can we conclude that the process needs recalibration?\n",
    "\n",
    "The null and alternative hypotheses: $H_0$ :  $\\mu$ = 39.00  H1 :  $\\mu \\neq 39.00$\n",
    "\n",
    "This is a 2-sided test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the statistic\n",
    "Thickness x must be between 38.98-39.02 mm with mean $\\mu = 39.00$ mm.\n",
    "\n",
    "For $n = 6$ inspected samples the observed thickness are:\n",
    "x = 39.030, 38.997, 39.012, 39.008, 39.019, 39.002 mm\n",
    "\n",
    "We calculate: \n",
    "\n",
    "$\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n x_i = 39.011$\n",
    "\n",
    "$s = \\sqrt{\\frac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar{x})^2}$\n",
    "\n",
    "The “statistic” number for our problem is $t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}} = 2.327$\n",
    "\n",
    "Assuming all x’s have a normal distribution then the number t follows a t distribution with $n - 1 = 5$  degrees  of freedom (DOF), or  t ~ $t_5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the p-value\n",
    "R:   pt(-2.327,5)*2  # this is the 2-sded p-value = 0.067\n",
    "\n",
    "Excel: T.DIST(-2.327,5,TRUE)*2 = 0.067\n",
    "\n",
    "The test is 2 sided so the left tail and righttail (indicated by the blue arrows) are added together\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "The observed mean thickness in the tested sample in not significantly different from the expected thickness.  However, the p-value is pretty close to the 0.05 threshold, so a more careful calibration might be considered, if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the t.test function in R\n",
    "x = c(39.030, 38.997, 39.012, 39.008, 39.019, 39.002)\n",
    "\n",
    "t.test(x,mu=39)\n",
    "\n",
    "One Sample t-test\n",
    "\n",
    "data:  x\n",
    "\n",
    "t = 2.3275, df = 5, p-value = 0.06742\n",
    "\n",
    "alternative hypothesis: true mean is not equal to 39\n",
    "\n",
    "95 percent confidence interval: [38.99882 39.02385]\n",
    "\n",
    "Sample estimates:\n",
    "\n",
    "mean of x 39.01133 \n",
    "\n",
    "See help(t.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with a z test\n",
    "Suppose we ignore the fact that the sample is small, with n=6, and we perform a z-test.  That means the same approach, with z = 2.327, but using N(0,1) instead of the t distribution.\n",
    "\n",
    "If so, the resulting p-value is  pnorm(-2.327,0,1)*2 = 0.02\n",
    "\n",
    "That means a significant difference between the observed and expected mean \n",
    "thickness.\n",
    "\n",
    "However, this conclusion is not correct, because we used a normal distribution \n",
    "for a sample which is too small.\n",
    "\n",
    "**We see that using an incorrect distribution, or a poor approximation (or and incorrect test) might lead to wrong conclusions.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the difference between two means, small sample case\n",
    "**Example at the beginning of section 6.7 in the textbook.** DNA molecules present in 6 biological solutions are counted. Then, DNA molecules are counted in another 4 solutions which were treated with an enzyme. Is the mean number of DNA molecules different in the two types of solutions?\n",
    "\n",
    "**Sample 1:** $n_x = 6, \\quad x = 33, 30, 26, 22, 37, 34$ **without enzyme**\n",
    "\n",
    "**Sample 2:** $n_y = 4, \\quad x = 22, 29, 25, 23$ **with enzyme**\n",
    "\n",
    "The difference between the mean numbers $D = \\bar{x} - \\bar{y} = 5.58$\n",
    "\n",
    "The variance of D: $\\sigma_D^2 = \\frac{s^2_x}{n_x} + \\frac{s^2_y}{n_y}$\n",
    "\n",
    "The two hypothesis are $H_0$: $D = 0$ and $H_1$: $D \\neq 0$\n",
    "\n",
    "The t statistic: $t = \\frac{Observed\\,D - Expected\\,D}{std.of\\,D} = \\frac{(\\bar{x} - \\bar{y} - 0)}{\\sqrt{\\frac{s^2_x}{n_x} + \\frac{s^2_y}{n_y}}} = 2.038$ **How many DOF v?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welch formula \n",
    "The number DOF, often denoted by v, is calculated with the Welch formula. \n",
    "\n",
    "$$v = \\frac{(\\frac{s^2_x}{n_x} + \\frac{s^2_y}{n_y})^2}{\\frac{(\\frac{s^2_x}{n_x})^2}{n_x - 1} + \\frac{(\\frac{s^2_y}{n_y})^2}{n_y - 1}}$$\n",
    "\n",
    "Here we obtain v = 7.89, but often a software uses the nearest integer or the nearest smaller integer (depending on the software)\n",
    "\n",
    "However the t distribution can also be used for non-integer DOF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the p-value\n",
    "Lets calculate the p-value. We have a 2-sided test with a t distribution with 7.89 DOF. Make your own graph of the t-distribution and the right and left tails to complete your understanding. \n",
    "\n",
    "R: 2 * pt(-2.038, 7.89) = 2 * (1 - pt(2.038, 7.89)) = 0.0764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of this t test in R and Excel\n",
    "**R:**\n",
    "\n",
    "x = c(33,30,26,22,37,34)\n",
    "\n",
    "y = c(22,29,25,23)\n",
    "\n",
    "t.test(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three types of t test\n",
    "Options for t test when comparing two samples:\n",
    "\n",
    "1. Unequal variances - the most common. The std. of the **mean** diffrence is calculated as $\\sigma_{\\bar{x} - \\bar{y}} = \\sqrt{\\frac{s^2_x}{n_x} + \\frac{s^2_y}{n_y}}$\n",
    "2. Equal variances - when this information is known. In this case variance is calculated by putting all data in one sample and the software uses: $\\sigma_x = \\sigma_y = \\sqrt{\\frac{1}{n_x + n_y - 2}[ \\sum_i (x_i - \\bar{x})^2 + \\sum_j (y_j - \\bar{y})^2]}$\n",
    "3. Paired data. x and y have the same number of elements and the data consists in the *differences* between pairs of data points $x_i - y_i$. The software uses $\\sigma_{\\bar{x} - \\bar{y}} = \\sqrt{\\frac{1}{n(n - 1)} \\sum_{i = 1}^n [(x_i - y_i) - (\\bar{x} - \\bar{y})]^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on t test with paired data\n",
    "X data with n values: $x_1, x_2, ... x_n$\n",
    "\n",
    "Y data with n values: $y_1, y_2, ... y_n$\n",
    "\n",
    "We have the same number of data points for X and Y, equal to n. \n",
    "\n",
    "**In a paired sample t-test, each subject or element is measured twice, resulting in pairs of observations. The X and Y data must be logically paired.**\n",
    "\n",
    "For example: X corresponds to one situation and Y corresponds to another situation of the same object, or of the same individual, or at the same place, etc. Like before and after a certain treatment, or action, etc., on the same object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared tests\n",
    " - Goodness-of-fit (GOF) test\n",
    " - Test of homogeneity\n",
    " - Test of independance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catogorical data \n",
    "- The data describes different categories or groups. For example: \n",
    "    - Girls and boys (2 categories)\n",
    "    - Low, medium, high\n",
    "    - Yellow, blue, red, green (4 categories)\n",
    "- A large class of tests are performed to compare how many elements are observed in different groups with the expected numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z test of two categories\n",
    "In our course we have N = 222 students: G = 86 girls and B = 136 boys. Is the observed gender difference statistically significant?\n",
    "\n",
    "We can use the z-test method for proportions. Consider p the proportion of girls and 1 - p proportions of boys. \n",
    "\n",
    "$H_0: p = 0.5\\,,\\, or\\, G = B$ but possibly slightly different due to statistical randomness.\n",
    "\n",
    "$H_0: p \\neq 0.5\\,,\\, or\\, G \\neq B$ meaning truly different\n",
    "\n",
    "We observe $\\hat{p} = \\frac{G}{N} = \\frac{86}{222} = 0.387$  the z-score is $z = \\frac{\\hat{p} - p}{\\sigma_{\\hat{p}}}$ with $\\sigma_{\\hat{p}} = \\sqrt{\\frac{p(1 - p)}{N}}$\n",
    "\n",
    "We obtain $z = -3.36$ and a two-sided $p-value = 0.00079$\n",
    "\n",
    "Conclusion: Yes, there is a significant gender imbalance, thus we reject $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The chi-square method\n",
    "- The observed number are $O_g = G = 86$ girls and $O_b = B = 136$ boys.\n",
    "- The expected numbers are $E_g = \\frac{N}{2} = 111$ girls and $E_b = \\frac{N}{2} = 111$ boys. \n",
    "- Calculate the number\n",
    "\n",
    "$$\\chi^2 = \\frac{(O_g - E_g)^2}{E_g} + \\frac{(O_b - E_b)^2}{E_b} = 11.26$$ \n",
    "\n",
    "- This value is excatly $z^2$ from the z-test. *Exercise:* show that this is true for any numbers $G + B = N$ (do calculation with letters).\n",
    "- Remember that if z follows a standard norma distribution then $z^2$ follows a chi-square distribution with one DOF $\\chi_1^2$\n",
    "- The p-value is the probability that the difference between girls and boys is even larger than observed. That correspons to the tail $\\chi^2 \\gt 11.26$ \n",
    "\n",
    "R: $1 - pchisq(11.26,1) = 0.00079$\n",
    "\n",
    "Python: $1 - chi2.cdf(11.26,1) = 0.00079$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goodness-of-fit (GOF) test\n",
    "- The chi-square test that we performed for gender balance is called the goodness-of-fit test. It evaluates how well can we describe (or predict) the observed data with a known probability.\n",
    "- We used only 2 categories, girls and boys, and in that case a z-test was possible. That is no longer possible when we have more than 2 categories.\n",
    "- Example from Section 6.10 Table 6.3. A die is rolled 600 times and the observed values for the top face are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Observed</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category  Observed  Expected\n",
       "0        1       115       100\n",
       "1        2        97       100\n",
       "2        3        91       100\n",
       "3        4       101       100\n",
       "4        5       110       100\n",
       "5        6        86       100\n",
       "6    Total       600       600"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/Ch6/table6.3.csv\", index_col=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is: Is this die fair?\n",
    "\n",
    "For a fair die the expected numbers are all equal to 100, corresponding to the constant probability 1/6 for each face.  But there might be some fluctuations.\n",
    "\n",
    "(In general, in a goodness-of-fit test, we can have different probabilities for each expected number, but here they are all 1/6.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H_0$, $H_1$, and the chi-square number\n",
    "$H_0$:  observed numbers = expected numbers  ($\\pm$ some random fluctuations)\n",
    "\n",
    "$H_1$: observed numbers $\\neq$ expected numbers  (meaning a systematic difference)\n",
    "\n",
    "We use the observed (O) and expected (E) numbers  from each cell i=1,6 and calculate:\n",
    "\n",
    "$$\\chi^2 = \\sum_{i = 1}^6 \\frac{O_i - E_i}{E_i} = 6.12$$ \n",
    "\n",
    "This number has a chi-square distribution with $6 - 1 = 5$ degrees of freedom.  \n",
    "\n",
    "The number of DOF is the number of cells –1.\n",
    "\n",
    "Find the p-value \n",
    "\n",
    "$1 - pchisq(6.12, 5) = 0.29 > 0.05 \\Rightarrow$ Accept $H_0$ the die can be considered fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=6.12, pvalue=0.29471693654506914)\n",
      "Power_divergenceResult(statistic=6.12, pvalue=0.29471693654506914)\n",
      "0.29471693654506914\n",
      "0.043035946898983046\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2, chisquare\n",
    "\n",
    "obs = [115, 97, 91, 101, 110, 86]\n",
    "exp = [100, 100, 100, 100, 100, 100]\n",
    "\n",
    "print(chisquare(f_obs=obs))\n",
    "\n",
    "print(chisquare(f_obs=obs, f_exp=exp))\n",
    "\n",
    "\n",
    "print(1 - chi2.cdf(6.12, 5))\n",
    "\n",
    "print(1 - chi2.cdf(13,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphical representation of the p-valueA chi square test is always a two-sided test, because the $\\chi^2$ number is always positive. It represents the squared deviation between the observed and expected data. Therefore the sign or the direction of the deviation is not seen. However, if we want a 1-sided p-value we can divide the 2-sided p-value by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chi-square test for homogeneity\n",
    "Section 6.10, Example 6.22. The observed number of steel pins produced by several machines are classified in the following contingency table (tabla 6.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Machines</th>\n",
       "      <th>Too thin</th>\n",
       "      <th>OK</th>\n",
       "      <th>Too thick</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine 1</td>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine 2</td>\n",
       "      <td>34</td>\n",
       "      <td>161</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine 3</td>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine 4</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total</td>\n",
       "      <td>66</td>\n",
       "      <td>402</td>\n",
       "      <td>32</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Machines  Too thin   OK  Too thick  Total\n",
       "0  Machine 1        10  102          8    120\n",
       "1  Machine 2        34  161          5    200\n",
       "2  Machine 3        12   79          9    100\n",
       "3  Machine 4        10   60         10     80\n",
       "4      Total        66  402         32    500"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.stats import chisquare, chi2_contingency\n",
    "\n",
    "df = pd.read_csv(\"datasets/Ch6/table6.4.csv\", names=[\"Machines\", \"Too thin\", \"OK\", \"Too thick\", \"Total\"], header=0, index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is: Can we claim that the machines 1-4 give similar proportions of thin, Ok, and thick pins? In other words is this group of machines **homogenous**?\n",
    "\n",
    "For ex. suppose one machine produces 10% too thin, 80% Ok, 10% too thick. Are these numbers valid for all machines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H_0$ and $H_1$\n",
    "- We look at the numbers in a raw and think about a probability distribution behind these numbers.\n",
    "- Remember the die. In that case we had only one row and the numbers were expected to be consistent with a probability $\\frac{1}{6}$ \n",
    "- Now we have several rows and the probabilities are not known, but we can guess them by combining rows and columns and looking at proportions\n",
    "\n",
    "$H_0$: The proportions of thin-OK-thick pins are the same for all machines. Or, more generally, the probability distribution of the numbers in a row is the same for each row.\n",
    "\n",
    "$H_1$: These probability distributions are different. They depend on the row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we calculate the expected numbers\n",
    "Assuming the null hypothesis $H_0$ the machines are not different. If so, we use the observed data in each cell $O_{ij}$ (i for rows, j for columns) to find the probabilities.\n",
    "\n",
    "P(thin) = $\\frac{66}{500}$, P(OK) = $\\frac{402}{500}$, P(thick) = $\\frac{32}{500}$ \n",
    "\n",
    "The expected values in each cell $E_{ij}$ are given by these probabilities multiplied with the total number of machines of type i. For example:\n",
    "\n",
    "$E_{11} = P(thin) \\times\\, Total\\,M1 = \\frac{66}{500} \\times 120 = 15.84$\n",
    "\n",
    "$E_{21} = P(thin) \\times\\, Total\\,M2 = \\frac{66}{500} \\times 200 = 26.40$\n",
    "\n",
    "$E_{22} = P(OK) \\times\\, Total\\,M2 = \\frac{402}{500} \\times 200 = 160.80$\n",
    "\n",
    "$E_{23} = P(thick) \\times\\, Total\\,M2 = \\frac{32}{500} \\times 200 = 12.80$\n",
    "\n",
    "In general: $E_{ij} = \\frac{1}{total\\,pins} (\\sum_j O_{ij}) (\\sum_i O_{ij})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the test statistic \n",
    "Next steps is to calculate the statistics for this test which is\n",
    "\n",
    "$\\chi^2 = \\sum_{i = 1}^n \\sum_{j = 1}^m \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} = 15.84$\n",
    "\n",
    "This number has a chi-square distribution with (n - 1)(m - 1) DOF, n = number of rows, m = number of columns. Here (4 - 1)(3 - 1) = 6 DOF \n",
    "\n",
    "Observe that the rows ant the columns of the data matrix can be switched and we get the same $\\chi^2$. In fact we could transpose our matrix and reformulate the problem for the probabilites of a certain pin diameter produced by each machine. \n",
    "\n",
    "The p-value = 1 - chi2.cdf(15.84, 6) = 0.0146 < 0.05\n",
    "\n",
    "*Conclusion:* The proportions of thin-Ok-thick pins differ between machines. Reject $H_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15.584353328056686, 0.01616760116149423, 6, array([[ 15.84,  96.48,   7.68],\n",
      "       [ 26.4 , 160.8 ,  12.8 ],\n",
      "       [ 13.2 ,  80.4 ,   6.4 ],\n",
      "       [ 10.56,  64.32,   5.12]]))\n",
      "0.016169816116471503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Too thin</th>\n",
       "      <th>OK</th>\n",
       "      <th>Too thick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>161</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Too thin   OK  Too thick\n",
       "0        10  102          8\n",
       "1        34  161          5\n",
       "2        12   79          9\n",
       "3        10   60         10"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.stats import chisquare, chi2_contingency\n",
    "\n",
    "df = pd.read_csv(\"datasets/Ch6/table6.4.csv\", names=[\"Machines\", \"Too thin\", \"OK\", \"Too thick\", \"Total\"], header=0, index_col=False)\n",
    "\n",
    "df2 = df[0:4].drop(columns=[\"Total\", \"Machines\"])\n",
    "\n",
    "print(chi2_contingency(df2, correction=True))\n",
    "\n",
    "print(1 - chi2.cdf(15.584, 6))\n",
    "\n",
    "df2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chi-square test for independence \n",
    "Example 6.23. The steel pins are now classified by length and diameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Defects</th>\n",
       "      <th>Too thin</th>\n",
       "      <th>OK</th>\n",
       "      <th>Too thick</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Too short</td>\n",
       "      <td>13</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK</td>\n",
       "      <td>62</td>\n",
       "      <td>664</td>\n",
       "      <td>80</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Too long</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Defects  Too thin   OK  Too thick  Total\n",
       "0  Too short        13  117          4    134\n",
       "1         OK        62  664         80    806\n",
       "2   Too long         5   68          8     81"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/Ch6/exm6-23.csv\", names=[\"Defects\", \"Too thin\", \"OK\", \"Too thick\", \"Total\"], header=0)\n",
    "\n",
    "df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we claim that the diameter and length are independent variables? \n",
    "\n",
    "$H_0:$ Yes, they are. That means $P(line\\,i \\cap column\\,j) = P(line\\,i) \\times P(column\\,j)$ for any i and j\n",
    "\n",
    "$H_1:$ No, they are not. That means $P(line\\,i \\cap column\\,j) \\neq P(line\\,i) \\times P(column\\,j)$ at least for some i and j "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "- Technically the test for independence is similar to the test for homogeneity. \n",
    "- Only the interpretation of the test is (more or less) different \n",
    "- $H_0$ will be rejected, and the variables will not be considered independent, if the p-value < 0.05  \n",
    "- Do the test yourselves, like in the case of the test for the homogeneity, and obtain:\n",
    "\n",
    "$$\\chi^2 = 7.46505\\,, DOF = 4\\,, p-value = 0.1135 \\gt 0.05$$\n",
    "\n",
    "- Conclusion: the length and diameter can be considered independent. $H_0$ accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.4605304872121865, 0.11346237829192939, 4, array([[ 10.49951028, 111.42605289,  12.07443683],\n",
      "       [ 63.15377081, 670.21939275,  72.62683643],\n",
      "       [  6.3467189 ,  67.35455436,   7.29872674]]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare, chi2_contingency\n",
    "\n",
    "df = pd.read_csv(\"datasets/Ch6/exm6-23.csv\", names=[\"Defects\", \"Too thin\", \"OK\", \"Too thick\", \"Total\"], header=0)\n",
    "\n",
    "df2 = df[0:3].drop(columns=[\"Total\", \"Defects\"])\n",
    "\n",
    "df2\n",
    "print(chi2_contingency(df2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1.5 (Page 13):\n",
    "A certain process for manufacturing integrated circuits has been in use for a period of time, and it is known that 12% of the circuits it produces are defective. A new process that is supposed to reduce the proportion of defectives is being tested. In a simple random sample of 100 circuits produced by the new process, 12 were defective. \n",
    "\n",
    "a)\tOne of the engineers suggests that the test proves that the new process is no better than the old process, since the proportion of defectives in the sample is the same. Is this conclusion justified? Explain. \n",
    "\n",
    "No, I think the sample size is too small to determine whether the new process is better, worse or the same. Since in such a small sample randomness plays a large role. \n",
    "\n",
    "b)\tAssume that there had been only 11 defective circuits in the sample of 100. Would this have proven that the new process is better? Explain.\n",
    "\n",
    "Again like in the answer above the sample size is just too small to justify when there is such a small difference.  \n",
    "\n",
    "c)\tWhich outcome represents stronger evidence that the new process is better: finding 11 defective circuits in the sample, or finding 2 defective circuits in the sample? \n",
    "\n",
    "Finding 2 defective circuits in the sample is much stronger evidence since the chance of that coming down to variance is much smaller than the process has actually improved. Going down from 12% defective circuits to 2% is such an significant improvement it is hard to argue that it because of variance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1.6 (Page 13):\n",
    "Refer to Exercise 5. True or false: \n",
    "\n",
    "a)\tIf the proportion of defectives in the sample is less than 12%, it is reasonable to conclude that the new process is better. \n",
    "\n",
    "False\n",
    "\n",
    "b)\tIf the proportion of defectives in the sample is only slightly less than 12%, the difference could well be due entirely to sampling variation, and it is not reasonable to conclude that the new process is better. \n",
    "\n",
    "True\n",
    "\n",
    "c)\tIf the proportion of defectives in the sample is a lot less than 12%, it is very unlikely that the difference is due entirely to sampling variation, so it is reasonable to conclude that the new process is better. \n",
    "\n",
    "True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1.7 (Page 13):\n",
    "To determine whether a sample should be treated as a simple random sample, which is more important: a good knowledge of statistics, or a good knowledge of the process that produced the data? \n",
    "\n",
    "Good knowledge of statistics is more important and especially how to choose the data in the simple random sample, since a person who doesn’t know the correct method is likely to choose a sample of convenience instead a simple random sample. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2.5 (Page 23):\n",
    "Find a sample size for which the median will always equal one of the values in the sample. \n",
    "\n",
    "Sample size = 2n + 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2.6 (Page 23):\n",
    "For a list of positive numbers, is it possible for the standard deviation to be greater than the mean? If so, give an example. If not, explain why not. \n",
    "\n",
    "I would argue that the standard deviation is a calculation of how spread the data is from the mean and thus if all the data points are positive numbers it should be impossible for the standard devitation to be greater than the mean. Let‘s take a spread data set: \n",
    "\n",
    "data = [5.000, 10.000, 15.000, 20.000]\n",
    "\n",
    "Mean = 12.500\n",
    "\n",
    "Sd = 6454.97\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2.7 (Page 23):\n",
    "Is it possible for the standard deviation of a list of numbers to equal 0? If so, give an example. If not, explain why not. \n",
    "\n",
    "Yes, if it is a list of the same number there is no devition, else there is always some deviation. \n",
    "\n",
    "Example:\n",
    "\n",
    "Data = [2, 2, 2, 2, 2]\n",
    "\n",
    "Mean = 2 \n",
    "\n",
    "Sd = 0\n",
    "\n",
    "Example:\n",
    "\n",
    "Data = [-1, 0, 1]\n",
    "\n",
    "Mean = 0 \n",
    "\n",
    "Sd = 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2.8\n",
    "In a certain company, every worker received a $50-per-week raise. How does this affect the mean salary? The standard deviation of the salaries?\n",
    "\n",
    "Let's look at an example: \n",
    "\n",
    "Salary before: {100, 150, 200}\n",
    "\n",
    "Mean before: 150\n",
    "\n",
    "Std before: 50\n",
    "\n",
    "Salary after: {150, 200, 250}\n",
    "\n",
    "Mean after: 200\n",
    "\n",
    "Std after: 50\n",
    "\n",
    "So we can see since the whole population is affected by the salary change the std doesn't change and the mean raises by the raise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"problem1.2.10.jpg\" width=\"600\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "  \n",
    "# get the image\n",
    "Image(url=\"problem1.2.10.jpg\", width=600, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3.7 (Page 40):\n",
    "The figure below is a histogram showing the distribution of serum cholesterol level for a sample of men. Use the histogram to answer the following questions: \n",
    "\n",
    "a)\tIs the percentage of men with cholesterol levels above 240 mg/dL closest to 30%, 50%, or 70%? \n",
    "\n",
    "Relative Frequency (240mg/dL+) = 0.14 + 0.1 + 0.05 + 0 + 0.02 = 0.31\n",
    "\n",
    "So it‘s the closest to 30%\n",
    "\n",
    "b)\tIn which interval are there more men: 240–260 mg/dL or 280–340 mg/dL? \n",
    "\n",
    "Relative Frequency (240-260mg/dL) =  0.14 + 0.1 = 0.24  \n",
    "\n",
    "Relative Frequency (280-340mg/dL) = 0.05 + 0 + 0.02 = 0.07\n",
    "\n",
    "There are more men in the 240-260mg/dL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2.1 (Page 49):\n",
    "An electrical engineer has on hand two boxes of resistors, with four resistors in each box. The resistors in the first box are labeled 10 Ω (ohms), but in fact their resistances are 9, 10, 11, and 12 Ω. The resistors in the second box are labeled 20 Ω, but in fact their resistances are 18, 19, 20, and 21 Ω. The engineer chooses one resistor from each box and determines the resistance of each. \n",
    "\n",
    "Let A be the event that the first resistor has a resistance greater than 10, let B be the event that the second resistor has a resistance less than 19, and let C be the event that the sum of the resistances is equal to 28. Find a sample space for this experiment, and specify the subsets corresponding to the events A, B, and C. \n",
    "\n",
    "10 ohm box = {9, 10, 11, 12}\n",
    "\n",
    "20 ohm box = {18, 19, 20, 21}\n",
    "\n",
    "Sample space = all possible outcomes of picking one resistor from each box (16 outcomes) \n",
    "\n",
    "A = {(11, any out of box2), (12, any out of box2)}\n",
    "\n",
    "B = {(any out of box1,18), (any out of box1, 18}}\n",
    "\n",
    "C = {(9,19), (10,18}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1.2 (Page 60):\n",
    "A die (six faces) has the number 1 painted on three of its faces, the number 2 painted on two of its faces, and the number 3 painted on one face. Assume that each face is equally likely to come up. \n",
    "\n",
    "1.\tFind a sample space for this experiment.\n",
    "\n",
    "    Sample space = {1,1,1,2,2,3} \n",
    "\n",
    "2.\tFind P(odd number). \n",
    "\n",
    "    P(odd number) = {1,1,1,3} / {1,1,1,2,2,3} = 4/6 = 2/3 = 66,67%\n",
    "\n",
    "3.\tIf the die were loaded so that the face with the 3 on it were twice as likely to come up as each of the other five faces, would this change the sample space? Explain.\n",
    "\n",
    "    Yes cause the likelihood that the three would come up would go from 1/6 to 2/7 which would change the sample space to {1,1,1,2,2,3,3}\n",
    "4.\tIf the die were loaded so that the face with the 3 on it were twice as likely to come up as each of the other   five faces, would this change the value of P(odd number)? Explain. \n",
    "\n",
    "    Yes since the sample space changes so does the probability. \n",
    "\n",
    "    P(odd number) = {1,1,1,3,3} / (1,1,1,2,2,3,3} = 5/7 \n",
    "\n",
    "    So the odds of rolling a odd number increases when the likelihood of an three increases. Which is logical. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1.3 (Page 60):\n",
    "A section of an exam contains four True-False questions. A completed exam paper is selected at random, and the four answers are recorded.\n",
    "1.\tList all 16 outcomes in the sample space.\n",
    "\n",
    "    SS = {TTTT, TTTF,TTFF, TFFF, FFFF, FTTT, FFTT, FFFT, TFFT,FTTF, FTFT, TFTF, FTFF, FFTF, TTFT, TFTT} \n",
    "\n",
    "2.\tAssuming the outcomes to be equally likely, find the probability that all the answers are the same. \n",
    "\n",
    "    P(All answers the same) = {TTTT, FFFF} / SS = 2/16 = 1/8\n",
    "\n",
    "3.\tAssuming the outcomes to be equally likely, find the probability that exactly one of the four answers is “True.” \n",
    "\n",
    "    P(exactly one True) = {TFFF, FTFF, FFTF, FFFT} / SS = 4/16 = 1/4\n",
    "\n",
    "4.\tAssuming the outcomes to be equally likely, find the probability that at most one of the four answers is “True.” \n",
    "\n",
    "    P(at most one True} = {FFFF, TFFF, FTFF, FFTF, FFFT} / SS = 5/16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2.1.13 (Page 61)\n",
    "Let S be the event that a randomly selected college student has taken a statistics course, and let C be the event that the same student has taken a chemistry course. Suppose P(S) = 0.4, P(C) = 0.3, and P(S ∩ C) = 0.2. \n",
    "\t\n",
    "a)Find the probability that a student has taken statistics, chemistry, or both. \n",
    "\n",
    "P(Student completing S, C or both)= P(S∪C)= P(C) + P(S) - P(S∩C) = 0.9 = 50%\n",
    "\t\n",
    "b) Find the probability that a student has taken neither statistics nor chemistry. \n",
    "\n",
    "P(A^c)=1-P(A)\n",
    "\n",
    "P(A)=1-P(A^C)\n",
    "\n",
    "P(Student completing neither S nor C) = P(S^c∩C^c) = 1 -  P(Student completing S, C or both) = 0.5 = 50%\n",
    "\n",
    "c)Find the probability that a student has taken statistics but not chemistry. \n",
    "\n",
    "P(Student completing S but not C) = P(S) – P(S∩C) = 0.2 = 20%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.16\n",
    "A system contains two components, A and B. The system will function so long as either A or B functions. The probability that A functions is 0.95, the probability that B functions is 0.90, and the probability that both function is 0.88. What is the probability that the system functions?\n",
    "\n",
    "$$ \n",
    "\\begin{align}P(A \\cup B) &= P(A) + P(B) - P(A \\cap B) \\\\ \n",
    "& = 0.95 + 0.90 - 0.88 \\\\ \n",
    "& = 0.97 \\\\ \n",
    "& = 97\\%\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1.13\n",
    "Let S be the event that a randomly selected college student has taken a statistics course, and let C be the event that the same student has taken a chemistry course. Suppose $P(S) = 0.4, P(C) = 0.3, and P(S \\cap C) = 0.2$.\n",
    "\n",
    "a. Find the probability that a student has taken statistics, chemistry, or both.\n",
    "\n",
    "$P(S \\cup C) = P(S) + P(C) - P(S \\cap C)$\n",
    "\n",
    "$P(S \\cup C) = 0.4 + 0.3 - 0.2 = 0.5$\n",
    "\n",
    "b. Find the probability that a student has taken neither statistics nor chemistry.\n",
    "\n",
    "$P(S^c \\cap C^c) = 1 - P(S \\cup C)$ \n",
    "\n",
    "$P(S^c \\cap C^c)  = 1 - 0.5 = 0.5$\n",
    "\n",
    "c. Find the probability that a student has taken statistics but not chemistry.\n",
    "\n",
    "$P(S \\cap C^c) = P(S) - P(S \\cap C)$\n",
    "\n",
    "$P(S \\cap C^c) = 0.4 - 0.2 = 0.2$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1.14\n",
    "Six hundred paving stones were examined for cracks, and 15 were found to be cracked. The same 600 stones were then examined for discoloration, and 27 were found to be discolored. A total of 562 stones were neither cracked nor discolored. One of the 600 stones is selected at random.\n",
    "\n",
    "$P(C) = 0.025$\n",
    "\n",
    "$P(D) = 0.045$\n",
    "\n",
    "$P(C^c \\cap D^c) = 0.9367$\n",
    "\n",
    "a. Find the probability that it is cracked, discolored, or both.\n",
    "\n",
    "$P(C \\cup D) = 1 - 0.9367 = 0.0633$\n",
    "\n",
    "b. Find the probability that it is both cracked and discolored.\n",
    "\n",
    "$P(C \\cup D) = P(C) + P(D) - P(C \\cap D)$ \n",
    "\n",
    "$ 0.0633 = 0.025 + 0.045 - P(C \\cap D)$\n",
    "\n",
    "$P(C \\cap D) = 0.025 + 0.045 - 0.0633 = 0.0067$\n",
    "\n",
    "c. Find the probability that it is cracked but not discolored.\n",
    "\n",
    "$P(C \\cap D^c) = P(C) - P(C \\cap D)$\n",
    "\n",
    "$P(C \\cap D^c) = 0.025 - 0.0067 = 0.0183$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1.16\n",
    "A system contains two components, A and B. The system will function so long as either A or B functions. The probability that A functions is 0.95, the probability that B functions is 0.90, and the probability that both function is 0.88. What is the probability that the system functions?\n",
    "\n",
    "$P(A) = 0.95$\n",
    "\n",
    "$P(B) = 0.90$\n",
    "\n",
    "$P(A \\cap B) = 0.88$\n",
    "\n",
    "$P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$ \n",
    "\n",
    "$P(A \\cup B) = 0.95 + 0.90 - 0.88 = 0.97$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1.17\n",
    "A system contains two components, A and B. The system will function only if both components function. The probability that A functions is 0.98, the probability that B functions is 0.95, and the probability that either A or B functions is 0.99. What is the probability that the system functions?\n",
    "\n",
    "$P(A) = 0.98$\n",
    "\n",
    "$P(B) = 0.95$\n",
    "\n",
    "$P(A \\cup B) = 0.99$\n",
    "\n",
    "$P(A \\cap B) = P(A) + P(B) - P(A \\cup B)$\n",
    "\n",
    "$P(A \\cap B) = 0.98 + 0.95 - 0.99 = 0.94$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2.4 \n",
    "A group of 18 people have gotten together to play baseball. They will divide themselves into two teams of 9 players each, with one team wearing green uniforms and the other wearing yellow uniforms. In how many ways can this be done?\n",
    "\n",
    "This can be done in $\\begin{pmatrix} 18 \\\\ 9 \\end{pmatrix}$ ways.\n",
    "\n",
    "$\\begin{pmatrix} 18 \\\\ 9 \\end{pmatrix} = \\frac{18!}{9!(18 - 9)!} = 48620$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2.6\n",
    "A college math department consisting of 10 faculty members must choose a department head, an assistant department head, and a faculty senate representative. In how many ways can this be done?\n",
    "\n",
    "\n",
    "This can be done:\n",
    "\n",
    "$\\begin{pmatrix} 10\\\\ 1 \\end{pmatrix} \\times \\begin{pmatrix} 9 \\\\ 1 \\end{pmatrix} \\times \\begin{pmatrix} 8\\\\ 1 \\end{pmatrix} = 720$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2.10\n",
    "Joe, Megan, and Santana are salespeople. Their sales manager has 18 accounts and must assign six accounts to each of them. In how many ways can this be done?\n",
    "\n",
    "$\\begin{pmatrix} 18 \\\\ 6 \\end{pmatrix} \\times \\begin{pmatrix} 12 \\\\ 6 \\end{pmatrix} \\times \\begin{pmatrix} 6 \\\\ 6 \\end{pmatrix} = 19489$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2.10 (4th edition)\n",
    "A company has hired 15 employees, and must assign 6 to the day shift, 5 to the graveyard shift, and 4 to the night shift. In how many ways can the assignment be made?\n",
    "\n",
    "$N = 15$\n",
    "\n",
    "$n_1 + n_2 + n_3 = 15$\n",
    "\n",
    "$n_1 = 6 \\quad n_2 = 5 \\quad n_3 = 4$\n",
    "\n",
    "Number of assignments to day shift:\n",
    "\n",
    "$\\begin{pmatrix} N \\\\ n_1 \\end{pmatrix} = \\begin{pmatrix} 15 \\\\ 6 \\end{pmatrix} = \\frac{15!}{6!(15 - 6)!}$\n",
    "\n",
    "Number of assignments to graveyard shift:\n",
    "\n",
    "$\\begin{pmatrix} N - n_1 \\\\ n_2 \\end{pmatrix} = \\begin{pmatrix} 9 \\\\ 5 \\end{pmatrix} = \\frac{9!}{5!(9 - 5)!}$\n",
    "\n",
    "Number of assignments to night shift:\n",
    "\n",
    "$\\begin{pmatrix} N - n_1 - n_2 \\\\ n_3 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix} = \\frac{4!}{4!(4 - 4)!}$\n",
    "\n",
    "Total number of possible assignment:\n",
    "\n",
    "$\\begin{pmatrix} N \\\\ n_1 \\end{pmatrix} \\begin{pmatrix} N - n_1 \\\\ n_2 \\end{pmatrix} \\begin{pmatrix} N - n_1 - n_2 \\\\ n_3 \\end{pmatrix} = \\frac{N!}{n_1!(N - n_1)!} \\times \\frac{(N - n_1)!}{n_2!(N - n_1 - n_2)!} \\times \\frac{(N - n_1 - n_2)!}{n_3!(N - n_1 - n_2 - n_3)!} = \\frac{N!}{n_1!n_2!n_3!} = \\frac{15!}{6!5!4!} = 630630$\n",
    "\n",
    "Skiptir ekki mali hvaða röð við veljum á vaktirnar þar sem loka svarið er ekki háð því. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2.11\n",
    "One drawer in a dresser contains 8 blue socks and 6 white socks. A second drawer contains 4 blue socks and 2 white socks. One sock is chosen from each drawer. What is the probability that they match?\n",
    "\n",
    "$\\frac{8}{14} * \\frac{4}{6} + \\frac{6}{14} * \\frac{2}{6} = 0.5238$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2.12\n",
    "A drawer contains 6 red socks, 4 green socks, and 2 black socks. Two socks are chosen at random. What is the probability that they match?\n",
    "\n",
    "$\\frac{6}{12} \\times \\frac{5}{11} + \\frac{4}{12} \\times \\frac{3}{11} + \\frac{2}{12} \\times \\frac{1}{11} = 0.33$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Too Thin</th>\n",
       "      <th>OK</th>\n",
       "      <th>Too Thick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Too Short</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>38</td>\n",
       "      <td>900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Too Long</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Too Thin   OK  Too Thick\n",
       "Too Short        10    3          5\n",
       "OK               38  900          4\n",
       "Too Long          2   25         13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('./datasets/Ch2/table2-1.csv', header=0)\n",
    "df.rename(index={0:'Too Short', 1:'OK', 2:'Too Long'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) P(too short), P(too thin), P(too short | too thin), P(too thin | too short), and show how Bayes’ rule \n",
    "works with these numbers. \n",
    "\n",
    "$P(too\\,short) = \\frac{18}{1000} = 0.018$ \n",
    "\n",
    "$P(too\\,thin) = \\frac{50}{1000} = 0.05$\n",
    "\n",
    "$P(too\\,short \\mid too thin) = \\frac{10}{50} = 0.20$\n",
    "\n",
    "$P(too\\,thin \\mid too short) = \\frac{10}{18} = 0.556$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) P(too long), P(too thick), P(too long | too thick), P(too thick | too long), and show how Bayes’ rule \n",
    "works with these numbers. \n",
    "\n",
    "$P(too\\,long) = \\frac{40}{1000} = 0.04$ \n",
    "\n",
    "$P(too\\,thick) = \\frac{22}{1000} = 0.022$\n",
    "\n",
    "$P(too\\,long \\mid too\\,thick) = \\frac{13}{22} = 0.59$ \n",
    "\n",
    "$P(too\\,thick \\mid too\\,long) = \\frac{13}{40} = 0.325$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.8\n",
    "A drag racer has two parachutes, a main and a backup, that are designed to bring the vehicle to a stop after the end of a run. A = Suppose that the main chute deploys with probability 0.99, and that if the main fails to deploy, B = the backup deploys with probability 0.98.\n",
    "\n",
    "a. What is the probability that one of the two parachutes deploys?\n",
    "\n",
    "$P(A) = 0.99$\n",
    "\n",
    "$P(B \\mid A^c) = 0.98$\n",
    "\n",
    "$\\Rightarrow P(A \\cap B) = P(A \\mid B)P(B)$\n",
    "\n",
    "$\\Rightarrow P(B \\cap A) = P(B \\mid A)P(A)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A \\cup B) &= 1 - P(A^c \\cap B^c) \\\\\n",
    "& = 1 - P(B^c \\cap A^c) \\\\\n",
    "& = 1 - P(B^c \\mid A^c) P(A^c) \\\\\n",
    "& = 1 - (1 - P(B \\mid A^c))(1 - P(A)) \\\\\n",
    "& = 1 - (1 - 0.98)(1 - 0.99) \\\\\n",
    "& = 0.998\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "b. What is the probability that the backup parachute deploys?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(B) &= P(B \\cap A) + P(B \\cap A^c) \\\\\n",
    "&= P(B \\mid A)P(A) + P(B \\mid A^c)P(A^c) \\\\\n",
    "&= 0 + 0.98 * 0.01 \\\\\n",
    "&= 0.0098\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.9 \n",
    "At a certain car dealership, 20% of customers who bought a new vehicle bought an SUV, and 3% of them bought a black SUV. Given that a customer bought an SUV, what is the probability that it was black?\n",
    "\n",
    "$P(S) = 0.20$\n",
    "\n",
    "$P(BS) = 0.03$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(BS \\mid S) &= \\frac{P(BS \\cap S)}{P(S)} \\\\\n",
    "&= \\frac{P(BS)}{P(S)} \\\\\n",
    "&= \\frac{0.03}{0.20} \\\\\n",
    "&= 0.15\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.9 (4th edition)\n",
    "Of people in a certain city who bought a new vehicle in the past year, 12% of them bought a hybrid vehicle, and 5% of them bought a hybrid truck. Given that a person bought a hybrid vehicle, what is the probability that it was a truck. \n",
    "\n",
    "$P(A) = 0.12$\n",
    "\n",
    "$P(B) = P(A \\cap B) = 0.05$\n",
    "\n",
    "$P(B \\mid A) = \\frac{0.05}{0.12} = 0.4167$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.15\n",
    "A population of 600 semiconductor wafers contains wafers from three lots. The wafers are categorized by lot and by whether they conform to a thickness specification. The (Page 86) following table presents the number of wafers in each category. A wafer is chosen\n",
    "at random from the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) If the wafer is from Lot A, what is the probability that it is conforming?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(C \\mid A) &= \\frac{P(C \\cap A)}{P(A)} \\\\\n",
    "&= \\frac{88}{100}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conforming</th>\n",
       "      <th>Nonconforming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>165</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>260</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conforming  Nonconforming\n",
       "A          88             12\n",
       "B         165             35\n",
       "C         260             40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/Ch2/ex2-3-15.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('./datasets/Ch2/ex2-3-15.csv', index_col=0)\n",
    "prob_conform_A = df.at['A', 'Conforming'] / df.loc['A'].sum()\n",
    "prob_conform_A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) If the wafer is conforming, what is the probability that it is from Lot A?\n",
    "\n",
    "$P(A) = 0.1667$\n",
    "\n",
    "$P(C) = 0.855$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A \\mid C) &= \\frac{P(C \\mid A)P(A)}{P(C)} \\\\\n",
    "&= \\frac{0.88 \\times 0.1667}{0.855} \\\\\n",
    "&= 0.172\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. If the wafer is conforming, what is the probability that it is not from Lot C?\n",
    "\n",
    "$P(LC) = 0.5$\n",
    "\n",
    "$P(C) = 0.855$\n",
    "\n",
    "$P(C \\mid LC) = \\frac{260}{300} = 0.8667$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(LC \\mid C) &= \\frac{P(C \\mid LC)P(LC)}{P(C)} \\\\\n",
    "&= \\frac{0.8667 \\times 0.5}{0.855} \\\\\n",
    "&= 0.507\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. If the wafer is not from Lot C, what is the probability that it is conforming?\n",
    "\n",
    "$P(C \\mid nLC) = \\frac{253}{300} = 0.843$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.24 \n",
    "A lot of 1000 components contains 300 that are defective. Two components are drawn at random and tested. Let A be the event that the first component drawn is defective, and let B be the event that the second component drawn is defective.\n",
    "\n",
    "$P(A) = \\frac{300}{1000} = 0.30$\n",
    "\n",
    "$P(B) = \\frac{\\frac{300}{999}\\frac{299}{999}}{2} = 0.2998$\n",
    "\n",
    "$P(B \\mid A) = \\frac{299}{999} = 0.2993$\n",
    "\n",
    "$P(A \\cap B) = \\frac{300}{1000} \\times \\frac{299}{999} = 0.09$ \n",
    "\n",
    "$P(A^c \\cap B) = \\frac{700}{1000} \\times \\frac{300}{999} = 0.21$\n",
    "\n",
    "$P(A \\mid B) = \\frac{P(A)P(B \\mid A)}{P(A)P(B \\mid A) + P(nA)P(B \\mid nA)} = \\frac{P(B \\mid A)P(A)}{P(B)}$\n",
    "\n",
    "$P(A \\mid B) = \\frac{0.30 \\times 0.2993}{0.30 \\times 0.2993 + 0.70 \\times 0.7001} = 0.155$\n",
    "\n",
    "Are A and B independent? Is it reasonable to treat A and B as though they were independent? Explain. (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.300460\n",
      "0.299150\n",
      "0.090140\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "\n",
    "x = 300 * [1] + 700 * [0]  \n",
    "n = 100000\n",
    "\n",
    "draw_A = []\n",
    "draw_B = []\n",
    "for i in range(0,n):\n",
    "    rand_draw = sample(x,2)\n",
    "    draw_A.append(rand_draw[0])\n",
    "    draw_B.append(rand_draw[1])\n",
    "\n",
    "P_A = sum(draw_A) / n\n",
    "P_B = sum(draw_B) / n\n",
    "\n",
    "print(f'{P_A:5f}')\n",
    "print(f'{P_B:5f}')\n",
    "\n",
    "\n",
    "multiplyAB = [a*b for a,b in zip(draw_A, draw_B)]\n",
    "\n",
    "P_A_and_B = sum(multiplyAB) / n\n",
    "\n",
    "print(f'{P_A_and_B:5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.27\n",
    "Each day, a weather forecaster predicts whether or not it will rain. For 80% of rainy days, she correctly predicts that it will rain. For 90% of non-rainy days, she correctly predicts that it will not rain. Suppose that 10% of days are rainy and 90% are non-rainy.\n",
    "\n",
    "a) What proportion of the forecasts are correct?\n",
    "\n",
    "$P(R) = 0.10$\n",
    "\n",
    "$P(nR) = 0.90$ \n",
    "\n",
    "$P(P \\mid R) = 0.80$\n",
    "\n",
    "$P(P \\mid nR) = 0.90$\n",
    "\n",
    "$P(P) = 0.90 \\times 0.90 + 0.1 \\times 0.8 = 0.89$\n",
    "\n",
    "b) Another forecaster always predicts that there will be no rain. What proportion of these forecasts are correct?\n",
    "\n",
    "$P(nR) = 0.90$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.30\n",
    "The proportion of people in a given community who have a certain disease is 0.05. A test is available to diagnose the disease. If a person has the disease, the probability that the test will produce a positive signal is 0.99. If a person does not have the disease, the probability that the test will produce a positive signal is 0.01. \n",
    "\n",
    "$\n",
    "P(D) = 0.05 \\\\\n",
    "P(+) = 0.01 \\\\\n",
    "P(+ \\mid D) = 0.99\n",
    "$\n",
    "\n",
    "a) Given that the test is positive, what is the probability that the person has the disease?\n",
    "\n",
    "$P(D \\mid +) = \\frac{0.05 * 0.99}{0.05 * 0.99 + 0.95 * 0.01} = 0.83898$\n",
    "\n",
    "b) Given that the test is negative, what is the probability that the person does not have the disease?\n",
    "\n",
    "$P(nD \\mid -) = \\frac{0.95 * 0.99}{0.95 * 0.99 + 0.05 * 0.01} = 0.99946865$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.31\n",
    "Sickle-cell anemia is an inherited disease in which red blood cells are misshapen and sticky. Sickle cells tend to form clumps in blood vessels, inhibiting the flow of blood. Humans have two genes for sickle-cell anemia, either of which may be S for normal cells or s for sickle cells. A person with two copies of the s gene will have sickle-cell anemia. A person with one s gene and one S gene will not have the disease, but will be a carrier, which means that the s gene may be transmitted to the person’s offspring. If two carriers have a child, the probability is 0.25 that the child will have the disease and 0.5 that the child will be a carrier. Outcomes among children are independent.\n",
    "\n",
    "Sample space = {ss, sS, Ss, SS}\n",
    "$\n",
    "P(SC \\mid PC) = 0.25 \\\\\n",
    "P(CC \\mid PC) = 0.5\n",
    "$ \n",
    "\n",
    "a) A mother and father who are both carriers have two children. What is the probability that neither child has the disease?\n",
    "\n",
    "$P(SC \\mid PC) * P(SC \\mid PC) = 0.0625$\n",
    "\n",
    "b) What is the probability that both children are carriers?\n",
    "\n",
    "$P(CC \\mid PC) * P(CC \\mid PC) = 0.25$ \n",
    "\n",
    "c) If neither child has the disease, what is the probability that both are carriers?\n",
    "\n",
    "$P(Both carriers, if not diseas) = \\frac{2}{3} \\times \\frac{2}{3} = 0.444$\n",
    "\n",
    "d) A woman who is the child of two carriers has a child by a man who is a carrier. What is the probability that this child has the disease?\n",
    "\n",
    "$P(women is carrier) * P(disease) = 0.5 * 0.25 = 0.125$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.34\n",
    "A system consists of four components connected as shown in the following diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Problem2.3.34.jpg\" width=\"600\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "  \n",
    "# get the image\n",
    "Image(url=\"Problem2.3.34.jpg\", width=600, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume A, B, C, and D function independently. If the probabilities that A, B, C, and D fail are 0.10, 0.05, 0.10, and 0.20, respectively, what is the probability that the system functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A) = 1 - 0.10 = 0.90$ \n",
    "\n",
    "$P(B) = 1 - 0.05 = 0.95$\n",
    "\n",
    "$P(C) = 1 - 0.10 = 0.90$\n",
    "\n",
    "$P(D) = 1 - 0.20 = 0.80$\n",
    "\n",
    "$P(K) = P(L1 \\cup L2) = P((A \\cap B) \\cup (C \\cup D))$\n",
    "\n",
    "$P(K) = P(A \\cap B) + P(C \\cup D) - P((A \\cap B) \\cap (C \\cup D))$\n",
    "\n",
    "$P(A \\cap B) = P(A)P(B) = 0.855$ because the events are independent. \n",
    "\n",
    "$P(C \\cup D) = P(C) + P(D) - P(C \\cap D) = P(C) + P(D) - P(C)P(D) = 0.98$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(K) &= P(A \\cap B) + P(C \\cup D) - P((A \\cap B) \\cap (C \\cup D)) \\\\ \n",
    "&= (0.855) + (0.98) - P(A \\cap B)P(C \\cup D) \\\\\n",
    "&= (0.855) + (0.98) - (0.855)(0.98) \\\\\n",
    "&= 0.9971 \n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3.35\n",
    "A system consists of four components, connected as shown in the diagram. Suppose that the components function independently, and that the probabilities of failure are 0.05 for A, 0.03 for B, 0.07 for C, and 0.14 for D. Find the probability that the system functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Problem2.3.35.jpg\" width=\"600\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "  \n",
    "# get the image\n",
    "Image(url=\"Problem2.3.35.jpg\", width=600, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \n",
    "P(A) = 0.95 \\\\\n",
    "P(B) = 0.97 \\\\\n",
    "P(C) = 0.93 \\\\\n",
    "P(D) = 0.86\n",
    "$\n",
    "\n",
    "$\n",
    "P(C \\cap D) = P(C) + P(D) - P(C \\cap D) = 0.93 + 0.86 - 0.93 * 0.86 = 0.9902 \\\\\n",
    "P(K) = P(A \\cap B) + P(C \\cup D) - P((A \\cap B) \\cap (C \\cup D)) \\\\\n",
    "P(K) = P(A)P(B) + P(C \\cup D) - P(A \\cap B)P(C \\cup D) \\\\\n",
    "P(K) = 0.95 * 0.97 + 0.9902 - 0.9215 * 0.9902 = 0.99923\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(x)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p(x)\n",
       "x      \n",
       "0  0.40\n",
       "1  0.30\n",
       "2  0.15\n",
       "3  0.10\n",
       "4  0.05"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('./datasets/Ch2/ex2-4-2.csv', index_col=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(X \\leq x) = \\sum_{x_i \\leq x} P(x_i)$\n",
    "\n",
    "$P(X \\leq 2) = P(0) + P(1) + P(2)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p(x)    0.85\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('./datasets/Ch2/ex2-4-2.csv', index_col=0)\n",
    "\n",
    "df[0:3].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(X > 1) = 1 - P(x \\leq 1) = 1 - (P(0) + P(1)) = 0.30$\n",
    "\n",
    "eða \n",
    "\n",
    "$P(2) + P(3) + P(4) = 0.30$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find expected value (E(X))\n",
    "\n",
    "$\\mu_x = \\sum_i P(x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('./datasets/Ch2/ex2-4-2.csv')\n",
    "\n",
    "E_x = (df['x'] * df['p(x)']).sum()\n",
    "\n",
    "E_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) find variance ($ \\sigma^2_x$)\n",
    "\n",
    "$\\sigma^2_x = \\sum_i x^2 P(x_i) - (E(x))^2 = 2,6 - (1,1)^2 = 1,39$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4.2 (page 112)  \n",
    "Computer chips often contain surface imperfections. For a certain type of computer chip, the probability mass function of the number of defects X is presented in the following table.\n",
    "\n",
    "a) Find $P(X \\leq 2)$\n",
    "\n",
    "b) Find $P(X \\gt 1)$\n",
    "\n",
    "c) Find $\\mu_x$\n",
    "\n",
    "d) Find $\\sigma_x^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) P(X <= 2) = 0.85\n",
      "b) P(X > 1) = 0.3\n",
      "c) E(x) = 1.1\n",
      "d) Var(x) = 1.39\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('./datasets/Ch2/ex2-4-2.csv')\n",
    "\n",
    "a = df.loc[df['x'] <= 2, 'p(x)'].sum()\n",
    "print(f'a) P(X <= 2) = {a}')\n",
    "\n",
    "b = df.loc[df['x'] > 1 , 'p(x)'].sum()\n",
    "print(f'b) P(X > 1) = {b}')\n",
    "\n",
    "mean = (df['x'] * df['p(x)']).sum()\n",
    "print(f'c) E(x) = {mean}')\n",
    "\n",
    "var = ((df['x'] - mean) * (df['x'] - mean) * df['p(x)']).sum()\n",
    "\n",
    "print(f'd) Var(x) = {round(var, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4.7 (page 113) \n",
    "A computer sends a packet of information along a channel and waits for a return signal acknowledging that the packet has been received. If no acknowledgment is (page 113) received within a certain time, the packet is re-sent. Let X represent the number of times the packet is sent. Assume that the probability mass function of X is given by\n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    "    p(x)=\n",
    "    \\begin{cases}\n",
    "      cx & for\\,x = 1,2,3,4,5 \\\\\n",
    "      0 & otherwise\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "a) Find the value of the constant c so that p(x) is a probability mass function.\n",
    "\n",
    "$ \\sum_{x} cx = c(1 + 2 + 3 + 4 + 5) = 1$ \n",
    "\n",
    "$c = \\frac{1}{15}$\n",
    "\n",
    "b) Find P(X = 2).\n",
    "\n",
    "$P(X = 2) = 2 * \\frac{1}{15} = \\frac{2}{15}$ \n",
    "\n",
    "c) Find the mean number of times the packet is sent.\n",
    "\n",
    "$E(x) = \\frac{1}{15} * 1 + \\frac{2}{15} * 2 +  \\frac{3}{15} * 3 + \\frac{4}{15} * 4 + \\frac{5}{15} * 5 = 3.67$\n",
    "\n",
    "d) Find the variance of the number of times the packet is sent.\n",
    "\n",
    "$Var(x) = (1 - 3.67)^2 * \\frac{1}{15} + (2 - 3.67)^2 * \\frac{2}{15} +  (3 - 3.67)^2 * \\frac{3}{15} + (4 - 3.67)^2 * \\frac{4}{15} + (5 - 3.67)^2 * \\frac{5}{15} = \\frac{14}{9} = 1.56$\n",
    "\n",
    "e) Find the standard deviation of the number of times the packet is sent.\n",
    "\n",
    "$\\sigma = \\sqrt{Var(x)} = \\sqrt{\\frac{14}{9}} = \\frac{\\sqrt{14}}{3} = 1.247$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4.8 (page 113) \n",
    "After manufacture, computer disks are tested for errors. Let X be the number of errors detected on a randomly chosen disk. The following table presents values of the cumulative distribution function F(x) of X.\n",
    "\n",
    "a) What is the probability that two or fewer errors are detected?\n",
    "\n",
    "b) What is the probability that more than three errors are detected?\n",
    "\n",
    "c) What is the probability that exactly one error is detected?\n",
    "\n",
    "d) What is the probability that no errors are detected?\n",
    "\n",
    "e) What is the most probable number of errors to be detected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) F(2) = 0.83\n",
      "b) 1 - F(3) = 0.05\n",
      "c) F(1) - F(0) = 0.31\n",
      "d) F(0) = P(0) = 0.41\n",
      "e) P(Most likely) = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('./datasets/Ch2/ex2-4-8.csv')\n",
    "\n",
    "f_2 = df.at[2, 'F(x)']\n",
    "print(f'a) F(2) = {f_2}')\n",
    "\n",
    "b = 1 - df.at[3, 'F(x)']\n",
    "print(f'b) 1 - F(3) = {round(b,2)}')\n",
    "\n",
    "c = df.at[1, 'F(x)'] - df.at[0, 'F(x)']\n",
    "print(f'c) F(1) - F(0) = {c}')\n",
    "\n",
    "d = df.at[0, 'F(x)']\n",
    "print(f'd) F(0) = P(0) = {d}')\n",
    "\n",
    "p_x = pd.Series([0, 0.41, 0.72, 0.83, 0.95])\n",
    "df['P(x)'] = df['F(x)'] - p_x\n",
    "e = df.at[0, 'x']\n",
    "print(f'e) P(Most likely) = {e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4.10 (page 113) \n",
    "Candidates for a job are interviewed one by one until a qualified candidate is found. Thirty percent of the candidates are qualified.\n",
    "\n",
    "a) What is the probability that the first candidate is qualified?\n",
    "\n",
    "P(Q) = 0.3 \n",
    "\n",
    "b) What is the probability that the first candidate is unqualified and the second candidate is qualified?\n",
    "\n",
    "$P(nQ) * P(Q) = 0.7 * 0.3 = 0.21$\n",
    "\n",
    "c) Let X represent the number of candidates interviewed up to and including the first qualified candidate. Find P(X = 4).\n",
    "\n",
    "$P(X = 4) = 0.7 * 0.7 * 0.7 * 0.3 = 0.1029$\n",
    "\n",
    "d) Find the probability mass function of X.\n",
    "\n",
    "$f(x) = 0.7^{x - 1} * 0.3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4.15\n",
    "The function lifetime of a transistor in a certain application is random with probability density. \n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    "    f(t)=\n",
    "    \\begin{cases}\n",
    "      0.1e^{-0.1t} & t \\gt 0 \\\\\n",
    "      0 & t \\leq 0\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "a) Find the mean lifetime\n",
    "\n",
    "$\\mu_t = \\int_{0}^\\infty tf(t)dt = 0.1 \\int_{0}^\\infty te^{-0.1t}dt = 0.1 \\times \\frac{1}{0.1^2} = 10$ \n",
    "\n",
    "10 mánuðir. \n",
    "\n",
    "b)\n",
    "\n",
    "$\\sigma_x^2 = \\int_{0}^{\\infty} t^2 f(t)dt - \\mu^2 = 0.1 \\int_{0}^{\\infty} t^2 e^{-0.1t} dt - \\mu^2 = 0.1 \\frac{2}{0.1^3} - 10^2 = 200 - 100 = 100$\n",
    "\n",
    "$\\sigma_x = 10$ (sqrt of b)\n",
    "\n",
    "c) \n",
    "\n",
    "$F(L) = P(0 \\lt t \\lt L) = \\int_{0}^{L} f(t)dt = 0.1 \\int_{0}^{L} e^{-0.1t} dt = 1 - e^{-0.1L}$\n",
    "\n",
    "d) \n",
    "\n",
    "$F(12) = P(0 \\lt t \\lt 12) = 1 - e^{-0.1 * 12} = 0.6988$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4.24\n",
    "Particles are a major component of air pollution in many areas. It is of interest to study the sizes of contaminating particles. Let X represent the diameter, in micrometers, of a randomly chosen particle. Assume that in a certain area, the probability density function of X is inversely proportional to the volume of the particle; that is, assume that\n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    "    f(x)=\n",
    "    \\begin{cases}\n",
    "      \\frac{c}{x^3} & x \\geq 1 \\\\\n",
    "      0 & x \\lt 1\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "$$\n",
    "\n",
    "where c is a constant. \n",
    "\n",
    "\n",
    "a) Find the value of c so that f(x) is a probability density function.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "1 &= \\int_{1}^{\\infty} \\frac{c}{x^3} dx\\\\\n",
    "&= c \\int_{1}^{A} \\frac{1}{x^3} dx \\,,\\, A \\rightarrow \\infty \\\\\n",
    "&= c -\\frac{1}{2x^2} \\Big|_{1}^{A} \\\\\n",
    "&= c (-\\frac{1}{2A^2} + \\frac{1}{2}) \\\\\n",
    "&= \\frac{c}{2} \\\\\n",
    "c &= 2\n",
    "\\end{align}\n",
    "$ \n",
    "\n",
    "b) Find the mean particle diameter.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\mu_x &= 2 \\int_{1}^{\\infty} x * \\frac{1}{x^3} dx\\\\\n",
    "&= 2 \\int_{1}^{A} \\frac{1}{x^2} dx \\,,\\, A \\rightarrow \\infty \\\\\n",
    "&= 2 -\\frac{1}{x} \\Big|_{1}^{A} \\\\\n",
    "&= 2 (-\\frac{1}{A} + \\frac{1}{1}) \\\\\n",
    "&= 2 * 1 \\quad (-\\frac{1}{A} -> 0) \\\\\n",
    "&= 2\n",
    "\\end{align}\n",
    "$ \n",
    "\n",
    "c) Find the cumulative distribution function of the particle diameter.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "F(a) &= 2 \\int_{1}^{a} \\frac{1}{x^3} dx\\\\\n",
    "&= 2 -\\frac{1}{2x^2} \\Big|_{1}^{a} \\\\\n",
    "&= 2 (-\\frac{1}{2a^2} + \\frac{1}{2}) \\\\\n",
    "&= 1 - \\frac{1}{a^2} \\\\\n",
    "\\end{align}\n",
    "$ \n",
    "\n",
    "d) Find the median particle diameter.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "0.5 &= 1 - \\frac{1}{a^2} \\\\\n",
    "a^2 &= \\frac{1}{0.5} \\\\\n",
    "a &= \\sqrt{2}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "e) The term PM10 refers to particles 10 μm or less in diameter. What proportion of the contaminating particles are PM10?\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(x \\leq 10) &= 2 \\int_{1}^{10} \\frac{1}{x^3} dx\\\\\n",
    "&= 2 -\\frac{1}{2x^2} \\Big|_{1}^{10} \\\\\n",
    "&= 2 (-\\frac{1}{200} + \\frac{1}{2}) \\\\\n",
    "&= 0.99 \\\\\n",
    "\\end{align}\n",
    "$ \n",
    "\n",
    "f) The term PM25 refers to particles 2.5 μm or less in diameter. What proportion of the contaminating particles are PM25?\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(x \\leq 2.5) &= 2 \\int_{1}^{2.5} \\frac{1}{x^3} dx\\\\\n",
    "&= 2 -\\frac{1}{2x^2} \\Big|_{1}^{2.5} \\\\\n",
    "&= 2 (-\\frac{2}{25} + \\frac{1}{2}) \\\\\n",
    "&= 0.84 \\\\\n",
    "\\end{align}\n",
    "$ \n",
    "\n",
    "g) What proportion of the PM10 particles are PM25?\n",
    "\n",
    "$\\frac{0.84}{0.99} = 0.8484$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.5.10\n",
    "A gas station earns $2.60 in revenue for each gallon of regular gas it sells, $2.75 for each gallon of midgrade gas, and $2.90 for each gallon of premium gas. Let X1, X2, and X3\n",
    "denote the numbers of gallons of regular, midgrade, and premium gasoline sold in a day. \n",
    "\n",
    "Assume that X1, X2, and X3 have means $\\mu_1 = 1500\\, \\mu_2 = 500\\,\\,and\\,\\mu_3 = 300$, \n",
    "\n",
    "and standard deviations $\\sigma_1 = 180\\,\\, \\sigma_2 = 90\\,\\,, and\\,\\, \\sigma_3 = 40$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$c_1 = 2.6 \\\\ \n",
    "c_2 = 2.75 \\\\\n",
    "c_3 = 2.9$\n",
    "\n",
    "$ x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3$ \n",
    "\n",
    "$ \\mu_1 = 1500 \\\\\n",
    "\\mu_2 = 500 \\\\\n",
    "\\mu_3 = 300$\n",
    "\n",
    "$\\sigma_1 = 180 \\\\\n",
    "\\sigma_2 = 90 \\\\\n",
    "\\sigma_3 = 40$\n",
    "\n",
    "a) $\\mu = c_1 \\mu_1 + c_2 \\mu_2 + c_3 \\mu_3 = 6145$ $\n",
    "\n",
    "b) $\\sigma^2 = c_1^2 \\sigma_1^2 + c_2^2 \\sigma_2^2 + c_3^2 \\sigma_3^2$\n",
    "\n",
    "$\\sigma = \\sqrt{\\sigma^2} = 541.97$ $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.2.6 \n",
    "A cylindrical hole is bored through a steel block, and a cylindrical piston is machined to fit into the hole. The diameter of the hole is 20.00 ± 0.01 cm, and the diameter of the piston is 19.90 ± 0.02 cm. The clearance is one-half the difference between the diameters. Estimate the clearance and find the uncertainty in the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Problem3.2.6.jpg\" width=\"600\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "  \n",
    "# get the image\n",
    "Image(url=\"Problem3.2.6.jpg\", width=600, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$c = \\frac{1}{2}(D - d) = \\frac{1}{2}(20.00 - 19.90) = 0.05$\n",
    "\n",
    "$\\sigma_c^2 = c_1^2 \\sigma_D^2  + c_2^2 \\sigma_d^2 = (\\frac{1}{2})^2 (\\sigma_D^2 + \\sigma_d^2)$\n",
    "\n",
    "$\\sigma_c = \\sqrt{\\sigma_c^2} = \\frac{1}{2} \\sqrt{\\sigma_D^2 + \\sigma_d^2} = \\frac{1}{2} \\sqrt{(0.01)^2 + (0.02)^2} = 0.011$ cm\n",
    "\n",
    "$c = 0.05 \\pm 0.011$ cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proble 3.2.14\n",
    "A certain scale has an uncertainty of 3 g and a bias of 2 g.\n",
    "\n",
    "a) A single measurement is made on this scale. What are the bias and uncertainty in this measurement?\n",
    "\n",
    "$\\sigma = 3 g \\quad bias = 2 g$\n",
    "\n",
    "b) Four independent measurements are made on this scale. What are the bias and uncertainty in the average of these measurements?\n",
    "\n",
    "$\\sigma = \\frac{3g}{\\sqrt{n}} =  \\frac{3g}{\\sqrt{4}} = 1.5g \\quad bias = 2g$\n",
    "\n",
    "c) Four hundred independent measurements are made on this scale. What are the bias and uncertainty in the average of these measurements?\n",
    "\n",
    "$\\sigma = \\frac{3g}{\\sqrt{n}} =  \\frac{3g}{\\sqrt{400}} = 0.15g \\quad bias = 2g$\n",
    "\n",
    "d) As more measurements are made, does the uncertainty get smaller, get larger, or stay the same?\n",
    "\n",
    "The uncertainty gets smaller with more measurements.\n",
    "\n",
    "e) As more measurements are made, does the bias get smaller, get larger, or stay the same?\n",
    "\n",
    "The bias stays the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.2.15\n",
    "The volume of a rock is measured by placing the rock in a graduated cylinder partially filled with water and measuring the increase in volume. Eight independent measurements are made. The average of the measurements is 87.0 mL, and the standard deviation is 2.0 mL.\n",
    "\n",
    "a) Estimate the volume of the rock, and find the uncertainty in the estimate.\n",
    "\n",
    "b) Eight additional measurements are made, for a total of 16. What is the uncertainty, approximately, in the average of the 16 measurements?\n",
    "\n",
    "c) Approximately how many measurements would be needed to reduce the uncertainty to 0.4 mL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n = 8 \\\\ \n",
    "\\bar{v} = 87.0 \\\\ \n",
    "\\sigma_v = 2.0$\n",
    "\n",
    "a) $\\bar{v} = 87.0$ ml\n",
    "\n",
    "$\\sigma_{\\bar{v}} = \\frac{\\sigma_v}{\\sqrt{n}} = \\frac{2.0}{\\sqrt{8}} = 0.707$ ml\n",
    "\n",
    "b) $n = 16 \\qquad \\sigma_{\\bar{v}} = \\frac{\\sigma_v}{\\sqrt{n}} = \\frac{2.0}{\\sqrt{16}} = 0.5$ ml\n",
    "\n",
    "c) $0.4 = \\frac{2.0}{\\sqrt{n}}$\n",
    "\n",
    "$n = (\\frac{2.0}{0.4})^2 = 25$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.3.2\n",
    "Given that X and Y are related by the given equation, and that X = 3.0 ± 0.1, estimate Y and its uncertainty.\n",
    "\n",
    "$X = 3.0 \\pm 0.1$\n",
    "\n",
    "$\\sigma_y = \\big|\\frac{dY}{dX}\\big| \\times \\sigma_x$\n",
    "\n",
    "a) $XY = 1$ \n",
    "\n",
    "$Y = \\frac{1}{X} = \\frac{1}{3} = 0.33$\n",
    "\n",
    "$\\sigma_Y = \\Big| -\\frac{1}{x^2} \\big| \\times \\sigma_X = \\big| -\\frac{1}{3^2} \\big| \\times 0.1 \\approx 0.01 \\Rightarrow Y = 0.33 \\pm 0.01$\n",
    "\n",
    "b) $\\frac{Y}{X} = 2$\n",
    "\n",
    "$Y = 2X = 6$\n",
    "\n",
    "$\\sigma_Y = \\big| 2 \\big| \\times \\sigma_X = \\big| 2 \\big| \\times 0.1 \\approx 0.02 \\Rightarrow Y = 6 \\pm 0.02$\n",
    "\n",
    "c) $\\sqrt{XY} = 3$\n",
    "\n",
    "$Y = \\frac{9}{X} = 3$ \n",
    "\n",
    "$\\sigma_Y = \\big| - \\frac{9}{x^2} \\big| \\times \\sigma_X = \\big|  - \\frac{9}{3^2}  \\big| \\times 0.1 = 0.1 \\Rightarrow Y = 3 \\pm 0.01$\n",
    "\n",
    "d) $Y \\sqrt{X} = 4$ \n",
    "\n",
    "$ Y = \\frac{4}{\\sqrt{X}} = \\frac{4}{\\sqrt{3}}$\n",
    "\n",
    "$\\sigma_Y = \\big| - \\frac{2}{x^{\\frac{3}{2}}} \\big| \\times \\sigma_X = \\big|  - \\frac{2}{3^{\\frac{3}{2}}}  \\big| \\times 0.1 \\approx 0.04 \\Rightarrow Y = \\frac{4}{\\sqrt{3}} \\pm 0.04$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.4.1 \n",
    "Find the uncertainty in U, assuming that X = 10.0 ± 0.5, Y = 5.0 ± 0.1 \n",
    "\n",
    "$\\sigma_u = \\sqrt{(\\frac{\\delta U}{\\delta x} \\sigma_x)^2 + (\\frac{\\delta U}{\\delta y} \\sigma_y)^2}$ (formula for the propagation of errors)\n",
    "\n",
    "a) $U = XY^2$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_u &= \\sqrt{(Y^2 * 0.5)^2 + ( 2XY * 0.1)^2} \\\\\n",
    "&= \\sqrt{(5^2 * 0.5)^2 + ( 2 * 10 * 5 * 0.1)^2} \\\\\n",
    "&= 16.007\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "b) $U = X^2 + Y^2$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_u &= \\sqrt{(2X * 0.5)^2 + ( 2Y * 0.1)^2} \\\\\n",
    "&= \\sqrt{(10 * 0.5)^2 + ( 2 * 5 * 0.1)^2} \\\\\n",
    "&= 5.099\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "c) $U = \\frac{X^2 + Y^2}{2}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_u &= \\sqrt{(X * 0.5)^2 + (Y * 0.1)^2} \\\\\n",
    "&= \\sqrt{(10 * 0.5)^2 + ( 2 * 5 * 0.1)^2} \\\\\n",
    "&= 2.55\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.4.3\n",
    "From a fixed point on the ground, the distance to a certain tree is measured to be s = 55.2 ± 0.1 m and the angle from the point to the top of the tree is measured to be θ = 0.50 ± 0.02 radians. The height of the tree is given by h = s tan θ.\n",
    "\n",
    "$\\sigma_u = \\sqrt{(\\frac{\\delta U}{\\delta x} \\sigma_x)^2 + (\\frac{\\delta U}{\\delta y} \\sigma_y)^2}$ (formula for the propagation of errors)\n",
    "\n",
    "$\\sigma_s = 0.1m$\n",
    "\n",
    "$\\sigma_{\\theta} = 0.02 rads$\n",
    "\n",
    "a) Estimate h, and find the uncertainty in the estimate.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_u &= \\sqrt{(\\frac{\\delta U}{\\delta s} \\sigma_s)^2 + (\\frac{\\delta U}{\\delta \\theta} \\sigma_{\\theta})^2} \\\\ \n",
    "&= \\sqrt{(\\tan{\\theta} * 0.1)^2 + (\\frac{s}{\\cos^2{\\theta}} 0.02)^2} \\\\\n",
    "&= \\sqrt{(\\tan{0.5} * 0.1)^2 + (\\frac{55.2}{\\cos^2{0.5}} 0.02)^2} \\\\\n",
    "&= 1.4345\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "b) Which would provide a greater reduction in the uncertainty in h: reducing the\n",
    "uncertainty in s to 0.05 m or reducing the uncertainty in θ to 0.01 radians?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_u &= \\sqrt{(\\frac{\\delta U}{\\delta s} \\sigma_s)^2 + (\\frac{\\delta U}{\\delta \\theta} \\sigma_{\\theta})^2} \\\\ \n",
    "&= \\sqrt{(\\tan{\\theta} * 0.1)^2 + (\\frac{s}{\\cos^2{\\theta}} 0.01)^2} \\\\\n",
    "&= \\sqrt{(\\tan{0.5} * 0.1)^2 + (\\frac{55.2}{\\cos^2{0.5}} 0.01)^2} \\\\\n",
    "&= 0.7188\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_u &= \\sqrt{(\\frac{\\delta U}{\\delta s} \\sigma_s)^2 + (\\frac{\\delta U}{\\delta \\theta} \\sigma_{\\theta})^2} \\\\ \n",
    "&= \\sqrt{(\\tan{\\theta} * 0.05)^2 + (\\frac{s}{\\cos^2{\\theta}} 0.02)^2} \\\\\n",
    "&= \\sqrt{(\\tan{0.5} * 0.05)^2 + (\\frac{55.2}{\\cos^2{0.5}} 0.02)^2} \\\\\n",
    "&= 1.4337\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Reducing the radians has much more of an effect. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1.4\n",
    "Let X and Y be Bernoulli random variables. Let Z = X + Y.\n",
    "\n",
    "a) Show that if X and Y cannot both be equal to 1, then Z is a Bernoulli random variable.\n",
    "\n",
    "If X = 1 then we have Z = 1 + 0 = 1 and if we have Y = 1 then we have Z = 0 + 1 = 1. If both X and Y = 0 then Z = 0 + 0 = 0, so Z is also a Bernoulli random variable since Z can only be either equal 0 or 1. \n",
    "\n",
    "b) Show that if X and Y cannot both be equal to 1, then $p_Z =p_X +p_Y$\n",
    "\n",
    "Likely hood that X = 1 is p. Likewise X = 0 is 1 - p.\n",
    "\n",
    "Likely hood that Y = 1 is p. Likewise Y = 0 is 1 - p.\n",
    "\n",
    "Z = 1 + 0 = p + (1 - p) = 1 \n",
    "\n",
    "Z = 0 + 1 = 1 - p + p = 1 \n",
    "\n",
    "Z = 0 + 0 = 1 - p + 1 - p = 0 \n",
    "\n",
    "\n",
    "c) Show that if X and Y can both be equal to 1, then Z is not a Bernoulli random variable.\n",
    "\n",
    "if X = 1 and Y = 1 then Z = 1 + 1 = 2 which doesn't equal a Bernoulli random variable, which can only be either 0 or 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1.6 \n",
    "Two dice are rolled. Let X = 1 if the dice come up doubles and let X = 0 otherwise. Let Y = 1 if the sum is 6, and let Y = 0 otherwise. Let Z = 1 if the dice come up both doubles and\n",
    "with a sum of 6 (that is, double 3), and let Z = 0 otherwise.\n",
    "\n",
    "a) Let $p_X$ denote the success probability for X. Find $p_X$.\n",
    "\n",
    "$P(X = 1) = \\frac{6\\, doubles}{6 * 6 \\, poss.} = \\frac{1}{6}$\n",
    "\n",
    "b) Let $p_Y$ denote the success probability for Y. Find $p_Y$.\n",
    "\n",
    "$P(Y = 1) = \\frac{count(1+5\\,, 2+4\\,, 3+3\\,, 4+2\\,, 5+1)}{6 * 6 \\, poss.} = \\frac{5}{36}$\n",
    "\n",
    "c) Let $p_Z$ denote the success probability for Z. Find $p_Z$.\n",
    "\n",
    "$P(Z = 1) = \\frac{1\\,case}{36}$\n",
    "\n",
    "d) Are X and Y independent?\n",
    "\n",
    "$Z = X \\cap Y$\n",
    "\n",
    "if independant then $P(X)P(Y) = P(Z)$. $P(X)P(Y) = \\frac{1}{6} \\times \\frac{5}{36} \\neq P(Z)$ so they are not independant. \n",
    "\n",
    "e) Does $p_Z$ = $p_Xp_Y$?\n",
    "\n",
    "No, see calculations above.\n",
    "\n",
    "f) Does Z = XY? Explain.\n",
    "\n",
    "if X = 1 and Y = 1 then Z = 1. If X = 1 and Y = 0 then Z = 0 and if X = 0 and Y = 1 then Z = 0. So as we can see Z = XY. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1.8 \n",
    "A Bernoulli random variable has variance 0.21. What are the possible values for its success probability?\n",
    "\n",
    "$Var(x) = p(1 - p)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "0.21 &= p(1 - p) \\\\\n",
    "\\frac{0.21}{p} &= 1 - p \\\\\n",
    "\\frac{0.21}{p} + p &= 1 \\\\ \n",
    "\\frac{0.21 + p^2}{p} &= 1 \\\\\n",
    "0.21 + p^2 &= p \\\\\n",
    "p^2 - p + 0.21 &= 0 \\\\\n",
    "p &= [0.3:0.7]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2.3\n",
    "Find the following probabilities:\n",
    "\n",
    "a) P(X = 2) when X ∼ Bin(4, 0.6)\n",
    "\n",
    "b) P(X > 2) when X ∼ Bin(8, 0.2)\n",
    "\n",
    "c) P(X ≤ 2) when X ∼ Bin(5, 0.4)\n",
    "\n",
    "d) P(3≤X≤5) when X ∼ Bin(6,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.3456\n",
      "b) 0.20308\n",
      "c) 0.68256\n",
      "d) 0.81188 or 0.81188\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "k_1 = 2\n",
    "n_1 = 4 \n",
    "p_1 = 0.6 \n",
    "\n",
    "x_eq_2 = binom.pmf(k_1, n_1, p_1) \n",
    "print(f'a) {x_eq_2}')\n",
    "\n",
    "k_2 = 2\n",
    "n_2 = 8\n",
    "p_2 = 0.2\n",
    "\n",
    "#P(x > 2) = 1 - P(x <= 2)\n",
    "\n",
    "x_gt_2 = 1 - binom.cdf(2, 8, 0.2)\n",
    "x_gt_2\n",
    "\n",
    "print(f'b) {round(x_gt_2,5)}')\n",
    "\n",
    "k_3 = 2\n",
    "n_3 = 5\n",
    "p_3 = 0.4\n",
    "\n",
    "x_leq_2 = binom.cdf(2,5,0.4)\n",
    "\n",
    "print(f'c) {x_leq_2}')\n",
    "\n",
    "k_4 = 5\n",
    "n_4 = 6\n",
    "p_4 = 0.7\n",
    "\n",
    "#P(x > 5) = 1 - P(x <= 5)\n",
    "\n",
    "x_gt_5 = 1 - binom.cdf(k_4, n_4, p_4)\n",
    "\n",
    "#P(x < 3) \n",
    "\n",
    "x_lt_3 = binom.cdf(2, n_4, p_4)\n",
    "\n",
    "three_leq_x_leq_five = 1 - x_gt_5 - x_lt_3\n",
    "\n",
    "other_way = sum(binom.pmf([i for i in range(3,6)], n_4, p_4))\n",
    "\n",
    "print(f'd) {round(three_leq_x_leq_five,5)} or {round(other_way,5)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2.9\n",
    "Several million lottery tickets are sold, and 60% of the tickets are held by women. Five winning tickets will be drawn at random.\n",
    "\n",
    "60% women\n",
    "\n",
    "40% men \n",
    "\n",
    "P = 0.6 (women)\n",
    "\n",
    "1 - p = 0.4 (men)\n",
    "\n",
    "n = 5\n",
    "\n",
    "a) What is the probability that three or fewer of the winners will be women?\n",
    "\n",
    "b) What is the probability that three of the winners will be of one gender and two of the winners will be of the other gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.66304\n",
      "b) 0.576\n"
     ]
    }
   ],
   "source": [
    "p = 0.6\n",
    "n = 5\n",
    "k_a = 3\n",
    "\n",
    "three_or_fewer = binom.cdf(k_a, n, p)\n",
    "print(f'a) {round(three_or_fewer,5)}')\n",
    "\n",
    "#P(3 women) + P(2 women) \n",
    "b_4_1_9 = binom.pmf(3, n, p) + binom.pmf(2, n, p)\n",
    "print(f'b) {round(b_4_1_9,5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2.11\n",
    "A quality engineer samples 100 steel rods made on mill A and 150 rods made on mill B. Of the rods from mill A, 88 meet specifications, and of the rods from mill B, 135 meet specifications.\n",
    "\n",
    "Regla 4.7 segir okkur að ef við erum með binomial dreifingu (X ~ bin(n,p)) þá eru áætlaðar líkur p: \n",
    "\n",
    "$\\hat{p} = \\frac{\\bar{x}}{n}$\n",
    "\n",
    "$\\bar{x} = \\mu \\quad \\sigma_{\\bar{x}}^2 = \\sigma_{\\mu}^2 = np(1 - p) \\approx n\\hat{p}(1 - \\hat{p})$\n",
    "\n",
    "$\\sigma_{\\hat{p}} = \\sigma_{\\frac{\\bar{x}}{n}} = \\frac{\\sigma_{\\bar{x}}}{n} = \\frac{\\sqrt{n\\hat{p}(1 - \\hat{p})}}{n}= \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$\n",
    "\n",
    "Mill A:\n",
    "\n",
    "N = 100\n",
    "\n",
    "$\\hat{p} = \\frac{88}{100} = 0.88$\n",
    "\n",
    "$1 - \\hat{p} = 0.12$\n",
    "\n",
    "Mill B:\n",
    "\n",
    "N = 150\n",
    "\n",
    "$\\hat{p} = \\frac{135}{150} = 0.90$\n",
    "\n",
    "$1 - \\hat{p} = 0.1$\n",
    "\n",
    "\n",
    "a) Estimate the proportion of rods from mill A that meet specifications, and find the uncertainty in the estimate.\n",
    "\n",
    "$\\hat{p} = \\frac{88}{100} = 0.88$\n",
    "\n",
    "$\\sigma_{\\hat{p}} = \\frac{\\sqrt{n\\hat{p}(1 - \\hat{p})}}{n}= \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = \\sqrt{\\frac{0.88(1 - 0.88)}{100}} = 0.0325$\n",
    "\n",
    "b) Estimate the proportion of rods from mill B that meet specifications, and find the uncertainty in the estimate.\n",
    "\n",
    "$\\hat{p} = \\frac{135}{150} = 0.90$\n",
    "\n",
    "$\\sigma_{\\hat{p}} = \\frac{\\sqrt{n\\hat{p}(1 - \\hat{p})}}{n}= \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} = \\sqrt{\\frac{0.9(1 - 0.9)}{150}} = 0.0245$\n",
    "\n",
    "c) Estimate the difference between the proportions, and find the uncertainty in the estimate.\n",
    "\n",
    "$\\hat{p_a} - \\hat{p_b} = 0.90 - 0.88 = 0.02$\n",
    "\n",
    "$\\sigma = \\sqrt{\\sigma_{\\hat{p_a}}^2 + \\sigma_{\\hat{p_b}}^2} = 0.04069$ (Propagation of errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2.11 (4th edition)\n",
    "In a random sample of 100 parts ordered from vendor A, In a random sample of 200 parts ordered from vendor B, 10 were defective. \n",
    "\n",
    "Regla 4.7 segir okkur að ef við erum með binomial dreifingu (X ~ bin(n,p)) þá eru áætlaðar líkur p: $\\hat{p} = \\frac{\\bar{x}}{n}$\n",
    "\n",
    "$\\bar{x} = \\mu \\quad \\sigma_{\\bar{x}}^2 = \\sigma_mu^2 = np(1 - p) \\approx n\\hat{p}(1 - \\hat{p})$\n",
    "\n",
    "$\\sigma_{\\hat{p}} = \\sigma_{\\frac{\\bar{x}}{n}} = \\frac{\\sigma_{\\bar{x}}}{n} = \\frac{\\sqrt{n\\hat{p}(1 - \\hat{p})}}{n}= \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}$\n",
    "\n",
    "a) \n",
    "\n",
    "$\\hat{p} = \\frac{12}{100} = 0.12$\n",
    "\n",
    "$\\sigma_{\\hat{p_a}} = \\sqrt{\\frac{0.12(1 - 0.12)}{100}} = 0.0325$\n",
    "\n",
    "b)\n",
    "\n",
    "$\\hat{p} = \\frac{10}{200} = 0.05$\n",
    "\n",
    "$\\sigma_{\\hat{p_b}} = \\sqrt{\\frac{0.05(1 - 0.05)}{100}} = 0.0154$\n",
    "\n",
    "c)\n",
    "\n",
    "$\\hat{p_a} - \\hat{p_b} = 0.12 - 0.05 = 0.07$\n",
    "\n",
    "$\\sigma = \\sqrt{\\sigma_{\\hat{p_a}}^2 + \\sigma_{\\hat{p_b}}^2} = 0.036$ (Propagation of errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2.24\n",
    "One design for a system requires the installation of two identical components. The system will work if at least one of the components works. An alternative design requires four of these components, and the system will work if at least two of the four components work. If the probability that a component works is 0.9, and if the components function independently, which design has the greater probability of functioning?\n",
    "\n",
    "p = 0.9 \n",
    "\n",
    "System A:\n",
    "\n",
    "two components\n",
    "\n",
    "one has to work\n",
    "\n",
    "System B:\n",
    "\n",
    "four components \n",
    "\n",
    "two have to work\n",
    "\n",
    "$P(A) = P(c_1 \\cup c_2) = 0.9 + 0.9 - 0.9 * 0.9 = 0.99$\n",
    "\n",
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(A) = 0.99\n",
      "P(B) = 0.9963\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "p = 0.9\n",
    "k = 1\n",
    "\n",
    "print(f'P(A) = {1 - binom.pmf(0,2,p)}')\n",
    "\n",
    "print(f'P(B) = {1 - binom.cdf(k,n,p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So system B is more likely to function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3.3\n",
    "The number of large packages delivered by a courier service follows a Poisson distribution with a rate of 5per day. Let X be the number of large packages delivered on a given day. Find:\n",
    "\n",
    "a) $P(X = 6) \\\\$\n",
    "b) $P(X \\leq 2)\\\\$\n",
    "c) $P(5 \\lt X \\lt8)\\\\$\n",
    "d) $\\mu_x\\\\$\n",
    "e) $\\sigma_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) P(X = 6) = 0.14622\n",
      "b) P(X ≤ 2) = 0.87535\n",
      "c) P(5 < X < 8) = 0.25067\n",
      "d) mu_x = 5\n",
      "e) sigma_x = 2.23607\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "from math import sqrt\n",
    "\n",
    "lambda_4_3_3 = 5\n",
    "a_4_3_3 = poisson.pmf(6, lambda_4_3_3)\n",
    "b_4_3_3 = 1 - poisson.cdf(2, lambda_4_3_3) \n",
    "c_4_3_3 = poisson.cdf(7, lambda_4_3_3) - poisson.cdf(5, lambda_4_3_3)\n",
    "\n",
    "\n",
    "\n",
    "print(f'a) P(X = 6) = {round(a_4_3_3,5)}')\n",
    "print(f'b) P(X ≤ 2) = {round(b_4_3_3,5)}')\n",
    "print(f'c) P(5 < X < 8) = {round(c_4_3_3,5)}')\n",
    "print(f'd) mu_x = {lambda_4_3_3}')\n",
    "print(f'e) sigma_x = {round(sqrt(lambda_4_3_3),5)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3.6\n",
    "K ~Bin(n,p), n er mjög stórt og p er mjög lítið. \n",
    "\n",
    "$\\lambda = \\mu = np \\Rightarrow p = \\frac{\\lambda}{n}$\n",
    "\n",
    "$P(k) = \\begin{pmatrix} n \\\\ k\\end{pmatrix}p^k (1 - p)^{n - k} = \\frac{n!}{k!(n - k)!} (\\frac{\\lambda}{n})^k(1 - \\frac{\\lambda}{n})^{n - k}$\n",
    "\n",
    "$n \\rightarrow \\infty \\quad P(k) = \\frac{\\lambda^k}{k} e^{-\\lambda}$\n",
    "\n",
    "K ~Poisson($\\lambda$)\n",
    "\n",
    "$\\mu = \\lambda \\\\\n",
    "\\sigma^2 = \\lambda \\\\\n",
    "\\sigma = \\sqrt{\\lambda}$\n",
    "\n",
    "One out of every 5000 individuals in a population carries a certain defective gene. A random sample of 1000 individuals is studied.\n",
    "\n",
    "$\\lambda = np = 1000 * \\frac{1}{5000} = 0.2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.16375\n",
      "b) 0.81873\n",
      "c) 0.0011485\n",
      "d) 0.2\n",
      "e) 0.44721\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "from math import sqrt\n",
    "\n",
    "lambda_4_2_6 = 1000 / 5000\n",
    "\n",
    "#a P(x = 1)\n",
    "a_4_2_6 = poisson.pmf(1,lambda_4_2_6) # == binom.pmf(1,1000,1/5000)\n",
    "print(f'a) {round(a_4_2_6,5)}')\n",
    "\n",
    "#b P(x = 0) \n",
    "b_4_2_6 = poisson.pmf(0, lambda_4_2_6)\n",
    "print(f'b) {round(b_4_2_6,5)}')\n",
    "\n",
    "#c P(x > 2)\n",
    "c_4_2_6 = 1 - poisson.cdf(2, lambda_4_2_6)\n",
    "print(f'c) {round(c_4_2_6,7)}')\n",
    "\n",
    "#d avg = mu = lambda\n",
    "mu = lambda_4_2_6\n",
    "print(f'd) {mu}')\n",
    "\n",
    "#e stddev\n",
    "sigma = sqrt(lambda_4_2_6)\n",
    "print(f'e) {round(sigma,5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3.11\n",
    "A microbiologist wants to estimate the concentration of a certain type of bacterium in a waste-water sample. She puts a 0.5 mL sample of the wastewater on a microscope slide and counts 39 bacteria. Estimate the concentration of bacteria, per mL, in this wastewater, and find the uncertainty in the estimate.\n",
    "\n",
    "$\\sigma_{\\lambda} = \\sqrt{\\frac{\\lambda}{t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "Lambda_bacteria = 78.0 bacteria/mL\n",
      "Uncertainty:\n",
      "Sigma_bacteria = 12.49 bacteria/mL\n"
     ]
    }
   ],
   "source": [
    "lambda_bac = 39 / 0.5\n",
    "sigma_bac = sqrt(lambda_bac / 0.5)\n",
    "print('Mean:')\n",
    "print(f'Lambda_bacteria = {lambda_bac} bacteria/mL')\n",
    "print('Uncertainty:')\n",
    "print(f'Sigma_bacteria = {round(sigma_bac,5)} bacteria/mL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.3.13 Þarf ad klara\n",
    "The number of defective components produced by a certain process in one day has a Poisson distribution with mean 20. Each defective component has probability 0.60 of being repairable.\n",
    "\n",
    "a) Find the probability that exactly 15 defective components are produced.\n",
    "\n",
    "b) Given that exactly 15 defective components are produced, find the probability that exactly 10 of them are repairable.\n",
    "\n",
    "$P(10 repairable | 15 defective) = P(15 defective | 10 repairable) P(15 defective)$\n",
    "\n",
    "$P(10 repairable | 15 defective) = \\frac{P(10 repairable \\cap 15 defective)}{P(15 defective)}$\n",
    "\n",
    "c) Let N be the number of defective components produced, and let X be the number of them that are repairable. Given the value of N, what is the distribution of X?\n",
    "\n",
    "d) Find the probability that exactly 15 defective components are produced, with exactly 10 of them being repairable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) P(X = 15) = 0.05165\n"
     ]
    }
   ],
   "source": [
    "lambda_4_3_13 = 20\n",
    "p = 0.6\n",
    "\n",
    "a_4_3_13 = poisson.pmf(15, lambda_4_3_13)\n",
    "\n",
    "print(f'a) P(X = 15) = {round(a_4_3_13,5)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.5.1\n",
    "Find the area under the normal curve\n",
    "\n",
    "a) To the right of z = −0.85.\n",
    "\n",
    "b) Between z = 0.40 and z = 1.30.\n",
    "\n",
    "c) Between z = −0.30 and z = 0.90.\n",
    "\n",
    "d) Outside z = −1.50 to z=−0.45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/logisigurdarson/opt/anaconda3/envs/datascience/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.80234\n",
      "b) 0.24778\n",
      "c) 0.43385\n",
      "d) 0.74045\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "mu = 0\n",
    "stddev = 1\n",
    "\n",
    "print(f'a) {round(1 - norm.cdf(-0.85, mu, stddev),5)}')\n",
    "print(f'b) {round(norm.cdf(1.3, mu, stddev) - norm.cdf(0.4, mu, stddev),5)}')\n",
    "print(f'c) {round(norm.cdf(0.9, mu, stddev) - norm.cdf(-0.3, mu, stddev),5)}')\n",
    "print(f'd) {round(1 - (norm.cdf(-0.45, mu, stddev) - norm.cdf(-1.5, mu, stddev)),5)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.5.3\n",
    "Let Z ∼ N(0, 1). Find a constant c for which\n",
    "\n",
    "a) P(Z ≥ c) = 0.1587\n",
    "\n",
    "b) P(c≤Z≤0)=0.4772\n",
    "\n",
    "c) P(−c≤Z≤c)=0.8664\n",
    "\n",
    "d) P(0≤Z≤c)=0.2967\n",
    "\n",
    "e) P(|Z| ≤ c) = 0.1470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.999815\n",
      "b) -1.999077\n",
      "c) c = -1.500056 and 1.500056\n",
      "d) 0.829892\n",
      "e) c = -1.45021 and 1.45021\n"
     ]
    }
   ],
   "source": [
    "print(f'a) {round(norm.ppf(1 - 0.1587, 0, 1),6)}')\n",
    "print(f'b) {round(norm.ppf(1 - (0.4772 + 0.5), 0, 1),6)}')\n",
    "print(f'c) c = {round(norm.ppf((0.5 - 0.8664/2), 0, 1),6)} and {-round(norm.ppf((0.5 - 0.8664/2), 0, 1),6)}')\n",
    "print(f'd) {round(norm.ppf((0.5 + 0.2967), 0, 1),6)}')\n",
    "print(f'e) c = {round(norm.ppf((0.1470/2), 0, 1),6)} and {round(norm.ppf((1 - 0.1470/2), 0, 1),6)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.5.7\n",
    "In a recent study, the Centers for Disease Control reported that diastolic blood pressures (in mmHg) of adult women in the U.S. are approximately normally distributed with mean 80.5 and standard deviation 9.9.\n",
    "\n",
    "a) What proportion of women have blood pressures lower than 70?\n",
    "\n",
    "b) What is the 80th percentile of blood pressures?\n",
    "\n",
    "c) A woman has a blood pressure of 84. What percentile is her blood pressure on?\n",
    "\n",
    "d) A diastolic blood pressure greater than 90 is classified as hypertension (high blood pressure). What proportion of women have hypertension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.14443\n",
      "b) 88.83205\n",
      "c) 0.03786\n",
      "d) 0.16863\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "mean_4_5_7 = 80.5\n",
    "std_4_5_7 = 9.9\n",
    "\n",
    "\n",
    "print(f'a) {round(norm.cdf(70, mean_4_5_7, std_4_5_7),5)}')\n",
    "print(f'b) {round(norm.ppf(0.8, mean_4_5_7, std_4_5_7),5)}')\n",
    "print(f'c) {round(norm.pdf(84, mean_4_5_7, std_4_5_7),5)}')\n",
    "print(f'd) {round(norm.sf(90, mean_4_5_7, std_4_5_7),5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.5.9\n",
    "The lifetime of a lightbulb in a certain application is normally distributed with mean $\\mu$ = 1400 hours and standard deviation $\\sigma$ = 200 hours.\n",
    "\n",
    "a) What is the probability that a lightbulb will last more than 1800 hours?\n",
    "\n",
    "b) Find the 10th percentile of the lifetimes.\n",
    "\n",
    "c) A particular lightbulb lasts 1645 hours. What percentile is its lifetime on?\n",
    "\n",
    "d) What is the probability that the lifetime of a light-bulb is between 1350 and 1550 hours?\n",
    "\n",
    "e) Eight lightbulbs are chosen at random. What is the probability that exactly two of them have lifetimes between 1350 and 1550 hours?\n",
    "\n",
    "$P(X = 2) = \\begin{pmatrix} 8 \\\\2 \\end{pmatrix} p^{2}(1 - p)^{6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.02275\n",
      "b) 1143.69 hours\n",
      "c) 0.00094\n",
      "d) 0.37208\n",
      "e) 0.23761\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import comb, pow\n",
    "\n",
    "mu_4_5_9 = 1400\n",
    "std_4_5_9 = 200\n",
    "d_4_5_9 = norm.cdf(1550, mu_4_5_9, std_4_5_9) - norm.cdf(1350, mu_4_5_9, std_4_5_9)\n",
    "\n",
    "print(f'a) {round(norm.sf(1800, mu_4_5_9, std_4_5_9),5)}')\n",
    "print(f'b) {round(norm.ppf(0.1, mu_4_5_9, std_4_5_9),3)} hours')\n",
    "print(f'c) {round(norm.pdf(1645, mu_4_5_9, std_4_5_9),5)}')\n",
    "print(f'd) {round(d_4_5_9,5)}')\n",
    "print(f'e) {round(comb(8,2) * pow(d_4_5_9,2) * pow((1 - d_4_5_9),6),5)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.5.13\n",
    "A cylindrical hole is drilled in a block, and a cylindrical piston is placed in the hole. The clearance is equal to one-half the difference between the diameters of the hole and the piston. The diameter of the hole is normally distributed with mean 15 cm and standard deviation 0.025 cm, and the diameter of the piston is normally distributed with mean 14.88 cm and standard deviation 0.015 cm. The diameters of hole and piston are independent.\n",
    "\n",
    "a) Find the mean clearance.\n",
    "\n",
    "b) Find the standard deviation of the clearance.\n",
    "\n",
    "c) What is the probability that the clearance is less than 0.05 cm?\n",
    "\n",
    "d) Find the 25th percentile of the clearance.\n",
    "\n",
    "e) Specifications call for the clearance to be between 0.05 and 0.09 cm. What is the probability that the clearance meets the specification?\n",
    "\n",
    "f) It is possible to adjust the mean hole diameter. To what value should it be adjusted so as to maximize the probability that the clearance will be between 0.05 and 0.09 cm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) 0.06\n",
      "b) 0.01458\n",
      "c) 0.2464\n",
      "d) 0.05017\n",
      "e) 0.73379\n",
      "f) 15.02 cm\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt, pow\n",
    "\n",
    "mean_hole = 15\n",
    "std_hole = 0.025\n",
    "\n",
    "mean_piston = 14.88\n",
    "std_piston = 0.015\n",
    "\n",
    "mean_clearance = round((mean_hole - mean_piston) / 2,3)\n",
    "var_clearance = pow(0.5, 2) * (pow(std_hole,2) + pow(std_piston,2))\n",
    "std_clearance = round(sqrt(var_clearance),5)\n",
    "\n",
    "p_clear_less_point_five = norm.cdf(0.05, mean_clearance, std_clearance)\n",
    "\n",
    "p_25_percentile = round(norm.ppf(0.25, mean_clearance, std_clearance),5)\n",
    "\n",
    "p_between_poin_nine_and_point_five = norm.cdf(0.09, mean_clearance, std_clearance) - p_clear_less_point_five\n",
    "\n",
    "#likurnar eru í hámarki á milli 0.7 þegar við erum á milli 0.5 og 0.9\n",
    "\n",
    "mean_hole_two = 0.07 * 2 + mean_piston\n",
    "\n",
    "print(f'a) {mean_clearance}')\n",
    "print(f'b) {std_clearance}')\n",
    "print(f'c) {round(p_clear_less_point_five,5)}')\n",
    "print(f'd) {p_25_percentile}')\n",
    "print(f'e) {round(p_between_poin_nine_and_point_five,5)}')\n",
    "print(f'f) {round(mean_hole_two,5)} cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.5.21 Sönnun þarf ad gera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.6.1\n",
    "The lifetime (in days) of a certain electronic component that operates in a high-temperature\n",
    "environment is lognormally distributed with μ = 1.2 and σ = 0.4.\n",
    "\n",
    "a) Find the mean lifetime.\n",
    "\n",
    "b) Find the probability that a component lasts between three and six days.\n",
    "\n",
    "c) Find the median lifetime.\n",
    "\n",
    "d) Find the 90th percentile of the lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) mean lifetime: 3.59664\n",
      "b) P(3 ≤ x ≤ 6): 0.53053\n",
      "c) median lifetime: 3.32012\n",
      "d) 90th percentile: 5.54347\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "mu = 1.2\n",
    "sigma = 0.4\n",
    "\n",
    "mean_4_6_1 = exp(mu + (sigma**2) / 2)\n",
    "print(f'a) mean lifetime: {round(mean_4_6_1,5)}')\n",
    "print(f'b) P(3 ≤ x ≤ 6): {round(lognorm.cdf(6, sigma, 0, exp(mu)) - lognorm.cdf(3, sigma, 0, exp(mu)),5)}')\n",
    "print(f'c) median lifetime: {round(lognorm.median(sigma, 0, exp(mu)),5)}')\n",
    "print(f'd) 90th percentile: {round(lognorm.ppf(0.9, sigma, 0, exp(mu)), 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.6.3\n",
    "The body mass index (BMI) of a person is defined to be the person’s body mass divided by the square of the person’s height. The article “Influences of Parameter Uncertainties within the ICRP 66 Respiratory Tract Model: Particle Deposition” (W. Bolch, E. Farfan, et al., Health Physics, 2001:378–394) states that body mass index (in kg/m2) in men aged 25–34 is lognormally distributed with parameters μ = 3.215 and σ = 0.157.\n",
    "\n",
    "a) Find the mean BMI for men aged 25–34.\n",
    "\n",
    "b) Find the standard deviation of BMI for men aged 25–34.\n",
    "\n",
    "c) Find the median BMI for men aged 25–34.\n",
    "\n",
    "d) What proportion of men aged 25–34 have a BMI less than 22?\n",
    "\n",
    "e) Find the 75th percentile of BMI for men aged 25–34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) mean BMI: 25.2121\n",
      "b) std BMI: 3.9828\n",
      "c) median BMI: 24.9033\n",
      "d) % BMI less than 22: 0.2149\n",
      "e) 75th percentile: 27.6851\n"
     ]
    }
   ],
   "source": [
    "from math import exp, sqrt\n",
    "from statistics import median_grouped \n",
    "from scipy.stats import lognorm\n",
    "\n",
    "mu = 3.215\n",
    "sigma = 0.157\n",
    "\n",
    "mean_BMI_4_6_3 = exp(mu + (sigma**2) / 2)\n",
    "std_BMI_4_6_3 = sqrt(exp(2 * mu + 2 * sigma**2) - mean_BMI_4_6_3**2)\n",
    "median_BMI_4_6_3 = lognorm.median(sigma, 0, exp(mu))\n",
    "BMI_less_22 = lognorm.cdf(22, sigma, 0, exp(mu))\n",
    "percentile = lognorm.ppf(0.75, sigma, 0, exp(mu))\n",
    "\n",
    "print(f'a) mean BMI: {round(mean_BMI_4_6_3,4)}')\n",
    "print(f'b) std BMI: {round(std_BMI_4_6_3,4)}')\n",
    "print(f'c) median BMI: {round(median_BMI_4_6_3,4)}')\n",
    "print(f'd) % BMI less than 22: {round(BMI_less_22,4)}')\n",
    "print(f'e) 75th percentile: {round(percentile, 4)}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.6.4 Þarf ad gera\n",
    "The article “Stochastic Estimates of Exposure and Cancer Risk from Carbon Tetrachloride Released to the Air from the Rocky Flats Plant” (A. Rood, P. McGavran, et al., Page 261 Risk Analysis, 2001:675–695) models the increase in the risk of cancer due to exposure to carbon tetrachloride as lognormal with $\\mu = −15.65$ and $\\sigma = 0.79$.\n",
    "\n",
    "mean $E(x) = e^{\\mu + \\frac{\\sigma^2}{2}}$\n",
    "variance $Var(x) = e^{2\\mu + 2\\sigma^2} - E(x)^2$\n",
    "\n",
    "a) Find the mean risk.\n",
    "\n",
    "x = risk \n",
    "\n",
    "$E(x) = e^{-15.65 + \\frac{0.79^2}{2}} = 2.182 \\times 10^{-7}$\n",
    "\n",
    "b) Find the median risk.\n",
    "\n",
    "c) Find the standard deviation of the risk.\n",
    "\n",
    "d) Find the 5th percentile.\n",
    "\n",
    "e) Find the 95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) mean risk: 2.1817900221644364e-07\n",
      "b) median risk: 1.5969501451937286e-07\n",
      "c) std risk: 2.031017178297292e-07\n",
      "d) 5th percentile: 4.3546593145177714e-08\n",
      "e) 95th percentile 5.856370342754772e-07\n"
     ]
    }
   ],
   "source": [
    "from math import exp, sqrt\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "mu = -15.65\n",
    "sigma = 0.79\n",
    "\n",
    "mean_risk_4_6_4 = exp(mu + (sigma**2) / 2)\n",
    "median_risk_4_6_4 = lognorm.median(sigma, 0, exp(mu))\n",
    "std_risk_4_6_4 = sqrt(exp(2 * mu + 2 * sigma**2) - mean_risk_4_6_4**2)\n",
    "fith_percentile = lognorm.ppf(0.05, sigma, 0, exp(mu))\n",
    "ninity_percentile = lognorm.ppf(0.95, sigma, 0, exp(mu))\n",
    "\n",
    "print(f'a) mean risk: {mean_risk_4_6_4}')\n",
    "print(f'b) median risk: {median_risk_4_6_4}')\n",
    "print(f'c) std risk: {std_risk_4_6_4}')\n",
    "print(f'd) 5th percentile: {fith_percentile}')\n",
    "print(f'e) 95th percentile {ninity_percentile}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.7.2\n",
    "The time between requests to a web server is exponentially distributed with mean 0.5\n",
    "seconds.\n",
    "\n",
    "a) What is the value of the parameter λ?\n",
    "\n",
    "b) What is the median time between requests?\n",
    "\n",
    "c) What is the standard deviation?\n",
    "  \n",
    "d) What is the 80th percentile?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.7.8 þarf ad gera \n",
    "If T is a continuous random variable that is always positive (such as a waiting time), with probability density function f(t) and cumulative distribution function F(t), then the hazard function is defined to be the function:\n",
    "\n",
    "$$h(t) = \\frac{f(t)}{1 - F(t)}$$\n",
    "\n",
    "The hazard function is the rate of failure per unit time, expressed as a proportion of the items that have not failed.\n",
    "\n",
    "a) If T ∼ Weibull(α, β), find h(t).\n",
    "\n",
    "b) For what values of α is the hazard rate increasing with time? For what values of α is it decreasing?\n",
    "\n",
    "c) If T has an exponential distribution, show that the hazard function is constant.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "h(t) &= \\frac{\\lambda e^{-\\lambda x}}{1 - (1 - e^{-\\lambda x})} \\\\ \n",
    "h(t) &= \\frac{\\lambda e^{-\\lambda x}}{e^{-\\lambda x}} \\\\\n",
    "h(t) &= \\lambda\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.7.11\n",
    "The number of traffic accidents at a certain intersection is thought to be well modeled by a Poisson process with a mean of 3 accidents per year.\n",
    "\n",
    "a) Find the mean waiting time between accidents.\n",
    "\n",
    "b) Find the standard deviation of the waiting times between accidents.\n",
    "\n",
    "c) Find the probability that more than one year elapses between accidents.\n",
    "\n",
    "d) Find the probability that less than one month elapses between accidents.\n",
    "\n",
    "e) If no accidents have occurred within the last six months, what is the probability that an accident will occur within the next year? (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean waiting time: 4.0 months\n",
      "std waiting time: 4.0 months\n",
      "prob of more than one year: 0.0498\n",
      "prob less than a month: 0.2212\n",
      "prob of acc next year, if not acc last six months: 0.9502\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "mean_waiting_time = 12 / 3\n",
    "std_waiting_time = mean_waiting_time\n",
    "\n",
    "more_than_one_year = expon.sf(12, 0, mean_waiting_time)\n",
    "less_than_one_month = expon.cdf(1, 0, mean_waiting_time)\n",
    "\n",
    "print(f'mean waiting time: {mean_waiting_time} months')\n",
    "print(f'std waiting time: {std_waiting_time} months')\n",
    "print(f'prob of more than one year: {round(more_than_one_year,4)}')\n",
    "print(f'prob less than a month: {round(less_than_one_month,4)}')\n",
    "print(f'prob of acc next year, if not acc last six months: {round(expon.cdf(12, 0, mean_waiting_time), 4)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.9.3\n",
    "Let $X_1$ and $X_2$ be independent, each with unknown mean $\\mu$ and known variance $\\sigma^2 = 1$.\n",
    "\n",
    "a) Let $\\hat{\\mu_1} = \\frac{X_1 + X_2}{2}$. Find the bias, variance, and mean squared error of $\\hat{\\mu_1}$\n",
    "\n",
    "$E(\\hat{\\mu_1}) = \\frac{\\mu_{x_1} + \\mu_{x_2}}{2} = \\frac{\\mu + \\mu}{2} = \\mu$\n",
    "\n",
    "The bias of $\\hat{\\mu_1} = E(\\hat{\\mu_1}) - \\mu = \\mu - \\mu = 0 \\Rightarrow$ is unbiased\n",
    "\n",
    "The variance of $\\hat{\\mu_1} = Var(\\hat{\\mu_1}) = (\\frac{\\sigma + \\sigma}{2})^2 = \\frac{\\sigma^2 + \\sigma^2}{4} = \\frac{1 + 1}{4} = \\frac{1}{2}$\n",
    "\n",
    "The mean squared error of $\\hat{\\mu_1}$ is the sum of the variance and the square of the bias: \n",
    "\n",
    "$MSE(\\hat{\\mu_1}) = \\frac{1}{2} + 0^2 = 0.5$\n",
    "\n",
    "b) Let $\\hat{\\mu_2} = \\frac{X_1 + 2X_2}{3}$. Find the bias, variance, and mean squared error of $\\hat{\\mu_2}$\n",
    "\n",
    "$E(\\hat{\\mu_2}) = \\frac{\\mu_{x_1} + 2\\mu_{x_2}}{2} = \\frac{\\mu + 2 \\mu}{3} = \\mu$\n",
    "\n",
    "The bias of $\\hat{\\mu_2} = E(\\hat{\\mu_2}) - \\mu = \\mu - \\mu = 0 \\Rightarrow$ is unbiased\n",
    "\n",
    "The variance of $\\hat{\\mu_2} = Var(\\hat{\\mu_2}) = (\\frac{\\sigma + 2\\sigma}{2})^2 = \\frac{\\sigma^2 + 4\\sigma^2}{9} = \\frac{1 + 4}{5} = \\frac{5}{9}$\n",
    "\n",
    "The mean squared error of $\\hat{\\mu_2}$ is the sum of the variance and the square of the bias: \n",
    "\n",
    "$MSE(\\hat{\\mu_2}) = \\frac{5}{9} + 0^2 = \\frac{5}{9}$\n",
    "\n",
    "c) Let $\\hat{\\mu_3} = \\frac{X_1 + X_2}{4}$. Find the bias, variance, and mean squared error of $\\hat{\\mu_3}$\n",
    "\n",
    "$E(\\hat{\\mu_3}) = \\frac{\\mu_{x_1} + \\mu_{x_2}}{4} = \\frac{\\mu +  \\mu}{4} = \\frac{\\mu}{2}$\n",
    "\n",
    "The bias of $\\hat{\\mu_3} = E(\\hat{\\mu_3}) - \\mu = \\frac{\\mu}{2} - \\mu = -\\frac{\\mu}{2} = \\frac{\\mu}{2}$ (absolute value) $\\Rightarrow$ is biased\n",
    "\n",
    "The variance of $\\hat{\\mu_3} = Var(\\hat{\\mu_3}) = (\\frac{\\sigma + \\sigma}{4})^2 = \\frac{\\sigma^2 + \\sigma^2}{16} = \\frac{2}{16} = \\frac{1}{8}$\n",
    "\n",
    "The mean squared error of $\\hat{\\mu_3}$ is the sum of the variance and the square of the bias: \n",
    "\n",
    "$MSE(\\hat{\\mu_3}) =  (\\frac{\\mu}{2})^2 + \\frac{1}{8} = \\frac{\\mu^2}{4} + \\frac{1}{8}$\n",
    "\n",
    "d) For what values of $\\mu$ does $\\hat{\\mu_3}$ have smaller mean squared error than $\\hat{\\mu_1}$?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "MSE(\\hat{\\mu_3}) < MSE(\\hat{\\mu_1}) \\Longleftrightarrow  \\frac{\\mu^2}{4} + \\frac{1}{8} < \\frac{1}{2} \\\\\n",
    "&= \\frac{\\mu^2}{4} < \\frac{3}{8} \\\\\n",
    "&= \\mu^2 < \\frac{12}{8} \\Rightarrow -1.2247 < \\mu < 1.2247 \\quad (\\pm \\sqrt(1.5))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "e) For what values of $\\mu$ does $\\hat{\\mu_3}$ have smaller mean squared error than $\\hat{\\mu_2}$?\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "MSE(\\hat{\\mu_3}) < MSE(\\hat{\\mu_2}) \\Longleftrightarrow  \\frac{\\mu^2}{4} + \\frac{1}{8} < \\frac{5}{9} \\\\\n",
    "&= \\frac{\\mu^2}{4} < \\frac{31}{72} \\\\\n",
    "&= \\mu^2 < \\frac{31}{18} \\Rightarrow -1.31233 < \\mu < 1.31233 \\quad (\\pm \\sqrt(\\frac{31}{18}))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.9.6\n",
    "Let $X_1, ..., X_n$ be a random sample from a population with the Poisson($\\lambda$) distribution. Find\n",
    "the MLE of $\\lambda$.\n",
    "\n",
    "x ~ Poission($\\lambda$)         $\\lambda = ?$\n",
    "\n",
    "P(data | $\\lambda$) = L(p)\n",
    "\n",
    "$P(x) = e^{-\\lambda} \\frac{\\lambda^x}{x!} \\quad x = 1,2,...$\n",
    "\n",
    "data = {$x_1, x_2, ..., x_n$}\n",
    "\n",
    "$P(data) = P(x_1) P(x_2)...P(x_n) = L(\\lambda)$\n",
    "\n",
    "$\\frac{d}{d\\lambda} L = 0 \\Longleftrightarrow \\frac{d}{d\\lambda}ln(L) = 0$\n",
    "\n",
    "$ln(L) = \\sum_i P(x_i) \\qquad \\frac{d}{d\\lambda}ln(L) = \\sum_i \\frac{d}{d\\lambda} P(x_i) = 0$\n",
    "\n",
    "$ln(P(x_i)) = ln(e^{-\\lambda} \\frac{\\lambda^{x_i}}{x_i!}) = -\\lambda + x_i ln(\\lambda) - ln(x_i!)$\n",
    "\n",
    "$\\frac{d}{d\\lambda}ln(P(x_i)) = -1 + \\frac{x_i}{\\lambda}$\n",
    "\n",
    "$\\frac{d}{d\\lambda}ln(L) = \\sum_{i = 1}^n (1 - \\frac{x_i}{\\lambda} = -n + \\frac{1}{\\lambda}\\sum_{i = 1}^n x_i = 0$\n",
    "\n",
    "$\\Rightarrow \\hat{\\lambda} = \\frac{1}{n}\\sum_{i = 1}^n x_i$     an estimation of $\\lambda = E(x)$, MLE coincides with the sample mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.9.10\n",
    "Let $X_1,...,X_n$ be a random sample from a $N(\\mu, \\sigma^2)$ population. Find the MLEs of $\\mu$ and of $\\sigma$.\n",
    "\n",
    "x ~ $N(\\mu, \\sigma^2)$      data = ${x_1,x_2,...,x_n}$\n",
    "\n",
    "Estimate $\\mu,\\sigma^2$ using the ML method\n",
    "\n",
    "P(data | $\\mu, \\sigma^2$) = L($\\mu, \\sigma^2$)  max\n",
    "\n",
    "$P(x_1,x_2, ..., x_n) = P(x_1) P(x_2) ... P(x_n)$\n",
    "\n",
    "$dP(x_1) = f(x_1) dx \\quad f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{\\frac{-(x_i - \\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "$L(\\mu, \\sigma^2) = f(x_1) f(x_2) ... f(x_n)$\n",
    "\n",
    "$ln(L) = \\sum_i ln(f(x_i)) = \\sum_i (-\\frac{1}{2} ln(2\\pi\\sigma^2) - \\frac{-(x_i - \\mu)^2}{2\\sigma^2})$\n",
    "\n",
    "1) $\\mu \\quad \\frac{d}{d\\mu}ln(L) = \\sum_i (-\\frac{2(x_i - \\mu)}{2\\sigma^2}) = 0$\n",
    "\n",
    "$\\sum_{i = 0}^n (x_i - \\mu) = 0 \\Rightarrow \\sum_i x_i - n\\mu = 0 \\Rightarrow \\hat{\\mu} = \\frac{1}{n} \\sum_{i = 1}^n = x_i$\n",
    "\n",
    "2) $\\sigma \\quad \\frac{d}{d\\sigma^2}ln(L) = \\sum_i (-\\frac{1}{2} \\frac{1}{\\sigma^2} - \\frac{(x_i - \\mu)^2}{2}-\\frac{1}{\\sigma^4}) = 0$\n",
    "\n",
    "$\\sum_i(-1 + \\frac{(x_i - \\mu)^2}{\\sigma^2}) = 0 \\Rightarrow \\sigma^2 = \\frac{1}{n} \\sum_i (x_i - \\mu)$\n",
    "\n",
    "$\\hat{\\sigma^2} = \\frac{1}{n} \\sum_i (x_i - \\hat{\\mu})^2$ MLE does not coincide with sample std deviation which is $s^2 = \\frac{1}{n - 1}\\sum_i (x_i - \\hat{\\mu})^2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.1.13\n",
    "The sugar content in a one-cup serving of a certain breakfast cereal was measured for a\n",
    "sample of 140 servings. The average was 11.9 g and the standard deviation was 1.1 g.\n",
    "\n",
    "$\\bar{x} = 11.9$ g\n",
    "\n",
    "s = 1.1\n",
    "\n",
    "n = 140\n",
    "\n",
    "$\\sigma_{\\bar{x}} = \\frac{s}{\\sqrt{n}}$\n",
    "\n",
    "a) Find a 95% confidence interval for the mean sugar content.\n",
    "\n",
    "$\\sigma_{\\bar{x}} = \\frac{1.1}{\\sqrt{140}}$\n",
    "\n",
    "$\\mu \\in [11.9 - 1.96 * 0.093, 11.9 + 1.96 * 0.093] \\Longleftrightarrow \\mu \\in [11.718, 12.082]$\n",
    "\n",
    "b) Find a 99% confidence interval for the mean sugar content.\n",
    "\n",
    "$\\mu \\in [11.9 - 2.58 * 0.093, 11.9 + 2.58 * 0.093] \\Longleftrightarrow \\mu \\in [11.66, 12.14]$\n",
    "\n",
    "c) What is the confidence level of the interval (11.81, 11.99)?\n",
    "\n",
    "$\\bar{x} - Z_{score} \\sigma_{\\bar{x}} = 11.81$\n",
    "\n",
    "$\\bar{x} + Z_{score} \\sigma_{\\bar{x}} = 11.99$\n",
    "\n",
    "Isolate for $Z_{score}$\n",
    "\n",
    "$Z_{score} = \\frac{11.99 - 11.9}{0.093} = 0.9677$\n",
    "\n",
    "$Z_{score} = \\frac{11.9 - 11.81}{0.093} = 0.9677$\n",
    "\n",
    "See interval code\n",
    "\n",
    "d) How large a sample is needed so that a 95% confidence interval specifies the mean to within ±0.1?\n",
    "\n",
    "95% CI = $[\\bar{x} - 0.1, \\bar{x} + 0.1]$ =  $[\\bar{x} - 1.96\\sigma_{\\bar{x}}, \\bar{x} + 1.96\\sigma_{\\bar{x}}]$\n",
    "\n",
    "$1.96\\sigma_{\\bar{x}} = 0.1 \\Rightarrow 1.96 \\frac{s}{\\sqrt{n}} = 0.1 \\Rightarrow n = (\\frac{1.96 * 1.1}{0.1})^2 = 465$\n",
    "\n",
    "e) How large a sample is needed so that a 99% confidence interval specifies the mean to within ±0.1?\n",
    "\n",
    "99% CI = $[\\bar{x} - 0.1, \\bar{x} + 0.1]$ =  $[\\bar{x} - 2.58\\sigma_{\\bar{x}}, \\bar{x} + 2.58\\sigma_{\\bar{x}}]$\n",
    "\n",
    "$2.58\\sigma_{\\bar{x}} = 0.1 \\Rightarrow 2.58 \\frac{s}{\\sqrt{n}} = 0.1 \\Rightarrow n = (\\frac{2.58 * 1.1}{0.1})^2 = 806$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6668057818705643\n",
      "CI: 66.7\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm \n",
    "\n",
    "z = 0.9677\n",
    "\n",
    "CI = norm.cdf(z, 0, 1) - norm.cdf(-z, 0, 1) \n",
    "#print(1 - 2 * norm.cdf(-z, 0, 1))\n",
    "\n",
    "print(f'CI: {round(CI,3) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.1.23\n",
    "Based on a large sample of capacitors of a certain type, a 95% confidence interval for the mean capacitance, in $\\mu F$, was computed to be (0.213, 0.241). Find a 90% confidence interval for the mean capacitance of this type of capacitor.\n",
    "\n",
    "$0.241 = \\bar{x} + 1.96 \\sigma_{\\bar{x}}$\n",
    "\n",
    "$0.213 = \\bar{x} - 1.96 \\sigma_{\\bar{x}}$\n",
    "\n",
    "$0.241 - 0.213 = 2 * 1.96 \\sigma_{\\bar{x}}$\n",
    "\n",
    "$\\sigma_{\\bar{x}} = \\frac{0.241 - 0.213}{3.92} = 0.00714$ \n",
    "\n",
    "$\\bar{x} = 0.213 + 1.96 * 0.00714 = 0.223$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90% CI: [0.21125574510356648, 0.23474425489643352]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm \n",
    "\n",
    "fith_percent = norm.ppf(0.05, 0.223, 0.00714)\n",
    "ninityfith_percen  = norm.ppf(0.95, 0.223, 0.00714)\n",
    "\n",
    "print(f'90% CI: [{fith_percent}, {ninityfith_percen}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.8.6\n",
    "Following are weights, in pounds, of 12 two-month-old baby girls. Assume that the population is normally distributed.\n",
    "\n",
    "a) Find the sample standard deviation s.\n",
    "\n",
    "b) Construct a 95% confidence interval for population standard deviation σ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std.dev: 1.798172\n",
      "95% CI: [1.274, 3.053]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, chi2\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./datasets/Ch5/ex5-8-6.csv\")\n",
    "\n",
    "sample_mean = df.mean()\n",
    "std_dev = df.std()\n",
    "sigma_5_8_6 = std_dev / sqrt(len(df))\n",
    "\n",
    "upper_z = chi2.ppf(0.975, len(df) - 1)\n",
    "lower_z = chi2.ppf(0.025, len(df) - 1)\n",
    "\n",
    "low_interval = sqrt(((len(df) - 1) * std_dev **2) / upper_z)\n",
    "high_interval = sqrt(((len(df) - 1) * std_dev **2) / lower_z)\n",
    "\n",
    "\n",
    "print(f\"std.dev: {std_dev.to_string(index=False)}\")\n",
    "\n",
    "print(f'95% CI: [{round(low_interval,3)}, {round(high_interval,3)}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.8.10\n",
    "A sample of size 101 from a normal population has sample standard deviation s = 40. The lower and upper 0.025 points of the $\\chi^2_{100}$  distribution are $\\chi^2_{[100, 0.975]}= 74.222$ and $\\chi^2_{[100, 0.025]} = 129.561$. Use these values to construct a 95% confidence interval for $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI for sigma: [35.14170636942747, 46.42946345728505]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 101\n",
    "s = 40\n",
    "\n",
    "higher_chi = 74.222\n",
    "lower_chi = 129.561\n",
    "\n",
    "lower_interval = sqrt(((n - 1) * s**2) / lower_chi)\n",
    "higher_interval = sqrt(((n - 1) * s**2) / higher_chi)\n",
    "\n",
    "print(f'95% CI for sigma: [{lower_interval}, {higher_interval}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.1.6\n",
    "A certain type of stainless steel powder is supposed to have a mean particle diameter of μ = 15 μm. A random sample of 87 particles had a mean diameter of 15.2 μm, with a standard deviation of 1.8 μm. A test is made of $H_0$: μ = 15 versus $H_1$: μ ≠ 15.\n",
    "\n",
    "a) Find the P-value.\n",
    "\n",
    "See below\n",
    "\n",
    "b) Do you believe it is plausible that the mean diameter is 15 μm, or are you convinced\n",
    "that it differs from 15 μm? Explain your reasoning.\n",
    "\n",
    "Since p-value is a lot higher than 0.05  we can be sceptical about the correctness of $H_0$ but further research is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.30002701885400107\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "\n",
    "n = 87\n",
    "\n",
    "mu = 15\n",
    "s = 1.8\n",
    "\n",
    "sigma = s / sqrt(n)\n",
    "sample_mean = 15.2\n",
    "\n",
    "z = (sample_mean - mu) / sigma\n",
    "\n",
    "p_value = norm.cdf(-z, 0, 1) * 2\n",
    "\n",
    "print(f'p-value: {p_value}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.1.7\n",
    "In a test of corrosion resistance, a sample of 60 Incoloy steel specimens were immersed in acidified brine for four hours, after which each specimen had developed a number of corrosive pits. The maximum pit depth was measured for each specimen. The mean depth was 850 μm with a standard deviation of 153 μm. The specification is that the population mean depth μ is less than 900 μm.\n",
    "\n",
    "a. Find the P-value for testing H0: μ ≥ 900 versus H1: μ < 900.\n",
    "\n",
    "b. Do you believe it is plausible that the mean depth is at least 900μm, or are you\n",
    "convinced that it is less than 900μm? Explain.\n",
    "\n",
    "We reject H0, since the probability of observing a sample mean as small as 850 that was actually observed is 0.0057. Therefore we except H1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.005681031317330347\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 60 \n",
    "sample_mean_6_1_7= 850\n",
    "std_6_1_7 = 153\n",
    "\n",
    "mu_6_1_7 = 900\n",
    "\n",
    "sigma_6_1_7 = std_6_1_7 / sqrt(n)\n",
    "\n",
    "z = (sample_mean_6_1_7 - mu_6_1_7) / sigma_6_1_7\n",
    "\n",
    "print(f'p-value: {norm.cdf(z, 0, 1)}') #why?\n",
    "\n",
    "#plt.hist(norm.cdf(z,0, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.3.5\n",
    "In a survey of 500 residents in a certain town, 274 said they were opposed to constructing a new shopping mall. Can you conclude that more than half of the residents in this town are opposed to constructing a new shopping mall?\n",
    "\n",
    "$H_0: p \\leq 0.5$ $\\quad H_1: p \\gt0.5$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.01591156369324498\n",
      "So we can conclude that it is likely the survay is statisticly significant since the p-value is < 0.05\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "\n",
    "n = 500\n",
    "k = 274\n",
    "p = 0.5\n",
    "\n",
    "p_hat = k / n\n",
    "sigma = sqrt((p * (1 - p) / n))\n",
    "\n",
    "z = (p_hat - p) / sigma\n",
    "\n",
    "p_value = 1 - norm.cdf(z, 0, 1)\n",
    "\n",
    "print(f'p-value: {p_value}')\n",
    "print('So we can conclude that it is likely the survay is statisticly significant since the p-value is < 0.05')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.3.8\n",
    "A grinding machine will be qualified for a particular task if it can be shown to produce less than 8% defective parts. In a random sample of 300 parts, 12 were defective. On the basis of these data, can the machine be qualified?\n",
    "\n",
    "$H_0$ : $p \\geq 0.08$\n",
    "\n",
    "$H_1$ : $p < 0.08$\n",
    "\n",
    "p-value = 0.0053 (see calculations below)\n",
    "\n",
    "The p-value is smaller than then the standard 0.05 and thus it is safe to assume the machine is qulified, and we reject $H_0$. Also this is only a one sided test so it gives more room for inaccuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.005328187360645716\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "n = 300\n",
    "k = 12 \n",
    "p = 0.08\n",
    "\n",
    "p_hat = k / n\n",
    "sigma = sqrt((p * (1 - p)) / n)\n",
    "\n",
    "z = (p_hat - p) / sigma\n",
    "\n",
    "p_value = norm.cdf(z, 0, 1)\n",
    "\n",
    "print(f'p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.5.4\n",
    "A sample of 413 male college students, the average number of energy drinks consumed per month was 2.49 with a standard deviation of 4.87, and in a sample of 382 female college students, the average was 1.22 with a standard deviation of 3.24. Can you conclude that the mean number of energy drinks is greater for male students than for female students?\n",
    "\n",
    "$\\bar{x_b} = 2.49$\n",
    "\n",
    "$\\bar{x_g} = 1.22$\n",
    "\n",
    "D = the difference between the two sample means = $\\bar{x_b} - \\bar{x_g}$ seen as random numbers\n",
    "\n",
    "$H_0$: $D \\leq 0$, Their consumption is not greater.\n",
    "\n",
    "$H_1$: $D \\gt 0$, Their consumption is greater.\n",
    "\n",
    "The z score for D: $z = \\frac{D - \\mu_D}{\\sigma_D} = \\frac{\\bar{x_b} - \\bar{x_g - 0}}{\\sqrt{\\frac{s^2_b}{n_b} + \\frac{s^2_g}{n_g}}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 6.549014480741914e-06\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "\n",
    "mean_b = 2.49\n",
    "mean_g = 1.22\n",
    "\n",
    "s_b = 4.87\n",
    "s_g = 3.24\n",
    "\n",
    "n_b = 413\n",
    "n_g = 382\n",
    "\n",
    "z = (mean_b - mean_g - 0) / sqrt((s_b**2 / n_b) + (s_g**2 / n_g)) \n",
    "\n",
    "p_value = norm.cdf(-z, 0, 1)\n",
    "\n",
    "print(f'p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we reject $H_0$, their consumption is greater. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.5.9\n",
    "A sample of 77 subjects went on a low-carbohydrate diet for six months. At the end of that time the sample mean weight loss was 4.7 kg with a sample standard deviation of 7.2 kg. A second sample of 79 subjects went on a low-fat diet. Their sample mean weight loss was 2.6 kg with a standard deviation of 5.9 kg.\n",
    "\n",
    "a) Can you conclude that the mean weight loss is greater for those on the low- carbohydrate diet?\n",
    "\n",
    "$D = \\bar{x_{lc}} - \\bar{x_{lf}}$\n",
    "\n",
    "$H_0$: $D \\leq 0$\n",
    "\n",
    "$H_1$: $D \\gt 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.989757530572266\n",
      "a) p-value: 0.023308825922513803\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "\n",
    "mean_lc = 4.7\n",
    "s_lc = 7.2\n",
    "\n",
    "mean_lf = 2.6\n",
    "s_lf = 5.9\n",
    "\n",
    "n_lc = 77\n",
    "n_lf = 79\n",
    "\n",
    "z = (mean_lc - mean_lf - 0) / sqrt((s_lc**2 / n_lc) + (s_lf**2 / n_lf))\n",
    "\n",
    "p_value = norm.cdf(-z, 0 , 1)\n",
    "\n",
    "print(f'a) p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we reject $H_0$, mean weight loss greater for low carbohydrate group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Can you conclude that the mean weight loss on the low-carbohydrate diet is more than 1 kg greater than that of the low-fat diet?\n",
    "\n",
    "$D = \\bar{x_{lc}} - \\bar{x_{lf}}$\n",
    "\n",
    "$H_0$: $D \\leq 1$\n",
    "\n",
    "$H_1$: $D \\gt 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) p-value: 0.14864697938616772\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "\n",
    "mean_lc = 4.7\n",
    "s_lc = 7.2\n",
    "\n",
    "mean_lf = 2.6\n",
    "s_lf = 5.9\n",
    "\n",
    "n_lc = 77\n",
    "n_lf = 79\n",
    "\n",
    "z = (mean_lc - mean_lf - 1) / sqrt((s_lc**2 / n_lc) + (s_lf**2 / n_lf))\n",
    "\n",
    "p_value = norm.cdf(-z, 0 , 1)\n",
    "\n",
    "print(f'a) p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We accept $H_0$, we can not conclude that the mean weight loss on the lc dies is more than 1 kg greater than the lf diet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.7.2\n",
    "In a study of the relationship of the shape of a tablet to its dissolution time, 6 disk-shaped ibuprofen tablets and 8 oval-shaped ibuprofen tablets were dissolved in water. The dissolve times, in seconds, were as follows:\n",
    "\n",
    "Disk: 269.0 249.3 255.2 252.7 247.0 261.6 \n",
    "\n",
    "Oval: 268.8 260.0 273.5 253.9 278.5 289.4 261.6 280.2\n",
    "\n",
    "Can you conclude that the mean dissolve times differ between the two shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.016829011493447114\n",
      "t: -2.775676251020437\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t, ttest_ind\n",
    "\n",
    "#ttest_ind = Students t test\n",
    "#ttest_rel = Paired students t test\n",
    "\n",
    "disk = [269.0, 249.3, 255.2, 252.7, 247.0, 261.6]\n",
    "oval = [268.8, 260.0, 273.5, 253.9, 278.5, 289.4, 261.6, 280.2]\n",
    "\n",
    "t, p = ttest_ind(disk, oval, equal_var=False)\n",
    "\n",
    "print(f'p-value: {p}')\n",
    "print(f't: {t}')\n",
    "\n",
    "#p-value: the probability that the result is due to chance\n",
    "#p-value < 0.05, so we can conclude that the mean dissolve times differ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.7.6\n",
    "Two weights, each labeled as weighing 100 g, are each weighed several times on the same scale. The results, in units of μg above 100 g, are as follows:\n",
    "\n",
    "Firstweight: 53 88 89 62 39 66 \n",
    "\n",
    "Second weight: 23 39 28 2 49\n",
    "\n",
    "Since the same scale was used for both weights, and since both weights are similar, it is reasonable to assume that the variance of the weighing does not depend on the object being weighed. Can you conclude that the weights differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.008791204429500437\n",
      "t: 3.330562809466136\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "first_weight = [53, 88, 89, 62, 39, 66]\n",
    "second_weight = [23, 39, 28, 2, 49]\n",
    "\n",
    "t, p = ttest_ind(first_weight, second_weight, equal_var=True)\n",
    "\n",
    "print(f'p-value: {p}')\n",
    "print(f't: {t}')\n",
    "\n",
    "#p-value = 0.00898 < 0.05 so we can conclude that the weights differ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.7.14\n",
    "A new post-surgical treatment was compared with a standard treatment. Seven subjects received the new treatment, while seven others (the controls) received the standard treatment. The recovery times, in days, are given below.\n",
    "\n",
    "Can you conclude that the mean recovery time for those receiving the new treatment is less than the mean for those receiving the standard treatment?\n",
    "\n",
    "D = $\\bar{x_t} - \\bar{x_c}$ \n",
    "\n",
    "$H_0: D \\geq 0$ \n",
    "\n",
    "$H_1: D \\lt 0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.005592188590202719\n",
      "t: -3.0635646318651624\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "df = pd.read_csv(\"datasets/Ch6/ex6-9-7.csv\")\n",
    "df\n",
    "\n",
    "t, p = ttest_ind(df[\"Treatment (X)\"], df[\"Control (Y)\"], equal_var=False, alternative=\"less\")\n",
    "\n",
    "print(f'p-value: {p}')\n",
    "print(f't: {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value is less than 0.05 we reject $H_0$ and thus we conclude that the mean recovery time is less for those receiving the treatment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.8.1\n",
    "The article “Improved Bioequivalence Assessment of Topical Dermatological Drug Products Using Dermatopharmacokinetics” (B. N’Dri-Stempfer, W. Navidi, R. Guy, and A. Bunge, Pharmaceutical Research, 2009:316–328) described a study comparing the amounts of econozole nitrate absorbed into human skin for several formulations of antifungal ointment. Both a brand name and generic drug were applied to the arms of 14 subjects, and the amounts absorbed, in μg/cm2, were measured. Following are the results. Can you conclude that the mean amount absorbed differs between the brand name and the generic drug?\n",
    "\n",
    "Want to use two sided test. \n",
    "\n",
    "$H_0$: $D = 0$\n",
    "\n",
    "$H_1$: $D \\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.1682108810646709\n",
      "t: 1.459336638331387\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./datasets/Ch6/ex6-8-1.csv\", header=0, names=[\"Brand Name\", \"Generic\", \"Difference\"])\n",
    "\n",
    "t, p = ttest_rel(df[\"Brand Name\"], df[\"Generic\"])\n",
    "\n",
    "print(f'p-value: {p}')\n",
    "print(f't: {t}')\n",
    "\n",
    "#p-value 0.168 > 0.05, we can not conclude there is a diffrence. H_0 is accepted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.8.5\n",
    "Two formulations of a certain coating, designed to inhibit corrosion, are being tested. For each of eight pipes, half the pipe is coated with formulation A and the other half is coated with formulation B. Each pipe is exposed to a salt environment for 500 hours. Afterward, the corrosion loss (in μm) is measured for each formulation on each pipe.\n",
    "\n",
    "Can you conclude that the mean amount of corrosion differs between the two formulations?\n",
    "\n",
    "D = $\\bar{x_A} - \\bar{x_B}$\n",
    "\n",
    "$H_0$: $D = 0$\n",
    "\n",
    "$H_1$: $D \\neq 0$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.01934828466050993\n",
      "t: -3.021390645237225\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "df = pd.read_csv(\"./datasets/Ch6/ex6-8-5.csv\")\n",
    "t, p = ttest_rel(df[\"A\"], df[\"B\"])\n",
    "\n",
    "print(f'p-value: {p}')\n",
    "print(f't: {t}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reject $H_0$ since p-value is less than 0.05. Thus we can conclude that the mean corrosion differs between the formulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.8.10\n",
    "A group of eight individuals with high cholesterol levels were given a new drug that was designed to lower cholesterol levels. Cholesterol levels, in mg/dL, were measured before and after treatment for each individual, with the following results:\n",
    "\n",
    "a. Can you conclude that the mean cholesterol level after treatment is less than the mean before treatment?\n",
    "\n",
    "D = $\\bar{x_a} - \\bar{x_b}$\n",
    "\n",
    "$H_0: D \\geq 0$ \n",
    "\n",
    "$H_1: D \\lt 0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 3.2732685392738495e-07\n",
      "t: -16.7745404068734\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "df = pd.read_csv(\"./datasets/Ch6/ex6-8-10.csv\")\n",
    "\n",
    "t, p = ttest_rel(df[\"After\"], df[\"Before\"], alternative=\"less\", )\n",
    "\n",
    "\n",
    "print(f'p-value: {p}')\n",
    "print(f't: {t}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we reject $H_0$ because the p-value is < 0.05. Thus we can conclude that the mean cholesterol level after a treament is less than before it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Can you conclude that the reduction in mean cholesterol level after treatment is greater than 75 mg/dL?\n",
    "\n",
    "D = $\\bar{x_b} - \\bar{x_a} $\n",
    "\n",
    "$H_0: D \\lt 75$ \n",
    "\n",
    "$H_1: D \\geq 75$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.19297378266765725\n",
      "t: 0.9245809673079826\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "df = pd.read_csv(\"./datasets/Ch6/ex6-8-10.csv\")\n",
    "\n",
    "difference = df[\"Before\"] - df[\"After\"]\n",
    "\n",
    "D = [75 for i in range(len(difference))]\n",
    "\n",
    "t, p = ttest_ind(difference, D, equal_var=False, alternative=\"greater\")\n",
    "\n",
    "\n",
    "print(f'p-value: {p}')\n",
    "print(f't: {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We accept $H_0$, and thus conclude that the difference is less than 75mg/dL after the treatment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miniprojects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miniproject 1 (week 5)\n",
    "Step 1:\n",
    "\n",
    "$\\mu = E(x) = \\int_{a}^{b} x dP = \\int_{a}^{b} xf(x)dx = \\frac{1}{b - a} \\int_{a}^{b} x dx = \\frac{1}{b - a}\\, \\frac{x^2}{2} \\Big|_a^b = \\frac{b^2 - a^2}{2(a - b)} = \\frac{(b - a)(b - a)}{2(b - a)} \\Rightarrow \\mu = \\frac{b - a}{2}$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\sigma^2 &= Var(x)\\\\\n",
    "&= \\mu_{x^2} - (\\mu_x)^2 \\\\\n",
    "&= \\int_{a}^{b} x^2 f(x)dx \\\\\n",
    "&= \\frac{1}{b - a} \\int_{a}^{b} x^2 dx \\\\\n",
    "&= \\frac{1}{b - a}\\, \\frac{x^3}{3} \\Big|_{a}^{b}\\\\\n",
    "&= \\frac{1}{b - a} \\times \\frac{b^3 - a^3}{3} \\\\\n",
    "&= \\frac{(b - a)(b^2 + ab + a^2)}{3(b - a)} \\\\\n",
    "&= \\frac{b^2 + ab + a^2}{3}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$0 \\leq x \\leq 1$ \n",
    "\n",
    "$\\mu = \\frac{1 - 0}{2} = \\frac{1}{2}$\n",
    "\n",
    "$\\sigma^2 = \\frac{(1 - 0)^2}{12} \\\\\n",
    "\\sigma = \\sqrt{\\frac{1}{12}} = \\frac{1}{2\\sqrt{3}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random, mean, std\n",
    "import pandas as pd\n",
    "\n",
    "k = 10\n",
    "n = 10\n",
    "m = []\n",
    "stddevs = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(k):\n",
    "    rand_lis =  [random.random_sample(1) for _ in range(n)]\n",
    "    m.append(mean(rand_lis))\n",
    "    stddevs.append(std(rand_lis))\n",
    "\n",
    "df['M'] = m\n",
    "df['Std.dev'] = stddevs\n",
    "#df = df.set_axis([f'S{i}' for i in range(1,k)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe from the data all the means are in range 0.15 from the actual mean. The standard deviation looks to be closer to the actual stddev than the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 10\n",
      "k: 10\n",
      "Mean of the mean: 0.53449\n",
      "Mean of stddev: 0.26713\n",
      "Stddev: 0.28868\n",
      "Sample std of m: 0.0766037\n",
      "True sample std: 0.0912871\n",
      "As we can observe the mean of the mean is much closer to the true mean (0.5) than in array M\n"
     ]
    }
   ],
   "source": [
    "mean_mean = df['M'].mean()\n",
    "print(f'n: {n}\\nk: {k}')\n",
    "print(f'Mean of the mean: {round(mean_mean,5)}')\n",
    "sample_std_of_m = df['M'].std()\n",
    "mean_of_std = df['Std.dev'].mean()\n",
    "print(f'Mean of stddev: {round(mean_of_std,5)}\\nStddev: {round(1 / sqrt(12),5)}\\nSample std of m: {round(sample_std_of_m,7)}\\nTrue sample std: {round(1 / sqrt(12 * n),7)}')\n",
    "print('As we can observe the mean of the mean is much closer to the true mean (0.5) than in array M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 10\n",
    "\n",
    "k: 10\n",
    "\n",
    "Mean of the mean: 0.46781\n",
    "\n",
    "Mean of stddev: 0.25057\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0840819\n",
    "\n",
    "True sample std: 0.0912871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 100\n",
    "\n",
    "k: 10\n",
    "\n",
    "Mean of the mean: 0.49524\n",
    "\n",
    "Mean of stddev: 0.28404\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0339839\n",
    "\n",
    "True sample std: 0.0288675"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 1000\n",
    "\n",
    "k: 10\n",
    "\n",
    "Mean of the mean: 0.50005\n",
    "\n",
    "Mean of stddev: 0.28852\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0070751\n",
    "\n",
    "True sample std: 0.0091287"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 10000\n",
    "\n",
    "k: 10\n",
    "\n",
    "Mean of the mean: 0.50059\n",
    "\n",
    "Mean of stddev: 0.28877\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0021885\n",
    "\n",
    "True sample std: 0.0028868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 100000\n",
    "\n",
    "k: 10\n",
    "\n",
    "Mean of the mean: 0.49977\n",
    "\n",
    "Mean of stddev: 0.28855\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0013092\n",
    "\n",
    "True sample std: 0.0009129"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 1000000\n",
    "\n",
    "k: 10\n",
    "\n",
    "Mean of the mean: 0.49999\n",
    "\n",
    "Mean of stddev: 0.28866\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0002473\n",
    "\n",
    "True sample std: 0.0002887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 10\n",
    "\n",
    "k: 100\n",
    "\n",
    "Mean of the mean: 0.48305\n",
    "\n",
    "Mean of stddev: 0.26485\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0944039\n",
    "\n",
    "True sample std: 0.0912871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 10\n",
    "\n",
    "k: 1000\n",
    "\n",
    "Mean of the mean: 0.49714\n",
    "\n",
    "Mean of stddev: 0.2687\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0856888\n",
    "\n",
    "True sample std: 0.0912871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 10\n",
    "\n",
    "k: 10000\n",
    "\n",
    "Mean of the mean: 0.499\n",
    "\n",
    "Mean of stddev: 0.26983\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0910039\n",
    "\n",
    "True sample std: 0.0912871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n: 10\n",
    "\n",
    "k: 100000\n",
    "\n",
    "Mean of the mean: 0.49967\n",
    "\n",
    "Mean of stddev: 0.27023\n",
    "\n",
    "Stddev: 0.28868\n",
    "\n",
    "Sample std of m: 0.0911934\n",
    "\n",
    "True sample std: 0.0912871"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e60faada378f6b3d3e839d3773c81eab86867a18f20f84015888fc9faa7ad49d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
